
<!-- @import "[TOC]" {cmd="toc" depthFrom=1 depthTo=6 orderedList=false} -->

<!-- code_chunk_output -->

- [1. 系统级性能优化](#1-系统级性能优化)
- [2. Perf 简介](#2-perf-简介)
  - [2.1. 基本原理](#21-基本原理)
  - [2.2. 功能概述](#22-功能概述)
- [3. 一个简单例子](#3-一个简单例子)
- [4. 一行命令](#4-一行命令)
  - [4.1. 三种类型命令](#41-三种类型命令)
  - [4.2. Listing Events: 列出事件](#42-listing-events-列出事件)
  - [4.3. Counting Events: 事件计数](#43-counting-events-事件计数)
  - [4.4. Profiling: 采样数据](#44-profiling-采样数据)
  - [4.5. Static Tracing: 静态跟踪](#45-static-tracing-静态跟踪)
  - [4.6. Dynamic Tracing: 动态追踪](#46-dynamic-tracing-动态追踪)
  - [4.7. Mixed: 混合使用](#47-mixed-混合使用)
  - [4.8. Special: 特定命令](#48-special-特定命令)
  - [4.9. Reporting: report分析](#49-reporting-report分析)
- [5. 演示示例](#5-演示示例)
- [6. Prerequisites: 先决条件](#6-prerequisites-先决条件)
  - [6.1. Symbols: 符号表](#61-symbols-符号表)
  - [6.2. JIT符号表(Java, Node.js)](#62-jit符号表java-nodejs)
  - [6.3. Stack Traces: 堆栈追踪](#63-stack-traces-堆栈追踪)
    - [6.3.1. Frame Pointer: 不让忽略frame pointer](#631-frame-pointer-不让忽略frame-pointer)
    - [6.3.2. Dwarf: 用户级释放堆栈](#632-dwarf-用户级释放堆栈)
    - [6.3.3. LBR: 硬件能力](#633-lbr-硬件能力)
    - [6.3.4. 小结](#634-小结)
- [7. perf功能概述](#7-perf功能概述)
  - [7.1. 全局性概况](#71-全局性概况)
  - [7.2. 全局细节](#72-全局细节)
  - [7.3. 特定功能分析](#73-特定功能分析)
  - [7.4. perf record](#74-perf-record)
  - [7.5. 可视化工具perf timechart](#75-可视化工具perf-timechart)
  - [7.6. 3种使用方式和性能分析的3个过程](#76-3种使用方式和性能分析的3个过程)
  - [7.7. 使用示例](#77-使用示例)
- [8. Perf 性能事件](#8-perf-性能事件)
  - [8.1. 六种类型事件](#81-六种类型事件)
  - [8.2. perf list查看所有性能事件](#82-perf-list查看所有性能事件)
  - [8.3. Hardware Events(PMCs): 硬件性能事件(PMCs)](#83-hardware-eventspmcs-硬件性能事件pmcs)
  - [8.4. Software Events: 软件性能事件](#84-software-events-软件性能事件)
    - [8.4.1. 采样周期](#841-采样周期)
  - [8.5. Kernel Tracepoints: 内核态静态tracepoints](#85-kernel-tracepoints-内核态静态tracepoints)
    - [8.5.1. tracepoints分组](#851-tracepoints分组)
  - [8.6. User-Level Statically Defined Tracing (USDT): 用户态静态tracepoint](#86-user-level-statically-defined-tracing-usdt-用户态静态tracepoint)
  - [8.7. Dynamic Tracing: 动态追踪](#87-dynamic-tracing-动态追踪)
- [9. 示例(性能分析分类)](#9-示例性能分析分类)
  - [9.1. CPU Statistics: CPU静态统计](#91-cpu-statistics-cpu静态统计)
    - [9.1.1. CPU 微架构](#911-cpu-微架构)
    - [9.1.2. Detailed Mode: 详细模式](#912-detailed-mode-详细模式)
    - [9.1.3. Specific Counters: 具体计数器](#913-specific-counters-具体计数器)
    - [9.1.4. Raw Counters: 处理器支持的原始计数器](#914-raw-counters-处理器支持的原始计数器)
    - [9.1.5. Other Options: 其他选项](#915-other-options-其他选项)
  - [9.2. Timed Profiling(CPU Profiling): 定时间隔性能分析](#92-timed-profilingcpu-profiling-定时间隔性能分析)
    - [9.2.1. sampling: 采样](#921-sampling-采样)
    - [9.2.2. 分析](#922-分析)
  - [9.3. Event Profiling: 事件分析](#93-event-profiling-事件分析)
    - [9.3.1. Skew和PEBS: 指令偏移和PEBS基于采样的精确事件](#931-skew和pebs-指令偏移和pebs基于采样的精确事件)
  - [9.4. Static Kernel Tracing: 内核态静态追踪](#94-static-kernel-tracing-内核态静态追踪)
    - [9.4.1. Counting Syscalls: 系统调用计数](#941-counting-syscalls-系统调用计数)
      - [9.4.1.1. perf和strace对比](#9411-perf和strace对比)
    - [9.4.2. New Processes: 追踪新建一个进程](#942-new-processes-追踪新建一个进程)
    - [9.4.3. Outbound Connections: 出站网络连接](#943-outbound-connections-出站网络连接)
    - [9.4.4. Socket Buffers:](#944-socket-buffers)
  - [9.5. Static User Tracing: 用户态静态追踪](#95-static-user-tracing-用户态静态追踪)
  - [9.6. Dynamic Tracing: 动态追踪](#96-dynamic-tracing-动态追踪)
    - [Kernel: tcp_sending(): 某个内核函数被调用栈](#kernel-tcp_sending-某个内核函数被调用栈)
    - [Kernel: tcp_sendmsg() with size: 获取内核变量](#kernel-tcp_sendmsg-with-size-获取内核变量)
    - [Kernel: tcp_sendmsg() line number and local variable: 内核函数某一行跟踪点和局部变量](#kernel-tcp_sendmsg-line-number-and-local-variable-内核函数某一行跟踪点和局部变量)
    - [User: malloc():](#user-malloc)
  - [9.7. Scheduler Analysis: 调度器分析](#97-scheduler-analysis-调度器分析)
  - [9.8. eBPF](#98-ebpf)
    - [9.8.1.](#981)
    - [9.8.2. 事件限定符](#982-事件限定符)
  - [9.9. 性能事件的属性](#99-性能事件的属性)
    - [9.9.1. PMI中断和PEBS中断](#991-pmi中断和pebs中断)
    - [9.9.2. 性能事件的精度级别](#992-性能事件的精度级别)
    - [9.9.3. 其他属性](#993-其他属性)
  - [9.10. 没有预定义字符描述的硬件性能事件](#910-没有预定义字符描述的硬件性能事件)
  - [9.11. 性能事件指定错误](#911-性能事件指定错误)
- [10. Visualizations: 可视化](#10-visualizations-可视化)
  - [10.1. Flame Graphs: 火焰图](#101-flame-graphs-火焰图)
    - [10.1.1. 示例](#1011-示例)
    - [10.1.2. 生成](#1012-生成)
- [11. perf构建](#11-perf构建)
  - [11.1. 安装依赖库](#111-安装依赖库)
  - [11.2. 测试](#112-测试)
  - [11.3. 编译](#113-编译)
  - [11.4. 安装](#114-安装)
  - [11.5. 帮助文档](#115-帮助文档)
- [12. 简单示例](#12-简单示例)
  - [12.1. cycles原理](#121-cycles原理)
- [13. 参考](#13-参考)

<!-- /code_chunk_output -->

参照: http://www.brendangregg.com/perf.html

# 1. 系统级性能优化

系统级性能优化是指为了提高应用程序对操作系统资源与硬件资源的使用 效率，或者为了提高操作系统对硬件资源的使用效率而进行的代码优化。通过提 高对操作系统资源与硬件资源的利用率，使得应用程序与基础软硬件平台具有更 好的交互性，往往可以显著提升应用程序的执行速度和稳定性。

**系统级性能优化**包含**2个阶段**：

1. **性能剖析**（**performance profiling**）：**寻找性能瓶颈**，查找引发性能问题的原因及热点代码。
2. **代码优化**：针对具体的性能问题而**优化代码与编译选项**，以改善软件性能。

在代码优化阶段往往需要凭借开发者的经验，编写简洁高效的代码，甚至在汇编语言级别合理使用各种指令，合理安排各种指令的执行顺序。

而在**性能剖析阶段**，则需要借助于现有的**profiling工具**，如 perf，VTune，Oprofile 等。

# 2. Perf 简介

本文将介绍一下perf的用法，网上很多叫法如`perf_events` , `perf profiler` , `Performance Counters for Linux(Linux性能计数器, PCL)`。叫法不同，都指perf。

最初的时候, 它叫做 `Performance counter`, 在 `2.6.31` 中第一次亮相. 此后他成为内核开发最为活跃的一个领域. 在 `2.6.32` 中它正式改名为 `Performance Event`, 因为 `perf` 已不再仅仅作为 `PMU` 的抽象, 而是能够处理**所有的性能相关**的事件.

通过perf，你可以发现以下问题的答案：

* 为什么内核使用**太多的CPU**，**哪些代码**使用了这些CPU时间
* **什么代码**导致**CPU二级缓存不命中**
* CPU是否因**内存、IO**而卡顿
* 什么代码在**分配内存**，分配了**多少**
* 什么触发了**TCP重传**
* 某个内核函数是否**被频繁调用**
* 线程**离开CPU的原因** 

## 2.1. 基本原理

Perf是一个基于内核的子系统，它提供一个**性能分析框架**，它以**性能事件**为基础，基于**对这些事件！！！采样！！！** 进行**性能统计**原理，可用于性能瓶颈的查找与热点代码的定位. 

**采样的周期**以**事件的数量来表示**，而**非基于时间**。当**目标事件计数溢出指定的数值！！！**，则**产生一个采样**。

## 2.2. 功能概述

通过它, 应用程序可以利用 `PMU`, `tracepoint` 和内核中的**特殊计数器**来进行性能统计. 

它不但可以分析指定**应用程序**的性能问题（`per thread`），也可以用来分析**内核**的性能问题, 当然也可以**同时**分析**应用代码**和**内核**，从而全面理解应用程序中的性能瓶颈.

- 要想从剖析中获得更多**内核相关**信息，你需要`符号（Symbol）`和`栈追踪`，这可能需要安装额外的包，甚至使用**特定选项重新编译**你的内核。
- 剖析**用户空间代码**时，也要求目标应用程序的**调试信息（符号表**）被保留。

使用 `perf`, 您可以分析程序运行期间发生的**硬件事件**，比如 `instructions retired` , `processor clock cycles` 等; 您也可以分析**软件事件**, 比如 `Page Fault` 和进程切换。

这使得 `Perf` 拥有了众多的**性能分析能力**, 举例来说，使用 `Perf` 可以计算**每个时钟周期内的指令数**, 称为 `IPC`, `IPC` 偏低表明代码没有很好地利用 `CPU`.

`Perf` 还可以对程序进行**函数级别**的采样, 从而了解程序的性能瓶颈究竟在哪里等等. `Perf` 还可以替代 `strace`, 可以添加动态内核 `probe` 点. 还可以做 `benchmark` 衡量调度器的好坏.

perf利用Linux的**trace特性**，可以用于实时跟踪，统计**event计数**(`perf stat`)；或者使用**采样**(`perf record`)，**报告**(`perf report|script|annotate`)的使用方式进行诊断。

perf命令行接口并不能利用所有的Linux trace特性，有些trace需要通过ftrace接口使用。

对于perf和ftrace的使用见 https://github.com/brendangregg/perf-tools

而Linux有多少性能事件呢?? 下面会说到。

总之perf是一款很牛逼的综合性分析工具，大到系统全局性性能，再小到进程线程级别，甚至到函数及汇编级别。

# 3. 一个简单例子

追踪磁盘I/O:

```
# perf record -e block:block_rq_issue -ag
^C
# ls -l perf.data
-rw------- 1 root root 3458162 Jan 26 03:03 perf.data
# perf report
[...]
# Samples: 2K of event 'block:block_rq_issue'
# Event count (approx.): 2216
#
# Overhead       Command      Shared Object                Symbol
# ........  ............  .................  ....................
#
    32.13%            dd  [kernel.kallsyms]  [k] blk_peek_request
                      |
                      --- blk_peek_request
                          virtblk_request
                          __blk_run_queue
                         |          
                         |--98.31%-- queue_unplugged
                         |          blk_flush_plug_list
                         |          |          
                         |          |--91.00%-- blk_queue_bio
                         |          |          generic_make_request
                         |          |          submit_bio
                         |          |          ext4_io_submit
                         |          |          |          
                         |          |          |--58.71%-- ext4_bio_write_page
                         |          |          |          mpage_da_submit_io
                         |          |          |          mpage_da_map_and_submit
                         |          |          |          write_cache_pages_da
                         |          |          |          ext4_da_writepages
                         |          |          |          do_writepages
                         |          |          |          __filemap_fdatawrite_range
                         |          |          |          filemap_flush
                         |          |          |          ext4_alloc_da_blocks
                         |          |          |          ext4_release_file
                         |          |          |          __fput
                         |          |          |          ____fput
                         |          |          |          task_work_run
                         |          |          |          do_notify_resume
                         |          |          |          int_signal
                         |          |          |          close
                         |          |          |          0x0
                         |          |          |          
                         |          |           --41.29%-- mpage_da_submit_io
[...]
```

这里的`perf record`命令用来追踪`block:block_rq_issue`探针, 当发起**块设备I/O(磁盘io)请求**时候会**触发该探针**.

`-a`选项用于追踪所有CPUs, `-g`用于记录调用栈, 追踪数据保存到了`perf.data`文件.

`perf report`输出显示 2216 次`disk I/O`事件被追踪, 32.13% 负载来自dd命令. 这些命令是由内核函数`blk_peek_request()`发出, 遍历下堆栈信息, 32%负载中的58.71%来自close()系统调用.

# 4. 一行命令

## 4.1. 三种类型命令

Brendan D. Gregg 收集和写了很多一行命令, 按从小到大开销进行划分, 分为三种:

* `statistics/count`: **统计/计数**, 只是事件**计数的增加**
* `sample`: 采样. 对**某几个事件**进行**采样**, 收集**性能数据**(比如**指令指针**`IP`和**堆栈**`stack`), 这就意味着每隔一段时间就会收集一次数据, 所以开销变大
* `trace`: 追踪. 收集**所有事件**的性能数据

## 4.2. Listing Events: 列出事件

```
# Listing all currently known events:
perf list

# Listing sched tracepoints:
perf list 'sched:*'
```

## 4.3. Counting Events: 事件计数

全是`stat`子命令

```
# CPU counter statistics for the specified command:
perf stat command

# Detailed CPU counter statistics (includes extras) for the specified command:
perf stat -d command

# CPU counter statistics for the specified PID, until Ctrl-C:
perf stat -p PID

# CPU counter statistics for the entire system, for 5 seconds:
perf stat -a sleep 5

# Various basic CPU statistics, system wide, for 10 seconds:
perf stat -e cycles,instructions,cache-references,cache-misses,bus-cycles -a sleep 10

# Various CPU level 1 data cache statistics for the specified command:
perf stat -e L1-dcache-loads,L1-dcache-load-misses,L1-dcache-stores command

# Various CPU data TLB statistics for the specified command:
perf stat -e dTLB-loads,dTLB-load-misses,dTLB-prefetch-misses command

# Various CPU last level cache statistics for the specified command:
perf stat -e LLC-loads,LLC-load-misses,LLC-stores,LLC-prefetches command

# Using raw PMC counters, eg, counting unhalted core cycles:
perf stat -e r003c -a sleep 5 

# PMCs: counting cycles and frontend stalls via raw specification:
perf stat -e cycles -e cpu/event=0x0e,umask=0x01,inv,cmask=0x01/ -a sleep 5

# Count syscalls per-second system-wide:
perf stat -e raw_syscalls:sys_enter -I 1000 -a

# Count system calls by type for the specified PID, until Ctrl-C:
perf stat -e 'syscalls:sys_enter_*' -p PID

# Count system calls by type for the entire system, for 5 seconds:
perf stat -e 'syscalls:sys_enter_*' -a sleep 5

# Count scheduler events for the specified PID, until Ctrl-C:
perf stat -e 'sched:*' -p PID

# Count scheduler events for the specified PID, for 10 seconds:
perf stat -e 'sched:*' -p PID sleep 10

# Count ext4 events for the entire system, for 10 seconds:
perf stat -e 'ext4:*' -a sleep 10

# Count block device I/O events for the entire system, for 10 seconds:
perf stat -e 'block:*' -a sleep 10

# Count all vmscan events, printing a report every second:
perf stat -e 'vmscan:*' -a -I 1000
```

## 4.4. Profiling: 采样数据

子命令`record`

子命令top, **动态显示**

```
# Sample on-CPU functions for the specified command, at 99 Hertz:
perf record -F 99 command

# Sample on-CPU functions for the specified PID, at 99 Hertz, until Ctrl-C:
perf record -F 99 -p PID

# Sample on-CPU functions for the specified PID, at 99 Hertz, for 10 seconds:
perf record -F 99 -p PID sleep 10

# Sample CPU stack traces (via frame pointers) for the specified PID, at 99 Hertz, for 10 seconds:
perf record -F 99 -p PID -g -- sleep 10

# Sample CPU stack traces for the PID, using dwarf (dbg info) to unwind stacks, at 99 Hertz, for 10 seconds:
perf record -F 99 -p PID --call-graph dwarf sleep 10

# Sample CPU stack traces for the entire system, at 99 Hertz, for 10 seconds (< Linux 4.11):
perf record -F 99 -ag -- sleep 10

# Sample CPU stack traces for the entire system, at 99 Hertz, for 10 seconds (>= Linux 4.11):
perf record -F 99 -g -- sleep 10

# If the previous command didn't work, try forcing perf to use the cpu-clock event:
perf record -F 99 -e cpu-clock -ag -- sleep 10

# Sample CPU stack traces for a container identified by its /sys/fs/cgroup/perf_event cgroup:
perf record -F 99 -e cpu-clock --cgroup=docker/1d567f4393190204...etc... -a -- sleep 10

# Sample CPU stack traces for the entire system, with dwarf stacks, at 99 Hertz, for 10 seconds:
perf record -F 99 -a --call-graph dwarf sleep 10

# Sample CPU stack traces for the entire system, using last branch record for stacks, ... (>= Linux 4.?):
perf record -F 99 -a --call-graph lbr sleep 10

# Sample CPU stack traces, once every 10,000 Level 1 data cache misses, for 5 seconds:
perf record -e L1-dcache-load-misses -c 10000 -ag -- sleep 5

# Sample CPU stack traces, once every 100 last level cache misses, for 5 seconds:
perf record -e LLC-load-misses -c 100 -ag -- sleep 5 

# Sample on-CPU kernel instructions, for 5 seconds:
perf record -e cycles:k -a -- sleep 5 

# Sample on-CPU user instructions, for 5 seconds:
perf record -e cycles:u -a -- sleep 5 

# Sample on-CPU user instructions precisely (using PEBS), for 5 seconds:
perf record -e cycles:up -a -- sleep 5 

# Perform branch tracing (needs HW support), for 1 second:
perf record -b -a sleep 1

# Sample CPUs at 49 Hertz, and show top addresses and symbols, live (no perf.data file):
perf top -F 49

# Sample CPUs at 49 Hertz, and show top process names and segments, live:
perf top -F 49 -ns comm,dso
```

## 4.5. Static Tracing: 静态跟踪

子命令`record`, 针对具体事件进行**收集**

```
# Trace new processes, until Ctrl-C:
perf record -e sched:sched_process_exec -a

# Sample (take a subset of) context-switches, until Ctrl-C:
perf record -e context-switches -a

# Trace all context-switches, until Ctrl-C:
perf record -e context-switches -c 1 -a

# Include raw settings used (see: man perf_event_open):
perf record -vv -e context-switches -a

# Trace all context-switches via sched tracepoint, until Ctrl-C:
perf record -e sched:sched_switch -a

# Sample context-switches with stack traces, until Ctrl-C:
perf record -e context-switches -ag

# Sample context-switches with stack traces, for 10 seconds:
perf record -e context-switches -ag -- sleep 10

# Sample CS, stack traces, and with timestamps (< Linux 3.17, -T now default):
perf record -e context-switches -ag -T

# Sample CPU migrations, for 10 seconds:
perf record -e migrations -a -- sleep 10

# Trace all connect()s with stack traces (outbound connections), until Ctrl-C:
perf record -e syscalls:sys_enter_connect -ag

# Trace all accepts()s with stack traces (inbound connections), until Ctrl-C:
perf record -e syscalls:sys_enter_accept* -ag

# Trace all block device (disk I/O) requests with stack traces, until Ctrl-C:
perf record -e block:block_rq_insert -ag

# Sample at most 100 block device requests per second, until Ctrl-C:
perf record -F 100 -e block:block_rq_insert -a

# Trace all block device issues and completions (has timestamps), until Ctrl-C:
perf record -e block:block_rq_issue -e block:block_rq_complete -a

# Trace all block completions, of size at least 100 Kbytes, until Ctrl-C:
perf record -e block:block_rq_complete --filter 'nr_sector > 200'

# Trace all block completions, synchronous writes only, until Ctrl-C:
perf record -e block:block_rq_complete --filter 'rwbs == "WS"'

# Trace all block completions, all types of writes, until Ctrl-C:
perf record -e block:block_rq_complete --filter 'rwbs ~ "*W*"'

# Sample minor faults (RSS growth) with stack traces, until Ctrl-C:
perf record -e minor-faults -ag

# Trace all minor faults with stack traces, until Ctrl-C:
perf record -e minor-faults -c 1 -ag

# Sample page faults with stack traces, until Ctrl-C:
perf record -e page-faults -ag

# Trace all ext4 calls, and write to a non-ext4 location, until Ctrl-C:
perf record -e 'ext4:*' -o /tmp/perf.data -a 

# Trace kswapd wakeup events, until Ctrl-C:
perf record -e vmscan:mm_vmscan_wakeup_kswapd -ag

# Add Node.js USDT probes (Linux 4.10+):
perf buildid-cache --add `which node`

# Trace the node http__server__request USDT event (Linux 4.10+):
perf record -e sdt_node:http__server__request -a
```

## 4.6. Dynamic Tracing: 动态追踪

子命令**probe**, 动态

子命令record, 记录**probe事件**

```
# Add a tracepoint for the kernel tcp_sendmsg() function entry ("--add" is optional):
perf probe --add tcp_sendmsg

# Remove the tcp_sendmsg() tracepoint (or use "--del"):
perf probe -d tcp_sendmsg

# Add a tracepoint for the kernel tcp_sendmsg() function return:
perf probe 'tcp_sendmsg%return'

# Show available variables for the kernel tcp_sendmsg() function (needs debuginfo):
perf probe -V tcp_sendmsg

# Show available variables for the kernel tcp_sendmsg() function, plus external vars (needs debuginfo):
perf probe -V tcp_sendmsg --externs

# Show available line probes for tcp_sendmsg() (needs debuginfo):
perf probe -L tcp_sendmsg

# Show available variables for tcp_sendmsg() at line number 81 (needs debuginfo):
perf probe -V tcp_sendmsg:81

# Add a tracepoint for tcp_sendmsg(), with three entry argument registers (platform specific):
perf probe 'tcp_sendmsg %ax %dx %cx'

# Add a tracepoint for tcp_sendmsg(), with an alias ("bytes") for the %cx register (platform specific):
perf probe 'tcp_sendmsg bytes=%cx'

# Trace previously created probe when the bytes (alias) variable is greater than 100:
perf record -e probe:tcp_sendmsg --filter 'bytes > 100'

# Add a tracepoint for tcp_sendmsg() return, and capture the return value:
perf probe 'tcp_sendmsg%return $retval'

# Add a tracepoint for tcp_sendmsg(), and "size" entry argument (reliable, but needs debuginfo):
perf probe 'tcp_sendmsg size'

# Add a tracepoint for tcp_sendmsg(), with size and socket state (needs debuginfo):
perf probe 'tcp_sendmsg size sk->__sk_common.skc_state'

# Tell me how on Earth you would do this, but don't actually do it (needs debuginfo):
perf probe -nv 'tcp_sendmsg size sk->__sk_common.skc_state'

# Trace previous probe when size is non-zero, and state is not TCP_ESTABLISHED(1) (needs debuginfo):
perf record -e probe:tcp_sendmsg --filter 'size > 0 && skc_state != 1' -a

# Add a tracepoint for tcp_sendmsg() line 81 with local variable seglen (needs debuginfo):
perf probe 'tcp_sendmsg:81 seglen'

# Add a tracepoint for do_sys_open() with the filename as a string (needs debuginfo):
perf probe 'do_sys_open filename:string'

# Add a tracepoint for myfunc() return, and include the retval as a string:
perf probe 'myfunc%return +0($retval):string'

# Add a tracepoint for the user-level malloc() function from libc:
perf probe -x /lib64/libc.so.6 malloc

# Add a tracepoint for this user-level static probe (USDT, aka SDT event):
perf probe -x /usr/lib64/libpthread-2.24.so %sdt_libpthread:mutex_entry

# List currently available dynamic probes:
perf probe -l
```

## 4.7. Mixed: 混合使用

```
# Trace system calls by process, showing a summary refreshing every 2 seconds:
perf top -e raw_syscalls:sys_enter -ns comm

# Trace sent network packets by on-CPU process, rolling output (no clear):
stdbuf -oL perf top -e net:net_dev_xmit -ns comm | strings

# Sample stacks at 99 Hertz, and, context switches:
perf record -F 99 -e cpu-clock -e cs -a -g 

# Sample stacks to 2 levels deep, and, context switch stacks to 5 levels (needs 4.8):
perf record -F 99 -e cpu-clock/max-stack=2/ -e cs/max-stack=5/ -a -g 
```

## 4.8. Special: 特定命令

```
# Record cacheline events (Linux 4.10+):
perf c2c record -a -- sleep 10

# Report cacheline events from previous recording (Linux 4.10+):
perf c2c report
```

## 4.9. Reporting: report分析

```
# Show perf.data in an ncurses browser (TUI) if possible:
perf report

# Show perf.data with a column for sample count:
perf report -n

# Show perf.data as a text report, with data coalesced and percentages:
perf report --stdio

# Report, with stacks in folded format: one line per stack (needs 4.4):
perf report --stdio -n -g folded

# List all events from perf.data:
perf script

# List all perf.data events, with data header (newer kernels; was previously default):
perf script --header

# List all perf.data events, with customized fields (< Linux 4.1):
perf script -f time,event,trace

# List all perf.data events, with customized fields (>= Linux 4.1):
perf script -F time,event,trace

# List all perf.data events, with my recommended fields (needs record -a; newer kernels):
perf script --header -F comm,pid,tid,cpu,time,event,ip,sym,dso 

# List all perf.data events, with my recommended fields (needs record -a; older kernels):
perf script -f comm,pid,tid,cpu,time,event,ip,sym,dso

# Dump raw contents from perf.data as hex (for debugging):
perf script -D

# Disassemble and annotate instructions with percentages (needs some debuginfo):
perf annotate --stdio
```

# 5. 演示示例

在Kernel Recipes 2017上，Brendan D. Gregg 分享了关于Linux perf的演讲，重点在CPU分析和火焰图工作。

视频在YouTube: https://www.youtube.com/watch?v=UVM3WX8Lq2k

PPT在: https://www.slideshare.net/brendangregg/kernel-recipes-2017-using-linux-perf-at-netflix

2015年也有个: http://www.brendangregg.com/blog/2015-02-27/linux-profiling-at-netflix.html

# 6. Prerequisites: 先决条件

可以通过安装`perf`包使用perf

也可以在linux tree下自己编译, 具体参照下面`构建`部分

为了充分利用perf，需要**符号表**(symbols)和**堆栈跟踪**(stack traces)。 这些可能在Linux发行版中默认工作，或者它们可能需要添加软件包，或使用其他配置选项重新编译内核。

## 6.1. Symbols: 符号表

没有符号表，**无法**将**内存地址**翻译成**函数**和**变量名**。

例如，无符号表的`perf report`显示如下, 只有16进制地址:

```
    57.14%     sshd  libc-2.15.so        [.] connect           
               |
               --- connect
                  |          
                  |--25.00%-- 0x7ff3c1cddf29
                  |          
                  |--25.00%-- 0x7ff3bfe82761
                  |          0x7ff3bfe82b7c
                  |          
                  |--25.00%-- 0x7ff3bfe82dfc
                   --25.00%-- [...]
```

而安装了`openssh-server-dbgsym`和`libc6-dbgsym`后(这是在ubuntu平台), 有符号表的跟踪显示如下

```
    57.14%     sshd  libc-2.15.so        [.] __GI___connect_internal
               |
               --- __GI___connect_internal
                  |          
                  |--25.00%-- add_one_listen_addr.isra.0
                  |          
                  |--25.00%-- __nscd_get_mapping
                  |          __nscd_get_map_ref
                  |          
                  |--25.00%-- __nscd_open_socket
                   --25.00%-- [...]
```

如何安装符号表?

对于**内核代码**的符号表，
* 可以安装对应的**debuginfo**包. 
* 在编译内核时，使用`CONFIG_KALLSYMS=y`。 

检查如下

```
# cat /boot/config-`uname -r` |grep CONFIG_KALLSYMS
CONFIG_KALLSYMS=y
CONFIG_KALLSYMS_ALL=y
CONFIG_KALLSYMS_EXTRA_PASS=y
```

对于**用户安装软件**的符号表，
* 如果是**yum安装**的，查找debug包(一般是`-dbgsym`结尾(ubuntu), )。
* 如果是用户自己编译的，例如使用**GCC编译**时加上`-g`选项。

## 6.2. JIT符号表(Java, Node.js)

ignore

## 6.3. Stack Traces: 堆栈追踪

应该始终编译带有`frame pointers`. 忽略`frame pointers`是一个不利于debug的编译优化, 但通常是默认的. 

没有`frame pointers`情况下, 可能会看到不完整的堆栈. 有3个方式修复:
* 使用**dwarf数据**unwind(放开)堆栈;
* 使用**上一个分支记录**（last branch record, LBR）（如果可用）（**处理器功能**）;
* 返回帧指针(frame pointer)

还有其他堆栈遍历(stack walking)技术，例如BTS（Branch Trace Store, 分支跟踪存储）和新的ORC展开器(ORC unwinder)。 

### 6.3.1. Frame Pointer: 不让忽略frame pointer

前面的sshd例子是通过默认方式构建的OpenSSH, 默认情况下会使用编译优化(`-O2`), 这个选项会忽略帧指针. 

当通过`-fno-omit-frame-pointer`选项重新编译后:

```
    100.00%     sshd  libc-2.15.so   [.] __GI___connect_internal
               |
               --- __GI___connect_internal
                  |          
                  |--30.00%-- add_one_listen_addr.isra.0
                  |          add_listen_addr
                  |          fill_default_server_options
                  |          main
                  |          __libc_start_main
                  |          
                  |--20.00%-- __nscd_get_mapping
                  |          __nscd_get_map_ref
                  |          
                  |--20.00%-- __nscd_open_socket
                   --30.00%-- [...]
```

对比可以看到, `add_one_listen_addr`的被调函数等.

kernel可能也会遇到这个问题, 下面是一个cpu profile的stack trace(`-g`)例子, 

```
    99.97%  swapper  [kernel.kallsyms]  [k] default_idle
            |
            --- default_idle

     0.03%     sshd  [kernel.kallsyms]  [k] iowrite16   
               |
               --- iowrite16
                   __write_nocancel
                   (nil)
```

kernel的stack trace是不完整的, 而打开`CONFIG_FRAME_POINTER=y`的例子如下:

```
    99.97%  swapper  [kernel.kallsyms]  [k] default_idle
            |
            --- default_idle
                cpu_idle
               |          
               |--87.50%-- start_secondary
               |          
                --12.50%-- rest_init
                          start_kernel
                          x86_64_start_reservations
                          x86_64_start_kernel

     0.03%     sshd  [kernel.kallsyms]  [k] iowrite16
               |
               --- iowrite16
                   vp_notify
                   virtqueue_kick
                   start_xmit
                   dev_hard_start_xmit
                   sch_direct_xmit
                   dev_queue_xmit
                   ip_finish_output
                   ip_output
                   ip_local_out
                   ip_queue_xmit
                   tcp_transmit_skb
                   tcp_write_xmit
                   __tcp_push_pending_frames
                   tcp_sendmsg
                   inet_sendmsg
                   sock_aio_write
                   do_sync_write
                   vfs_write
                   sys_write
                   system_call_fastpath
                   __write_nocancel
```

从`write()`syscall(`__write_nocancel`)到`iowrite16`都可以看到.

### 6.3.2. Dwarf: 用户级释放堆栈

从3.9内核开始，`perf_events`就支持在**用户级堆栈**中**缺少帧指针**的解决方法：`libunwind`，它使用`dwarf`。 

需要在perf编译时包含`libunwind`, 然后在使用perf时通过“`--call-graph dwarf`”（或“ `-g dwarf`”）启用。

参阅“`构建`”部分，以获取有关构建perf_events的其他说明，因为如果没有正确的库，它可能会在没有dwarf支持的情况下自行构建。

### 6.3.3. LBR: 硬件能力

`--call-graph lbr`

lbr如果硬件不支持, 可能会有如下报错

```
# perf record -F 99 -a --call-graph lbr
Error:
PMU Hardware doesn't support sampling/overflow-interrupts.
```

正常可以运行的话, 类似于下面:

```
# perf record -F 99 -a --call-graph lbr
^C[ perf record: Woken up 1 times to write data ]
[ perf record: Captured and wrote 0.903 MB perf.data (163 samples) ]
# perf script
[...]
stackcollapse-p 23867 [007] 4762187.971824:   29003297 cycles:ppp:
                  1430c0 Perl_re_intuit_start (/usr/bin/perl)
                  144118 Perl_regexec_flags (/usr/bin/perl)
                   cfcc9 Perl_pp_match (/usr/bin/perl)
                   cbee3 Perl_runops_standard (/usr/bin/perl)
                   51fb3 perl_run (/usr/bin/perl)
                   2b168 main (/usr/bin/perl)

stackcollapse-p 23867 [007] 4762187.980184:   31532281 cycles:ppp:
                   e3660 Perl_sv_force_normal_flags (/usr/bin/perl)
                  109b86 Perl_leave_scope (/usr/bin/perl)
                  1139db Perl_pp_leave (/usr/bin/perl)
                   cbee3 Perl_runops_standard (/usr/bin/perl)
                   51fb3 perl_run (/usr/bin/perl)
                   2b168 main (/usr/bin/perl)

stackcollapse-p 23867 [007] 4762187.989283:   32341031 cycles:ppp:
                   cfae0 Perl_pp_match (/usr/bin/perl)
                   cbee3 Perl_runops_standard (/usr/bin/perl)
                   51fb3 perl_run (/usr/bin/perl)
                   2b168 main (/usr/bin/perl)
```

注意: LBR通常有**堆栈深度限制**（8帧，16帧或32帧），因此它可能不适合用于深堆栈或火焰图生成，因为火焰图需要遍历到共同的根进行合并。

下面是默认的frame pointer遍历

```
# perf record -F 99 -a -g
^C[ perf record: Woken up 1 times to write data ]
[ perf record: Captured and wrote 0.882 MB perf.data (81 samples) ]
# perf script
[...]
stackcollapse-p 23883 [005] 4762405.747834:   35044916 cycles:ppp:
                  135b83 [unknown] (/usr/bin/perl)

stackcollapse-p 23883 [005] 4762405.757935:   35036297 cycles:ppp:
                   ee67d Perl_sv_gets (/usr/bin/perl)

stackcollapse-p 23883 [005] 4762405.768038:   35045174 cycles:ppp:
                  137334 [unknown] (/usr/bin/perl)
```

你可以
* 以frame pointer方式重新编译perl, 编译选项是`-fno-omit-frame-pointer`;
* 或者lbr选项, 只要不需要深堆栈

### 6.3.4. 小结

(使用`perf record -g`**收集stack traces**)

要跟踪完整的stack，3种办法(其一即可)。

1. perf支持dwarf.
  * 编译perf时候需要包含`libunwind`
  * 使用perf时使用`--call-graph dwarf`或`-g dwarf`
2. 编译时取消frame pointer优化.
  * 编译**应用软件**时必须指定 `-fno-omit-frame-pointer` ，才能跟踪完整的stack trace.
  * **编译内核**时包含 `CONFIG_FRAME_POINTER=y`
3. 硬件支持lbr选项
  * perf使用时带`--call-graph lbr`




总结一下，要愉快的跟踪更完备的信息，就要在**编译软件**时打开符号表的支持(`gcc -g`)，开启**annotate**的支持(`gcc -ggdb`)，以及**Stack trace**的支持(`gcc -fno-omit-frame-pointer`)。

# 7. perf功能概述

perf提供了命令行工具`perf`, 以及**很多子命令**. 这是提供各种事件的不同检测框架的单一接口。

单个perf命令会列出所有的子命令

```
# ./perf

 usage: perf [--version] [--help] [OPTIONS] COMMAND [ARGS]

 The most commonly used perf commands are:
   annotate        Read perf.data (created by perf record) and display annotated code
   archive         Create archive with object files with build-ids found in perf.data file
   bench           General framework for benchmark suites
   buildid-cache   Manage build-id cache.
   buildid-list    List the buildids in a perf.data file
   c2c             Shared Data C2C/HITM Analyzer.
   config          Get and set variables in a configuration file.
   data            Data file related processing
   diff            Read perf.data files and display the differential profile
   evlist          List the event names in a perf.data file
   ftrace          simple wrapper for kernel's ftrace functionality
   inject          Filter to augment the events stream with additional information
   kallsyms        Searches running kernel for symbols
   kmem            Tool to trace/measure kernel memory properties
   kvm             Tool to trace/measure kvm guest os
   list            List all symbolic event types
   lock            Analyze lock events
   mem             Profile memory accesses
   record          Run a command and record its profile into perf.data
   report          Read perf.data (created by perf record) and display the profile
   sched           Tool to trace/measure scheduler properties (latencies)
   script          Read perf.data (created by perf record) and display trace output
   stat            Run a command and gather performance counter statistics
   test            Runs sanity tests.
   timechart       Tool to visualize total system behavior during a workload
   top             System profiling tool.
   version         display the version of perf binary
   probe           Define new dynamic tracepoints
   trace           strace inspired tool

 See 'perf help COMMAND' for more information on a specific command.
```

No.|sub-commands|comment
:------:|:------:|:------
01 | annotate      |根据数据文件（perf.data），注解被采样到的函数，显示指令级别的热点。
02 | archive       |根据数据文件中记录的build-id，将所有被采样到的ELF文件打成压缩包。利用此压缩包，可以在任何机器上分析数据文件中的采样数据。
03 | bench         |Perf中内置的benchmark，目前包括两套针对调度器和内存管理子系统的benchmark。
04 | buildid-cache |管理perf的buildid缓存。每个ELF文件都有一个独一无二的buildid。Buildid被perf用来关联性能数据与ELF文件。
05 | buildid-list  |列出数据文件中记录的所有buildid。
06 | config        |从配置文件中设置读取变量。
07 | data          |数据文件的相关处理。
08 | diff          |对比两个数据文件的差异。能够给出每个符号（函数）在热点分析上的具体差异。
09 | evlist        |列出数据文件中的所有性能事件。
10 | ftrace        |调用ftrace功能。
11 | inject        |该工具读取perf record工具记录的事件流，并将其定向到标准输出。在被分析代码中的任何一点，都可以向事件流中注入其他事件。
12 | kallsyms      |查询运行内核的符号信息。
13 | kmem          |针对内存子系统的分析工具。
14 | kvm           |此工具可以用来追踪、测试运行与KVM虚拟机上的Guest OS。
15 | list          |列出当前系统支持的所有性能事件。包括硬件性能事件、软件性能事件以及检查点。
16 | lock          |分析内核中的加锁信息。包括锁的争用情况，等待延迟等。
17 | mem           |剖析内存访问信息。
18 | record        |收集采样信息，并将其记录在数据文件中。随后可通过其他工具对数据文件进行分析。
19 | report        |读取perf record创建的数据文件，并给出热点分析结果。
20 | sched         |针对调度器子系统的分析工具。
21 | script        |执行perl或python写的功能扩展脚本、生成脚本框架、读取数据文件中的数据信息等。
22 | stat          |剖析某个特定进程的性能概况，包括CPU、Cache Miss率等。
23 | test          |Perf针对当前软硬平台的测试工具。可以用此工具测试当前软硬件平台是否能够支持perf的所有功能。
24 | timechart     |生成一幅描述处理器与各进程状态变化的矢量图。
25 | top           |类似于Linux的top命令，对系统性能进行实时分析。
26 | probe         |用于定义动态检查点。
27 | trace         |类似strace功能。

除了**每个子命令的单独帮助**(`./perf --help sub_command`)外，内核源代码中的`tools/perf/Documentation`下也有文档。

Perf是一个包含很多种子工具的多功能工具集，功能很全面。

## 7.1. 全局性概况

* perf list: 查看当前系统支持的性能事件；
* perf bench: 对系统性能进行摸底；
* perf test: 对系统进行健全性测试；
* perf stat: 对全局性能进行统计；

## 7.2. 全局细节

* perf top: 实时查看当前**系统进程函数占用率**情况；
* perf probe: **自定义动态事件**；

## 7.3. 特定功能分析

有许多子命令提供特殊用途的功能。这些包括：

* perf c2c: `cache-2-cache`和cacheline错误共享分析
* perf kmem: 针对slab子系统性能分析；
* perf kvm: 针对kvm虚拟化分析；
* perf lock: 分析锁性能；
* perf mem: 分析内存slab性能；
* perf sched: 分析内核调度器性能, 见下面`示例中的Scheduler Analysis(调度器分析)`；
* perf trace: 记录系统调用轨迹；

## 7.4. perf record

最常用功能perf record，可以系统全局，也可以具体到**某个进程**，更甚具体到**某一进程某一事件**; 可宏观，也可以很微观。

* pref record: 记录信息到`perf.data`；
* perf report: 生成报告；
* perf diff: 对两个记录进行diff；
* perf evlist: 列出记录的性能事件；
* perf annotate: 显示perf.data函数代码；
* perf archive: 将相关符号打包，方便在其它机器进行分析；
* perf script: 将perf.data输出可读性文本；

`perf annotate`能够提供**源码信息**, 不过需要在应用编译的时候带有`-ggdb`.

## 7.5. 可视化工具perf timechart

* perf timechart record记录事件；
* perf timechart生成output.svg文档；

## 7.6. 3种使用方式和性能分析的3个过程

perf工具可以分为**三种方式**：

* `counting`(**计数**): 在**内核上下文**中对**事件**进行**计数**，其中perf打印计数摘要。 此模式**不会生成perf.data文件**。
* `sampling`(**采样**): 采样事件，将**事件数据**写入**内核缓冲区**，perf命令以柔和的异步速率读取事件数据，以写入`perf.data`文件。 然后，perf report或perf script命令将**读取此文件**。
* `bpf`(**动态插入自定义程序**): 事件的**bpf程序**，这是Linux 4.4+内核中的一项新功能，可以在**内核空间**中执行**自定义的用户定义程序**，从而可以执行高效的数据过滤和汇总。 例如，有效测量的时间延迟直方图。

而这也对应了性能分析的三个过程: 

1. 先尝试从**事件计数**开始, 使用`perf stat`命令，看是否足够。该子命令**开销最少**。
2. 再是**采样模式**, 使用`perf record`命令，需要对开销稍加注意，因为捕获文件会迅速变为数百兆字节。 这取决于**跟踪的事件的速率**：频率越高，开销越高，`perf.data`数据大小也越大。
3. 要真正**减少开销**并生成更多**高级摘要**，需要编写由perf执行的**BPF程序**。 请参阅下面`eBPF`部分。

## 7.7. 使用示例

选择这些例子是为了说明perf的**不同使用方式**, 从收集到报告, 详细的看下面的示例.

1. **gzip命令**的**性能计数**摘要，包括IPC(instructions per cycle, 每个周期的指令数)等：

```
# perf stat gzip XXX
```

```
# perf stat gzip centos.qcow2

 Performance counter stats for 'gzip centos.qcow2':

         80,777.53 msec task-clock                #    1.000 CPUs utilized
               157      context-switches          #    0.002 K/sec
                20      cpu-migrations            #    0.000 K/sec
               141      page-faults               #    0.002 K/sec
   249,822,322,306      cycles                    #    3.093 GHz
   360,334,876,460      instructions              #    1.44  insn per cycle
    71,652,946,820      branches                  #  887.041 M/sec
     2,931,602,779      branch-misses             #    4.09% of all branches

      80.781238213 seconds time elapsed

      79.914249000 seconds user
       0.863981000 seconds sys
```

2. 统计(count)5秒的**所有调度程序进程事件**，按**tracepoint计数**：

```
# perf stat -e 'sched:sched_process_*' -a sleep 5
```

```
# perf stat -e 'sched:sched_process_*' -a sleep 5

 Performance counter stats for 'system wide':

                10      sched:sched_process_free
                11      sched:sched_process_exit
                15      sched:sched_process_wait
                10      sched:sched_process_fork
                 5      sched:sched_process_exec
                 0      sched:sched_process_hang

       5.001998189 seconds time elapsed
```

3. **跟踪**(`trace`)5秒的**所有调度程序进程事件**，按**tracepoint**和**进程名称**：

```
# perf record -e 'sched:sched_process_*' -a sleep 5
# perf report
```

```
# perf record -e 'sched:sched_process_*' -a sleep 5
Couldn't synthesize bpf events.
Couldn't synthesize cgroup events.
[ perf record: Woken up 1 times to write data ]
[ perf record: Captured and wrote 0.341 MB perf.data (51 samples) ]

# perf report
```

4. **跟踪**(`trace`)5秒的**所有调度程序进程事件**，并且**dump详细信息**：

```
# perf record -e 'sched:sched_process_*' -a sleep 5
# perf script
```

```
# perf record -e 'sched:sched_process_*' -a sleep 5
Couldn't synthesize bpf events.
Couldn't synthesize cgroup events.
[ perf record: Woken up 1 times to write data ]
[ perf record: Captured and wrote 0.341 MB perf.data (51 samples) ]

# perf script
           sleep 12110 [049]  1440.744947: sched:sched_process_exec: filename=/usr/bin/sleep pid=12110 old_pid=12110
           httpd  3404 [048]  1440.775205: sched:sched_process_wait: comm=httpd pid=0 prio=120
         systemd     1 [049]  1441.176507: sched:sched_process_fork: comm=systemd pid=1 child_comm=systemd child_pid=12112
         systemd 12112 [000]  1441.176528: sched:sched_process_exit: comm=systemd pid=12112 prio=120
         swapper     0 [000]  1441.191201: sched:sched_process_free: comm=systemd pid=12112 prio=120
           httpd  3404 [048]  1441.776216: sched:sched_process_wait: comm=httpd pid=0 prio=120
           sleep 12105 [048]  1442.096322: sched:sched_process_exit: comm=sleep pid=12105 prio=120
 safe_TsysAgent.  4052 [001]  1442.096353: sched:sched_process_wait: comm=safe_TsysAgent. pid=0 prio=120
 safe_TsysAgent.  4052 [001]  1442.096483: sched:sched_process_fork: comm=safe_TsysAgent. pid=4052 child_comm=safe_TsysAgent. child_pid=12113
 ......
```

5. **跟踪**(`trace`)`read()`系统调用, 并且请求的bytes小于10:

```
# perf record -e 'syscalls:sys_enter_read' --filter 'count < 10' -a
```

```
# perf record -e 'syscalls:sys_enter_read' --filter 'count < 10' -a
Couldn't synthesize bpf events.
Couldn't synthesize cgroup events.
^C[ perf record: Woken up 1 times to write data ]
[ perf record: Captured and wrote 0.534 MB perf.data (133 samples) ]
```

6. **采样**(sample)CPU**堆栈**, 以 99 Hertz, 持续5秒:

```
# perf record -F 99 -ag -- sleep 5
# perf report
```

```
# perf record -F 99 -ag -- sleep 5

# perf report
```

7. **动态**检测内核`tcp_sendmsg()`函数，并**跟踪堆栈**, 持续5秒钟：

```
# perf probe --add tcp_sendmsg
# perf record -e probe:tcp_sendmsg -ag -- sleep 5
# perf probe --del tcp_sendmsg
# perf report
```

```
# ./perf probe --add tcp_sendmsg
Added new event:
  probe:tcp_sendmsg    (on tcp_sendmsg)

You can now use it in all perf tools, such as:

	perf record -e probe:tcp_sendmsg -aR sleep 1

# ./perf record -e probe:tcp_sendmsg -ag -- sleep 5
Couldn't synthesize bpf events.
Couldn't synthesize cgroup events.
[ perf record: Woken up 1 times to write data ]
[ perf record: Captured and wrote 0.333 MB perf.data (4 samples) ]

# ./perf probe --del tcp_sendmsg
Removed event: probe:tcp_sendmsg

# ./perf report
```

# 8. Perf 性能事件

利用perf剖析程序性能时，需要指定**当前测试**的**性能事件**。

性能事件在不同系统中是不同的。如果一些事件会对程序的执行时间造成较大的负面影响, 在优化代码时，应尽可能减少此类事件发生。

因此，必须先利用perf等性能剖析工具查找**引发这些性能事件**的**热点代码**以及**热点指令**。

![2020-07-20-09-42-57.png](./images/2020-07-20-09-42-57.png)

>这个图来自: http://www.brendangregg.com/perf.html#SCALE13x

这张图大致列出了perf支持的跟踪事件源.

## 8.1. 六种类型事件

分为六种类型的事件:

* **硬件事件**(`Hardware Events`): CPU性能监控计数(CPU performance monitoring counters)**硬件计数器**. 计数.
* **软件事件**(`Software Events`): 这些是基于**内核计数器**的低级事件. 比如, CPU迁移、次要故障和主要故障等等. 计数.
* **内核态tracepoint事件**(`Kernel Tracepoint Events`): 这些是内核中的**静态检测点**, 是在内核合适位置**硬编码**进去的. 硬编码.
* **用户静态定义追踪**(`User Statically-Defined Tracing`, USDT): 这些是用户态程序中的静态tracepoint. 硬编码.
* **动态追踪**(`Dynamic Tracing`): 可以在软件的**任何位置**创建事件, 从而可以被动态检测. **动态编码**.
  * 对于**内核态**来说, 利用了`kprobes`框架;
  * 对于**用户态**程序, 使用了`uprobes`.
* **定时间隔性能分析**(`Timed Profiling`): 使用`perf record -F Hz`, 能够以**任意频率**收集快照(**指令指针IP**或**堆栈跟踪Stack Trace**), 工作机制是**定期引发中断**. 这通常用于**CPU使用情况**分析(), 所以又称CPU Profiling. 具体见下面. 

## 8.2. perf list查看所有性能事件

**不同型号的CPU**支持的**硬件性能事件**不尽相同。**不同版本的内核**提供的**软件性能事件**与 **Tracepoint events** 也不尽相同。

因此，perf提供了list子命令以查看当前软硬件平台支持的性能事件列表。

使用方法如下：

```
# ./perf list -h

 Usage: perf list [<options>] [hw|sw|cache|tracepoint|pmu|sdt|event_glob]

    -d, --desc            Print extra event descriptions. --no-desc to not print.
    -v, --long-desc       Print longer event descriptions.
        --debug           Enable debugging output
        --deprecated      Print deprecated events.
        --details         Print information on the perf event names and expressions used internally by events.
```

执行命令后，perf将给出当前软硬件平台的所有性能事件。输出结果如下图所示。每行后面括弧里的信息表示该事件是**硬件事件**、**软件事件**还是`Tracepoint events`。

```
# perf list
List of pre-defined events (to be used in -e):
  cpu-cycles OR cycles                               [Hardware event]
  instructions                                       [Hardware event]
  cache-references                                   [Hardware event]
  cache-misses                                       [Hardware event]
  branch-instructions OR branches                    [Hardware event]
  branch-misses                                      [Hardware event]
  bus-cycles                                         [Hardware event]
  stalled-cycles-frontend OR idle-cycles-frontend    [Hardware event]
  stalled-cycles-backend OR idle-cycles-backend      [Hardware event]
  ref-cycles                                         [Hardware event]
  cpu-clock                                          [Software event]
  task-clock                                         [Software event]
  page-faults OR faults                              [Software event]
  context-switches OR cs                             [Software event]
  cpu-migrations OR migrations                       [Software event]
  minor-faults                                       [Software event]
  major-faults                                       [Software event]
  alignment-faults                                   [Software event]
  emulation-faults                                   [Software event]
  L1-dcache-loads                                    [Hardware cache event]
  L1-dcache-load-misses                              [Hardware cache event]
  L1-dcache-stores                                   [Hardware cache event]
[...]
  rNNN                                               [Raw hardware event descriptor]
  cpu/t1=v1[,t2=v2,t3 ...]/modifier                  [Raw hardware event descriptor]
   (see 'man perf-list' on how to encode it)
  mem:<addr>[:access]                                [Hardware breakpoint]
  probe:tcp_sendmsg                                  [Tracepoint event]
[...]
  sched:sched_process_exec                           [Tracepoint event]
  sched:sched_process_fork                           [Tracepoint event]
  sched:sched_process_wait                           [Tracepoint event]
  sched:sched_wait_task                              [Tracepoint event]
  sched:sched_process_exit                           [Tracepoint event]
[...]
# perf list | wc -l
     657
```

当使用**动态跟踪**，将**扩展此列表**。 此列表中的`probe:tcp_sendmsg`跟踪点是一个示例，我通过检测`tcp_sendmsg()`添加了该示例。 

## 8.3. Hardware Events(PMCs): 硬件性能事件(PMCs)

由**PMU部件产生**，在特定的条件下探测性能事件**是否发生**以及发生的**次数**。比如**cache命中**。

来自CPU自己或CPU的PMU（`Performance Monitoring Unit`，性能监控单元）硬件计数，包含一系列**微架构事件**例如时钟周期、L1缓存丢失等。具体支持的事件类型取决于CPU型号.

完整的性能事件列表见Intel手册`Performance Monitoring Events`

一个典型CPU将以下面方式实现PMCs: 在同一时间只能从成千上万的可用PMCs中记录几个. 因为CPU上的硬件资源是固定的(寄存器数量有限), 通过编程这些寄存器对已选的事件进行计数.

使用PMCs的例子, 可以见下面示例中的 `CPU Statistics(CPU静态统计)`

## 8.4. Software Events: 软件性能事件

- Software Event是**内核！！！产生的事件/计数器**，分布在**各个功能模块**中，统计和**操作系统相关性能事件**。比如**进程切换**，等。

基于**内核计数器！！！** 的低级事件，例如**CPU迁移**、**tick数**、**上下文切换**、**Minor Faults**、**Major Faults**（页面错误）

perf提供了一些**固定的软件事件**:

```
# ./perf list
List of pre-defined events (to be used in -e):
...
  alignment-faults                                   [Software event]
  bpf-output                                         [Software event]
  context-switches OR cs                             [Software event]
  cpu-clock                                          [Software event]
  cpu-migrations OR migrations                       [Software event]
  dummy                                              [Software event]
  emulation-faults                                   [Software event]
  major-faults                                       [Software event]
  minor-faults                                       [Software event]
  page-faults OR faults                              [Software event]
  task-clock                                         [Software event]
...
```

通过`man perf_event_open(2)`也能看到, type是`PERF_TYPE_SOFTWARE`

```
              If type is PERF_TYPE_SOFTWARE, we are measuring software events provided by the kernel.  Set config to one of the following:

                   PERF_COUNT_SW_CPU_CLOCK
                          This reports the CPU clock, a high-resolution per-CPU timer.

                   PERF_COUNT_SW_TASK_CLOCK
                          This reports a clock count specific to the task that is running.

                   PERF_COUNT_SW_PAGE_FAULTS
                          This reports the number of page faults.

                   PERF_COUNT_SW_CONTEXT_SWITCHES
                          This counts context switches.  Until Linux 2.6.34, these were all reported as user-space events, after that they are reported as
                          happening in the kernel.

                   PERF_COUNT_SW_CPU_MIGRATIONS
                          This reports the number of times the process has migrated to a new CPU.

                   PERF_COUNT_SW_PAGE_FAULTS_MIN
                          This counts the number of minor page faults.  These did not require disk I/O to handle.

                   PERF_COUNT_SW_PAGE_FAULTS_MAJ
                          This counts the number of major page faults.  These required disk I/O to handle.

                   PERF_COUNT_SW_ALIGNMENT_FAULTS (Since Linux 2.6.33)
                          This counts the number of alignment faults.  These happen when unaligned memory accesses happen; the kernel can handle these but
                          it reduces performance.  This happens only on some architectures (never on x86).

                   PERF_COUNT_SW_EMULATION_FAULTS (Since Linux 2.6.33)
                          This counts the number of emulation faults.  The kernel sometimes traps on unimplemented instructions and emulates them for user
                          space.  This can negatively impact performance.
...
```

内核也支持`tracepoints`, 和软件事件类似, 但是内核tracepoints有不同的扩展性更强的API.

### 8.4.1. 采样周期

**软件事件**有**默认的周期**. 这意味着当对软件事件采样时, 采样的是事件的**一部分子集**, 而**不是中间经历的每一次事件**. 通过`perf record -vv`可以查看

```
./perf record -vv -e context-switches /bin/true
Using CPUID GenuineIntel-6-55-7
intel_pt default config: tsc,mtc,mtc_period=3,psb_period=3,pt,branch
nr_cblocks: 0
affinity: SYS
mmap flush: 1
comp level: 0
------------------------------------------------------------
perf_event_attr:
  type                             1
  size                             120
  config                           0x3
  { sample_period, sample_freq }   4000
  sample_type                      IP|TID|TIME|PERIOD
  read_format                      ID
  disabled                         1
  inherit                          1
  mmap                             1
  comm                             1
  freq                             1
  enable_on_exec                   1
...
```

注意: `{ sample_period, sample_freq }`

通过`man perf_event_open(2)`查看这几个属性的描述. **默认情况**下, 这些**属性**表明内核**调整采样频率**, 从而**每秒**捕获 **4000** 个`context-switch`事件. 

如果打算record中间经历的所有事件, 使用`-c 1`, 表明每发生一次`context-switches`便收集一次stack trace信息:

```
./perf record -vv -e context-switches -c 1 /bin/true
Using CPUID GenuineIntel-6-55-7
intel_pt default config: tsc,mtc,mtc_period=3,psb_period=3,pt,branch
nr_cblocks: 0
affinity: SYS
mmap flush: 1
comp level: 0
------------------------------------------------------------
perf_event_attr:
  type                             1
  size                             120
  config                           0x3
  { sample_period, sample_freq }   1
  sample_type                      IP|TID|TIME
  read_format                      ID
  disabled                         1
  inherit                          1
  mmap                             1
  comm                             1
  enable_on_exec                   1
------------------------------------------------------------
...
```

注意: `{ sample_period, sample_freq }`

首先使用`perf stat`检查事件**发生率**，以便您可以估计要捕获的**数据量**。 默认情况下对**子集**进行采样可能是一件好事，尤其是对于诸如上下文切换之类的高频事件。

无论如何，许多其他事件（例如跟踪点）的默认值为1。 您会在许多软件和硬件事件中遇到非1的默认值。

## 8.5. Kernel Tracepoints: 内核态静态tracepoints

- Tracepoint Event是内核中**静态tracepoint所触发的事件**，是**硬编码**进内核中的, 可以用来判断程序运行期间内核的行为细节（这些tracepint的对应的sysfs节点在`/sys/kernel/debug/tracing/events`目录下）。比如systemcalls、TCP events、file system I/O、disk I/O、slab分配器的分配次数等。

tracepoints有个关键的点是要有稳定的API(事件名字和参数), 当写代码能使用它们, 并且在后续的版本中持续支持.

kernel tracepoints在内核代码中实现通常是宏定义在`include/trace/events/*.XXX`.

### 8.5.1. tracepoints分组

内核态tracepoints**被分组**, 比如, "`sock:`"表明是**socket事件**, "`sched:`"表明是**CPU调度事件**.

查看内核中分组的名字和数量:

```
./perf list | awk -F: '/Tracepoint event/ { lib[$1]++ } END { for (l in lib) { printf "  %-16.16s %d\n", l, lib[l] } }' | sort | column
```

```
# ./perf list | awk -F: '/Tracepoint event/ { lib[$1]++ } END { for (l in lib) { printf "  %-16.16s %d\n", l, lib[l] } }' | sort | column
    alarmtimer     4	    kmem           13	    raw_syscalls   2
    block          18	    kvm            76	    rcu            1
    bridge         4	    kvmmmu         16	    rpcgss         21
    cgroup         13	    kyber          3	    rpm            5
    clk            16	    libata         6	    rseq           2
    compaction     14	    mce            1	    rtc            12
    context_tracki 2	    mdio           1	    sched          24
    cpuhp          3	    migrate        1	    scsi           5
    devfreq        1	    mlx5           9	    signal         2
    devlink        5	    mmap           1	    skb            3
    dma_fence      7	    module         5	    sock           3
    exceptions     2	    msr            3	    sunrpc         109
    ext4           105	    napi           1	    swiotlb        1
    fib            1	    nbd            5	    syscalls       662
    fib6           1	    neigh          7	    task           2
    filelock       12	    net            18	    tcp            7
    filemap        4	    nfsd           64	    thermal        3
    ftrace         2	    nmi            1	    timer          13
    huge_memory    4	    nvme           4	    tlb            1
    hwmon          3	    oom            8	    udp            1
    initcall       3	    page_isolation 1	    ufs            13
    intel_iommu    7	    page_pool      4	    vmscan         18
    io_uring       14	    pagemap        2	    vsyscall       1
    iomap          8	    percpu         5	    workqueue      4
    iommu          7	    power          22	    writeback      34
    irq            5	    printk         1	    x86_fpu        11
    irq_matrix     12	    qdisc          4	    xdp            12
    irq_vectors    34	    qla            1	    xhci-hcd       53
    iscsi          7	    random         15
    jbd2           17	    ras            5
```

这些包括:

* block: 块设备I/O
* ext4: ext4文件系统操作
* kmem: 内核内存分配
* random: 随机数生成
* sched: CPU调度
* syscalls: 系统调用进入和退出
* task: 任务

每当kernel更新后, 检查一下tracepoint列表都是很有必要的. 添加它们的价值不时在争论中，它想知道会有多少人使用它们（我愿意）。 

关于使用这些tracepoints的例子, 见下面示例的`Static Kernel Tracing(内核静态追踪)`

## 8.6. User-Level Statically Defined Tracing (USDT): 用户态静态tracepoint

和kernel tracepoints类似, USDT是在**用户态**应用中**硬编码**的, 对外表现就是稳定的API(事件名字和参数).

目前, 很多应用程序已经开始包含了tracepoints, 用来支持[DTrace](http://www.brendangregg.com/dtrace.html). 但是, 多数应用默认情况下并不会默认编译. 通常编译时候需要使用参数`--with-dtrace`.

例如, `Node.js`编译支持

```
$ sudo apt-get install systemtap-sdt-dev       # adds "dtrace", used by node build
$ wget https://nodejs.org/dist/v4.4.1/node-v4.4.1.tar.gz
$ tar xvf node-v4.4.1.tar.gz 
$ cd node-v4.4.1
$ ./configure --with-dtrace
$ make -j 8
```

检查编译结果是否含有probes.

![2020-07-27-14-25-03.png](./images/2020-07-27-14-25-03.png)

关于USDT使用的例子, 见下面`Static User Tracing(用户态静态追踪)`.

## 8.7. Dynamic Tracing: 动态追踪

静态tracepoints和动态tracing动态追踪的不同在于下图, 说明了一个通用tracepoint的覆盖范围:

![2020-07-27-14-31-43.png](./images/2020-07-27-14-31-43.png)

The overhead while dynamic tracing is in use, and extra instructions are being executed, is relative to the frequency of instrumented events multiplied by the work done on each instrumentation.


虽然动态跟踪可以看到**所有东西**，但它也是一个**不稳定的接口**，因为它**检测原始代码**。这意味着在**内核补丁**或**更新**之后，您开发的任何**动态跟踪工具**都**可能崩溃**。所以**首先**尝试使用**静态跟踪点**，因为它们的接口应该更加稳定。它们也更容易使用和理解，因为在设计时考虑了跟踪最终用户。

动态跟踪的一个好处是可以在**正在运行的系统**上启用它，而**不需要重新启动任何东西**。您可以使用一个已经运行的内核或应用程序，然后开始**动态插装**，这将(安全地)**对内存中的指令**进行打补丁，以添加插装。这意味着在开始**使用该特性之前**，它没有任何开销或税收。前一刻二进制文件还在全速运行，而下一刻，它又在运行一些动态添加的额外插装指令。一旦您完成了动态跟踪会话的使用，这些指令最终应该被删除。

使用动态跟踪和执行额外指令时的开销相对于检测事件的频率乘以在每个检测上完成的工作。

使用动态追踪的例子, 见`Dynamic Tracing(动态追踪)`



要启用内核动态追踪，需要使用内核编译参数`CONFIG_KPROBES=y`、`CONFIG_KPROBE_EVENTS=y`。

要启用**用户动态追踪**，需要使用内核编译参数`CONFIG_UPROBES=y`、`CONFIG_UPROBE_EVENTS=y`



# 9. 示例(性能分析分类)

这也对应性能分析的几种情况

## 9.1. CPU Statistics: CPU静态统计

`perf stat`命令汇总了**CPU事件**(PMCs).

```
# perf stat gzip file1

 Performance counter stats for 'gzip file1':

       1920.159821 task-clock                #    0.991 CPUs utilized          
                13 context-switches          #    0.007 K/sec                  
                 0 CPU-migrations            #    0.000 K/sec                  
               258 page-faults               #    0.134 K/sec                  
     5,649,595,479 cycles                    #    2.942 GHz                     [83.43%]
     1,808,339,931 stalled-cycles-frontend   #   32.01% frontend cycles idle    [83.54%]
     1,171,884,577 stalled-cycles-backend    #   20.74% backend  cycles idle    [66.77%]
     8,625,207,199 instructions              #    1.53  insns per cycle        
                                             #    0.21  stalled cycles per insn [83.51%]
     1,488,797,176 branches                  #  775.351 M/sec                   [82.58%]
        53,395,139 branch-misses             #    3.59% of all branches         [83.78%]

       1.936842598 seconds time elapsed
```

其中:
* `task-clock`(用于执行程序的CPU时间)
* `context-switches`(程序在运行过程中发生的上下文切换次数)
* `cpu-migrations`(程序在运行过程中发生的CPU迁移次数，即被调度器从一个CPU转移到另外一个CPU上运行)
* `page-faults`(缺页)
* `cycles`(CPU时钟周期)
* `instructions`(该进程在这段时间内完成的CPU指令)
* `branches`(这段时间内发生分支预测的次数)
* `branch-misses`(这段时间内分支预测失败的次数)

这包括每个时钟周期执行的指令数(instructions per cycle, IPC)，标记为“insns per cycle”或早期版本的“IPC”。**IPC**或其反转**CPI**常用的**度量标准**。 **较高的IPC**值表示**较高的指令吞吐量**，而较低的值表示**更多的停顿周期**。 

通常认为高IPC值（例如，超过1.0）是好的，这表明可以对工作进行最佳处理。 但是，需要仔细检查一下**指令是什么**，以防这是由于**旋转循环造成**的：**指令率高**，但**实际工作率低**。

`perf stat`现在包括一些**高级指标**：`frontend cycles idle`(**前端周期空闲**)，`backend cycles idle`(**后端周期空闲**)和`stalled cycles per insn`(**每个insn的停顿周期**)。要真正理解这些内容，您需要一些CPU微体系结构的知识。

### 9.1.1. CPU 微架构

### 9.1.2. Detailed Mode: 详细模式

`perf stat`有一个**Detailed Mode**, 通过`-d`选项:

```
# perf stat -d gzip file1

 Performance counter stats for 'gzip file1':

       1610.719530 task-clock                #    0.998 CPUs utilized          
                20 context-switches          #    0.012 K/sec                  
                 0 CPU-migrations            #    0.000 K/sec                  
               258 page-faults               #    0.160 K/sec                  
     5,491,605,997 cycles                    #    3.409 GHz                     [40.18%]
     1,654,551,151 stalled-cycles-frontend   #   30.13% frontend cycles idle    [40.80%]
     1,025,280,350 stalled-cycles-backend    #   18.67% backend  cycles idle    [40.34%]
     8,644,643,951 instructions              #    1.57  insns per cycle        
                                             #    0.19  stalled cycles per insn [50.89%]
     1,492,911,665 branches                  #  926.860 M/sec                   [50.69%]
        53,471,580 branch-misses             #    3.58% of all branches         [51.21%]
     1,938,889,736 L1-dcache-loads           # 1203.741 M/sec                   [49.68%]
       154,380,395 L1-dcache-load-misses     #    7.96% of all L1-dcache hits   [49.66%]
                 0 LLC-loads                 #    0.000 K/sec                   [39.27%]
                 0 LLC-load-misses           #    0.00% of all LL-cache hits    [39.61%]

       1.614165346 seconds time elapsed
```

这个额外包含了`L1 data cache`(L1 数据缓存)和**LLC**(last level cache, 最后一级缓存)事件.

### 9.1.3. Specific Counters: 具体计数器

**硬件cache事件计数器**, 可以通过`perf list`查看:

```
# perf list | grep L1-dcache
  L1-dcache-loads                                    [Hardware cache event]
  L1-dcache-load-misses                              [Hardware cache event]
  L1-dcache-stores                                   [Hardware cache event]
  L1-dcache-store-misses                             [Hardware cache event]
  L1-dcache-prefetches                               [Hardware cache event]
  L1-dcache-prefetch-misses                          [Hardware cache event]

# perf stat -e L1-dcache-loads,L1-dcache-load-misses,L1-dcache-stores gzip file1

 Performance counter stats for 'gzip file1':

     1,947,551,657 L1-dcache-loads
                                            
       153,829,652 L1-dcache-misses     #    7.90% of all L1-dcache hits
     1,171,475,286 L1-dcache-stores
                                           

       1.538038091 seconds time elapsed
```

基于指定的计数器，打印的百分比是perf的便捷计算。如果包括“**cycle周期**”和“**instructions指令**”计数器，则在输出中将包括IPC计算。

可以测量的这些硬件事件通常特定于**处理器模型**。 在**虚拟化环境**中，许多可能不可用。

### 9.1.4. Raw Counters: 处理器支持的原始计数器

`Intel 64 and IA-32 Architectures Software Developer's Manual Volume 3B: System Programming Guide` 和 `BIOS and Kernel Developer's Guide (BKDG) For AMD Family 10h Processors`中描述了所有的计数器, 但是大多数没有在`perf list`中.

如果找到要检测的事件，则可以将其指定为**原始事件**，其格式为：`rUUEE`，其中`UU==umask`，而`EE==事件号`。 

在以下示例中，我添加了几个原始计数器：

```
# perf stat -e cycles,instructions,r80a2,r2b1 gzip file1

 Performance counter stats for 'gzip file1':

     5,586,963,328 cycles                    #    0.000 GHz                    
     8,608,237,932 instructions              #    1.54  insns per cycle        
         9,448,159 raw 0x80a2                                                  
    11,855,777,803 raw 0x2b1                                                   

       1.588618969 seconds time elapsed
```

`r80a2`已检测到`RESOURCE_STALLS.OTHER`，而`r2b1`已检测到`UOPS_DISPATCHED.CORE`：每个周期分配的**uops**数量。

如果您确实找到了一个很好的原始计数器，请建议将其作为别名添加到perf中，这样我们大家都可以在perf列表中找到它。

### 9.1.5. Other Options: 其他选项

perf的子命令, 尤其`stat`, 有很多可扩展的选项, 通过`perf stat -h`可以看到.

其中`--repeat`, `--sync`, `--pre`和`--post`等在自动化测试或benchmark中很有效.

## 9.2. Timed Profiling(CPU Profiling): 定时间隔性能分析

很多也称为**CPU Profiling**, 因为其实就是对CPU的执行情况的分析

定时间隔性能分析: perf可以基于以**固定间隔**对**instruction pointer(IP, 指令指针！！！**) 或**stack trace(堆栈跟踪！！！**) 进行**sampling(采样**)来分析**CPU使用情况！！！**。

### 9.2.1. sampling: 采样

以**99Hz**(`-F 99`)对整个系统(`-a`, 表明所有CPU), 带着堆栈信息(`-g`, 表明调用图), 进行CPU堆栈**采样**(sampling), 持续10s:

```
# perf record -F 99 -a -g -- sleep 30
[ perf record: Woken up 9 times to write data ]
[ perf record: Captured and wrote 3.135 MB perf.data (~136971 samples) ]

# ls -lh perf.data
-rw------- 1 root root 3.2M Jan 26 07:26 perf.data
```

选择**99Hz**而**不是100Hz**，是为了避免以一定的周期性活动意外地进行采样，这会产生偏斜的结果。 这也很粗糙：您可能希望将其提高到**更高的速率**（例如，达到 997 Hz）以获得更高的分辨率，尤其是在您对**短时间的活动**突发采样并且仍然希望有足够的分辨率有用时。 请记住，更高的频率意味着更高的开销。

### 9.2.2. 分析

`perf.data`文件可以通过**多种方式处理**。 
* 在最新版本中，`perf report`命令将启动`ncurses`导航器以进行**调用图检查**。 
* 在perf的旧版本（或者在新版本中使用`--stdio`）将**调用图**打印**为树**，并用**百分比**进行注释：

```
# perf report --stdio
# ========
# captured on: Mon Jan 26 07:26:40 2014
# hostname : dev2
# os release : 3.8.6-ubuntu-12-opt
# perf version : 3.8.6
# arch : x86_64
# nrcpus online : 8
# nrcpus avail : 8
# cpudesc : Intel(R) Xeon(R) CPU X5675 @ 3.07GHz
# cpuid : GenuineIntel,6,44,2
# total memory : 8182008 kB
# cmdline : /usr/bin/perf record -F 99 -a -g -- sleep 30 
# event : name = cpu-clock, type = 1, config = 0x0, config1 = 0x0, config2 = ...
# HEADER_CPU_TOPOLOGY info available, use -I to display
# HEADER_NUMA_TOPOLOGY info available, use -I to display
# pmu mappings: software = 1, breakpoint = 5
# ========
#
# Samples: 22K of event 'cpu-clock'
# Event count (approx.): 22751
#
# Overhead  Command      Shared Object                           Symbol
# ........  .......  .................  ...............................
#
    94.12%       dd  [kernel.kallsyms]  [k] _raw_spin_unlock_irqrestore
                 |
                 --- _raw_spin_unlock_irqrestore
                    |          
                    |--96.67%-- extract_buf
                    |          extract_entropy_user
                    |          urandom_read
                    |          vfs_read
                    |          sys_read
                    |          system_call_fastpath
                    |          read
                    |          
                    |--1.69%-- account
                    |          |          
                    |          |--99.72%-- extract_entropy_user
                    |          |          urandom_read
                    |          |          vfs_read
                    |          |          sys_read
                    |          |          system_call_fastpath
                    |          |          read
                    |           --0.28%-- [...]
                    |          
                    |--1.60%-- mix_pool_bytes.constprop.17
[...]
```

该树状信息以CPU上的函数开始，并一直追溯到祖先。这种方法称为“`callee based call graph`”(**基于被调用者的调用图**)。 

可以使用`-G`表示“`inverted call graph`”(**反向调用图**)，也可以使用`-g/-call-graph`的“`caller`”(**调用者**)选项（而不是默认的"**callee被调用者**"）来翻转。

此性能调用图中**最热**（最频繁）的**堆栈跟踪**发生在采样的`90.99％`中，这是开销百分比和**顶部堆栈叶**(top stack leaf)的乘积（`94.12％ x 96.67％`，这是**相对比率**）。 

性能报告也可以用“ -g graph”运行以显示**绝对开销率**，在这种情况下，“ 90.99％”直接显示在堆栈叶上, 类似于:

```
    94.12%       dd  [kernel.kallsyms]  [k] _raw_spin_unlock_irqrestore
                 |
                 --- _raw_spin_unlock_irqrestore
                    |          
                    |--90.99%-- extract_buf
[...]
```

如果用户态堆栈不完整, `perf record`可以使用`--call-graph dwarf`参数作为一个手段来unwind堆栈. 详细见前面.

`perf report`的输出可能很长, 从而难以阅读, 可以试着生成火焰图. 详细见后面.

## 9.3. Event Profiling: 事件分析

除了以一定的时间间隔进行采样外，**CPU硬件计数器**触发的采样是**CPU性能分析**的另一种形式，可用于更加了解`cache misses`**高速缓存未命中**，`memory stall cycles`**内存停顿周期**和其他低级处理器事件。 

可用的事件可以使用`perf list`找到：

```
# perf list | grep Hardware
  cpu-cycles OR cycles                               [Hardware event]
  instructions                                       [Hardware event]
  cache-references                                   [Hardware event]
  cache-misses                                       [Hardware event]
  branch-instructions OR branches                    [Hardware event]
  branch-misses                                      [Hardware event]
  bus-cycles                                         [Hardware event]
  stalled-cycles-frontend OR idle-cycles-frontend    [Hardware event]
  stalled-cycles-backend OR idle-cycles-backend      [Hardware event]
  ref-cycles                                         [Hardware event]
  L1-dcache-loads                                    [Hardware cache event]
  L1-dcache-load-misses                              [Hardware cache event]
  L1-dcache-stores                                   [Hardware cache event]
  L1-dcache-store-misses                             [Hardware cache event]
[...]
```

对于许多这样的硬件事件，每次发生时**收集堆栈**都会导致**过多的开销**，并且会降低系统速度并**更改目标的性能特征**。 

所以通常**只需检测一小部分事件**，而不是全部事件, 这样就已经够用。可以通过使用“`-c`”和**一个计数指定触发事件**收集的**阈值**来达到这个目的.

比如, 下面的命令用来检测`level 1 data load misses`, 每发生10000次收集一次stack trace

```
# perf record -e L1-dcache-load-misses -c 10000 -ag -- sleep 5
```

"`-c count`"机制是由处理器实现的, 当处理器达到这个阈值才中断内核.

指定自定义计数器例子可以看前面的`Raw Counters`和下面的`skew`部分

### 9.3.1. Skew和PEBS: 指令偏移和PEBS基于采样的精确事件

`Event Profiling`(**事件分析**)存在一个问题，而`CPU Profiling`(**定时采样**)不会遇到这个问题。 

* 对于**定时采样**，在**中断**与**读取指令指针**（IP）之间是否存在**较小**的**亚微秒**(`sub-microsecond`)延迟并**不重要**。而且一些CPU分析器故意引入此抖动，这是避免进行锁步采样的另一种方法。 
* 但对于事件分析而言，这确实很重要：如果您试图在**某个PMC事件**上**捕获IP**，并且**PMC溢出**和**捕获IP**之间存在**延迟**，则IP将指向**错误的地址**。这就会偏移(skew)。 

另一个引起问题的问题是，微操作是`parallel`**并行**且`out-of-order`**无序**地处理的，而指令指针IP指向**恢复指令**，而**不是导致事件的指令**。 在[这里](https://www.slideshare.net/brendangregg/scale2015-linux-perfprofiling/63)已经讨论过了。

解决方案是“**精确采样**”，在intel上是**PEBS**(`Precise Event-Based Sampling`, 基于事件的精确采样)，在AMD上是**IBS**(`Instruction-Based Sampling`, 基于指令的采样)。它们使用**CPU硬件支持**来捕获**事件发生**时**CPU的真实状态**。 

通过`:p`修饰符标明PMC事件名, perf可以使用精确采样, 例如"`-e instructions:p`". p越多, 则越精确(accurate). 下面内容来自`tools/perf/Documentation/perf-list.txt`的文档：

```
The 'p' modifier can be used for specifying how precise the instruction
address should be. The 'p' modifier can be specified multiple times:

 0 - SAMPLE_IP can have arbitrary skid
 1 - SAMPLE_IP must have constant skid
 2 - SAMPLE_IP requested to have 0 skid
 3 - SAMPLE_IP must have 0 skid, or uses randomization to avoid
     sample shadowing effects.
```

`p`修饰符用来表明指令地址的精确程度. 在**某些情况**下，perf将**默认**使用**精确采样**，而**无需指定它**。 运行“`perf record -vv ...`”以查看“ `precise_ip`”的值。 

另注意，**仅某些PMC支持PEBS**。

如果PEBS完全没有工作, 可以检查dmesg:

```
# dmesg | grep -i pebs
[    0.387014] Performance Events: PEBS fmt1+, SandyBridge events, 16-deep LBR, full-width counters, Intel PMU driver.
[    0.387034] core: PEBS disabled due to CPU errata, please upgrade microcode
```

通过更新微码包修复, 如下(intel平台):

```
# yum install microcode_ctl linux-firmware -y

# reboot

# dmesg | grep -i pebs
[    0.386596] Performance Events: PEBS fmt1+, SandyBridge events, 16-deep LBR, full-width counters, Intel PMU driver.
#
```

## 9.4. Static Kernel Tracing: 内核态静态追踪

一些静态追踪例子: tracepoints和其他静态事件的检测.

### 9.4.1. Counting Syscalls: 系统调用计数

下面命令统计了一个命令的系统调用计数, 同时打印了出来(只打印了非0值):

```
# perf stat -e 'syscalls:sys_enter_*' gzip file1 2>&1 | awk '$1 != 0'

 Performance counter stats for 'gzip file1':

                 1 syscalls:sys_enter_utimensat               
                 1 syscalls:sys_enter_unlink                  
                 5 syscalls:sys_enter_newfstat                
             1,603 syscalls:sys_enter_read                    
             3,201 syscalls:sys_enter_write                   
                 5 syscalls:sys_enter_access                  
                 1 syscalls:sys_enter_fchmod                  
                 1 syscalls:sys_enter_fchown                  
                 6 syscalls:sys_enter_open                    
                 9 syscalls:sys_enter_close                   
                 8 syscalls:sys_enter_mprotect                
                 1 syscalls:sys_enter_brk                     
                 1 syscalls:sys_enter_munmap                  
                 1 syscalls:sys_enter_set_robust_list         
                 1 syscalls:sys_enter_futex                   
                 1 syscalls:sys_enter_getrlimit               
                 5 syscalls:sys_enter_rt_sigprocmask          
                14 syscalls:sys_enter_rt_sigaction            
                 1 syscalls:sys_enter_exit_group              
                 1 syscalls:sys_enter_set_tid_address         
                14 syscalls:sys_enter_mmap                    

       1.543990940 seconds time elapsed
```

这个例子中, 分析了gzip指令. 有 3201 个`write()`系统调用, 1603 个`read()`系统调用. 其他的系统调用多由于进程和相应库的初始化.

有一个相似的工具`strace -c`, 对系统调用进行trace, 这个工具会比perf的开销更大, 因为perf将数据缓存在内核中.

#### 9.4.1.1. perf和strace对比

为了进一步说明差异：strace的当前实现使用`ptrace(2)`attach(附加)到**目标进程**，并在**系统调用期间**将其**停止**，像个**调试器**。 这很猛烈，并可能导致**严重的开销**。

为了证明这一点，执行下面**使用系统调用频繁**的程序, 分别本身执行、通过perf和通过运行。这里只截取了显示其性能的输出行：

```
# dd if=/dev/zero of=/dev/null bs=512 count=10000k
5242880000 bytes (5.2 GB) copied, 3.53031 s, 1.5 GB/s

# perf stat -e 'syscalls:sys_enter_*' dd if=/dev/zero of=/dev/null bs=512 count=10000k
5242880000 bytes (5.2 GB) copied, 9.14225 s, 573 MB/s

# strace -c dd if=/dev/zero of=/dev/null bs=512 count=10000k
5242880000 bytes (5.2 GB) copied, 218.915 s, 23.9 MB/s
```

可以看到, 
* 使用`perf`, 程序慢了2.5倍;
* 使用`strace`, 程序慢了62倍.

当然, 在使用系统调用不频繁的程序中, 性能差距没那么大.

### 9.4.2. New Processes: 追踪新建一个进程

追踪由`man ls`触发的新建进程:

```
# perf record -e sched:sched_process_exec -a
^C[ perf record: Woken up 1 times to write data ]
[ perf record: Captured and wrote 0.064 MB perf.data (~2788 samples) ]
# perf report -n --sort comm --stdio
[...]
# Overhead       Samples  Command
# ........  ............  .......
#
    11.11%             1    troff
    11.11%             1      tbl
    11.11%             1  preconv
    11.11%             1    pager
    11.11%             1    nroff
    11.11%             1      man
    11.11%             1   locale
    11.11%             1   grotty
    11.11%             1    groff
```

执行了**九个不同的命令**，每个命令一次。使用`-n`打印“Samples”列，并使用“`--sort comm`”来自**定义其余列**。

当进程运行`exec()`执行不同的二进制文件时，这通过跟踪`sched:sched_process_exec`起作用。这通常是**创建新进程**的方式，但并非总是如此。应用程序可以`fork()`创建工作进程池(`a pool of worker processes`)，但**不执行exec()**执行不同的二进制文件。应用程序也可以**重新执行**：通常再次对其本身调用`exec()`来**清理其地址空间**。 在这种情况下，**此exec跟踪点**将看到它，但这**不是一个新进程**。

可以跟踪`sched:sched_process_fork`**跟踪点**以**仅捕获**通过`fork()`创建的新进程。缺点是所标识的进程是**父进程**，而**不是新目标**，因为新进程尚未执行`exec()`最终程序。

### 9.4.3. Outbound Connections: 出站网络连接

出站网络连接: 本地服务器发起连接外部网络

入站网站连接: 外部向本地服务器发起连接

有时可能需要仔细检查服务器**启动了哪些网络连接**，**从哪个进程启动**以及**为什么启动**。 您可能会感到惊讶。 这些连接可能很重要，因为它们可能会导致延迟。

对于此示例，我有一个完全空闲的服务器，在跟踪时，我将使用ssh登录到该服务器。 我将通过`connect()`**系统调用**跟踪出站网络连接。 假设我正在通过SSH执行**入站连接**，那么将根本没有出站连接吗？

```

```

### 9.4.4. Socket Buffers:


## 9.5. Static User Tracing: 用户态静态追踪



## 9.6. Dynamic Tracing: 动态追踪

对于Linux内核, 配置`CONFIG_KPROBES=y`和`CONFIG_KPROBE_EVENTS=y`, 从而开启linux内核动态追踪功能; 配置`CONFIG_FRAME_POINTER=y`, 打开基于frame pointer的stack.

对于用户态, 配置`CONFIG_UPROBES=y`和`CONFIG_UPROBE_EVENTS=y`, 从而开启用户态动态追踪功能.

### Kernel: tcp_sending(): 某个内核函数被调用栈

```
# ./perf probe --add tcp_sendmsg
Added new event:
  probe:tcp_sendmsg    (on tcp_sendmsg)

You can now use it in all perf tools, such as:

	perf record -e probe:tcp_sendmsg -aR sleep 1
```

这就添加了一个tracepoint事件. 它推荐使用`-R`参数, 以此收集原始采样数据, 也已经是默认选项. 

追踪这个事件5秒, 并记录stack traces(堆栈追踪):

```
# ./perf record -e probe:tcp_sendmsg -a -g -- sleep 5
[ perf record: Woken up 1 times to write data ]
[ perf record: Captured and wrote 0.413 MB perf.data (1 samples) ]
```

然后分析`report`:

```
# perf report --stdio
# ========
# captured on: Fri Jan 31 20:10:14 2014
# hostname : pgbackup
# os release : 3.9.3-ubuntu-12-opt
# perf version : 3.9.3
# arch : x86_64
# nrcpus online : 8
# nrcpus avail : 8
# cpudesc : Intel(R) Xeon(R) CPU E5-2670 0 @ 2.60GHz
# cpuid : GenuineIntel,6,45,7
# total memory : 8179104 kB
# cmdline : /lib/modules/3.9.3/build/tools/perf/perf record -e probe:tcp_sendmsg -a -g -- sleep 5 
# event : name = probe:tcp_sendmsg, type = 2, config = 0x3b2, config1 = 0x0, config2 = 0x0, ...
# HEADER_CPU_TOPOLOGY info available, use -I to display
# HEADER_NUMA_TOPOLOGY info available, use -I to display
# pmu mappings: software = 1, tracepoint = 2, breakpoint = 5
# ========
#
# Samples: 12  of event 'probe:tcp_sendmsg'
# Event count (approx.): 12
#
# Overhead  Command      Shared Object           Symbol
# ........  .......  .................  ...............
#
   100.00%     sshd  [kernel.kallsyms]  [k] tcp_sendmsg
               |
               --- tcp_sendmsg
                   sock_aio_write
                   do_sync_write
                   vfs_write
                   sys_write
                   system_call_fastpath
                   __write_nocancel
                  |          
                  |--8.33%-- 0x50f00000001b810
                   --91.67%-- [...]
```

这显示了从`write()`系统调用到`tcp_sendmsg()`的堆栈.

使用了以后, 可以通过`perf probe --del`删掉它.

### Kernel: tcp_sendmsg() with size: 获取内核变量

如果kernel有debuginfo(`CONFIG_DEBUG_INFO=y`), 就可以**从函数中获取内核变量**. 下面是一个例子, 检查`size_t`(整型).

列出`tcp_sendmsg()`中的可用变量:

```
# perf probe -V tcp_sendmsg
Available variables at tcp_sendmsg
        @<tcp_sendmsg+0>
                size_t  size
                struct kiocb*   iocb
                struct msghdr*  msg
                struct sock*    sk
```

为`tcp_sendmsg()`创建一个带有`size`变量的probe:

```
# perf probe --add 'tcp_sendmsg size'
Added new event:
  probe:tcp_sendmsg    (on tcp_sendmsg with size)

You can now use it in all perf tools, such as:

	perf record -e probe:tcp_sendmsg -aR sleep 1
```

追踪这个probe:

```
# perf record -e probe:tcp_sendmsg -a
^C[ perf record: Woken up 1 times to write data ]
[ perf record: Captured and wrote 0.052 MB perf.data (~2252 samples) ]

# perf script
# ========
# captured on: Fri Jan 31 23:49:55 2014
# hostname : dev1
# os release : 3.13.1-ubuntu-12-opt
# perf version : 3.13.1
# arch : x86_64
# nrcpus online : 2
# nrcpus avail : 2
# cpudesc : Intel(R) Xeon(R) CPU E5645 @ 2.40GHz
# cpuid : GenuineIntel,6,44,2
# total memory : 1796024 kB
# cmdline : /usr/bin/perf record -e probe:tcp_sendmsg -a 
# event : name = probe:tcp_sendmsg, type = 2, config = 0x1dd, config1 = 0x0, config2 = ...
# HEADER_CPU_TOPOLOGY info available, use -I to display
# HEADER_NUMA_TOPOLOGY info available, use -I to display
# pmu mappings: software = 1, tracepoint = 2, breakpoint = 5
# ========
#
            sshd  1301 [001]   502.424719: probe:tcp_sendmsg: (ffffffff81505d80) size=b0
            sshd  1301 [001]   502.424814: probe:tcp_sendmsg: (ffffffff81505d80) size=40
            sshd  2371 [000]   502.952590: probe:tcp_sendmsg: (ffffffff81505d80) size=27
            sshd  2372 [000]   503.025023: probe:tcp_sendmsg: (ffffffff81505d80) size=3c0
            sshd  2372 [001]   503.203776: probe:tcp_sendmsg: (ffffffff81505d80) size=98
            sshd  2372 [001]   503.281312: probe:tcp_sendmsg: (ffffffff81505d80) size=2d0
[...]
```

`size`按照十六进制显示.

### Kernel: tcp_sendmsg() line number and local variable: 内核函数某一行跟踪点和局部变量

使用debuginfo，perf可以为**某内核函数中某一行**创建跟踪点。

先列出可用于`tcp_sendmsg`的**行探针**(line probe)：

```
# perf probe -L tcp_sendmsg
<tcp_sendmsg@/mnt/src/linux-3.14.5/net/ipv4/tcp.c:0>
      0  int tcp_sendmsg(struct kiocb *iocb, struct sock *sk, struct msghdr *msg,
                        size_t size)
      2  {
                struct iovec *iov;
                struct tcp_sock *tp = tcp_sk(sk);
                struct sk_buff *skb;
      6         int iovlen, flags, err, copied = 0;
      7         int mss_now = 0, size_goal, copied_syn = 0, offset = 0;
                bool sg;
                long timeo;
[...]
     79                 while (seglen > 0) {
                                int copy = 0;
     81                         int max = size_goal;
         
                                skb = tcp_write_queue_tail(sk);
     84                         if (tcp_send_head(sk)) {
     85                                 if (skb->ip_summed == CHECKSUM_NONE)
                                                max = mss_now;
     87                                 copy = max - skb->len;
                                }
         
     90                         if (copy <= 0) {
         new_segment:
[...]
```

这是在`Linux 3.14.5`, 检查在 81 行时可用的局部变量

```
# perf probe -V tcp_sendmsg:81
Available variables at tcp_sendmsg:81
        @<tcp_sendmsg+537>
                bool    sg
                int     copied
                int     copied_syn
                int     flags
                int     mss_now
                int     offset
                int     size_goal
                long int        timeo
                size_t  seglen
                struct iovec*   iov
                struct sock*    sk
                unsigned char*  from
```

跟踪第81行，并在循环中检查seglen变量：

```
# perf probe --add 'tcp_sendmsg:81 seglen'
Added new event:
  probe:tcp_sendmsg    (on tcp_sendmsg:81 with seglen)

You can now use it in all perf tools, such as:

	perf record -e probe:tcp_sendmsg -aR sleep 1

# perf record -e probe:tcp_sendmsg -a
^C[ perf record: Woken up 1 times to write data ]
[ perf record: Captured and wrote 0.188 MB perf.data (~8200 samples) ]

# perf script
            sshd  4652 [001] 2082360.931086: probe:tcp_sendmsg: (ffffffff81642ca9) seglen=0x80
   app_plugin.pl  2400 [001] 2082360.970489: probe:tcp_sendmsg: (ffffffff81642ca9) seglen=0x20
        postgres  2422 [000] 2082360.970703: probe:tcp_sendmsg: (ffffffff81642ca9) seglen=0x52
   app_plugin.pl  2400 [000] 2082360.970890: probe:tcp_sendmsg: (ffffffff81642ca9) seglen=0x7b
[...]
```

这真是太神奇了。 请记住，还可以使用`--filter`包括内核内过滤，以**仅匹配**所需的数据。

### User: malloc(): 

尽管这是一个有趣的示例，但我想马上说出`malloc()`调用非常频繁，因此您将需要考虑像这样跟踪调用的开销。
















## 9.7. Scheduler Analysis: 调度器分析

## 9.8. eBPF

### 9.8.1. 

### 9.8.2. 事件限定符

事件有多种表示方式，最简单的是它的字符串表示。引用事件时，可以指定限定符：

https://blog.gmem.cc/perf

## 9.9. 性能事件的属性

### 9.9.1. PMI中断和PEBS中断

perf的采样是**基于事件**进行的。**采样的周期**以**事件的数量来表示**，而**非基于时间**。当**目标事件计数溢出指定的数值！！！**，则**产生一个采样**。

样本中包含的信息取决于用户和工具指定的**度量类型**，但是最重要的信息是**指令指针**（instruction pointer），也就是程序**被中断时所处的位置**。

这种基于中断的采样，在现代处理器上存在刹车效应。也就是说，**样本中记录的指针**，和程序被中断以处理PMU事件时的指令指针，可能**相隔数十个指令**。

record子命令默认使用cycle事件，类似于定期采样。


**硬件性能事件**由处理器的PMU提供支持。

如前文所述，perf会对PMI中断发生时的PC寄存器进行采样。由于现代处理器的主频非常高，在加上深度流水线机制，从**性能事件被触发**，到处理器**响应PMI中断**，流水线上可能已处理过百条指令。那么**PMI中断**采到的**指令地址**就不再是处罚性能事件的那条指令的地址了，而可能具有**非常严重的偏差**。

为了解决这个问题，intel处理器通过**PEBS**（Precise Event Based Sampling）机制实现了**高精度事件采样**。PEBS通过硬件在**计数器溢出**时将处理器现场直接保存到内存（而**不是在相应中断时**才保存寄存器现场），从而使得perf能够真正触发性能事件的那条指令的地址，提高了采样精度。

在默认条件下，perf**不使用PEBS机制**。用户如果想要使用**高精度采样**，需要在指定性能事件时，在事件后调价后缀"`:p`"或"`:pp`"。

例如：

```
perf top -e cycles:pp
```

### 9.9.2. 性能事件的精度级别

Perf 在采样精度上定义了 4 个级别.

Level | Comment
---|---
0 | 无精度保证
1 | 采样指令与触发性能事件的指令之间的偏差为常数（:p）
2 | 需要尽量保证采样指令与触发性能事件的指令的偏差为0（:pp）
3 | 保证采样指令与触发性能事件的指令之间的偏差**必须为0**（:ppp）

目前X86处理器，包括Intel处理器与AMD处理器Jun仅能实现前3个精度级别。

### 9.9.3. 其他属性

除了精度级别以外，事件还具有其他几个属性，均可以通过"event:X"的方式予以指定。

attribute | Comment
---|---
u | 仅统计用户空间程序触发的性能事件。
k | 仅统计内核触发的性能事件。
h | 仅统计Hypervisor触发的性能事件。
G | 在KVM虚拟机中，仅攻击Guest系统触发的性能事件。
H | 仅统计Host系统触发的性能事件。
p | 精度级别。

## 9.10. 没有预定义字符描述的硬件性能事件

另外需要补充的是，perf list工具仅列出了具有字符描述的**硬件性能事件**。而那些**没有预定义字符描述的性能事件**，也可以通过特殊方式使用。

这时，就需要我们**根据CPU的手册**，通过性能事件的标号配置PMU的性能计数器。可以采用如下方式：

```
perf top -e r[UMask+EventSelect]
```

举个例子，我们现在想统计所有**从内存中读过数据的指令的个数**，perf list中并未预定义此事件的字符描述。通过查找intel的处理器手册，我们找了此事件编码：

![2020-07-20-08-47-26.png](./images/2020-07-20-08-47-26.png)

便可以通过以下方式使用此事件：

```
perf stat -e r010b ls
```

所以完整的性能事件列表见Intel手册`Performance Monitoring Events`


## 9.11. 性能事件指定错误

所以如果指定性能事件失败, 可能会有类似打印

```
./perf record -e syscalls:sys_enter ls
event syntax error: 'syscalls:sys_enter'
                     \___ unknown tracepoint

Error:	File /sys/kernel/debug/tracing/events/syscalls/sys_enter not found.
Hint:	Perhaps this kernel misses some CONFIG_ setting to enable this feature?.

Run 'perf list' for a list of valid events

 Usage: perf record [<options>] [<command>]
    or: perf record [<options>] -- <command> [<options>]

    -e, --event <event>   event selector. use 'perf list' to list available events
```

# 10. Visualizations: 可视化

perf内置了一个可视化: timecharts, 以及通过文本用户界面(TUI)和树状报告的text-style(文本风格)的可视化.

下面再介绍两个可视化: flame graphs(火焰图)和heat maps(热点图).

## 10.1. Flame Graphs: 火焰图

火焰图: http://www.brendangregg.com/flamegraphs.html

使用[火焰图工具](https://github.com/brendangregg/FlameGraph)分析perf的剖析数据生成. 火焰图和`perf report`使用的数据一样, 都是通过`stack traces(-g)`获取的perf.data文件.

### 10.1.1. 示例

下面火焰图显示`3.2.9-1`内核的network workload, 运行了一个KVM实例:

![http://www.brendangregg.com/FlameGraphs/cpu-linux-tcpsend.svg](http://www.brendangregg.com/FlameGraphs/cpu-linux-tcpsend.svg)

火焰图在x轴显示采样数量总体, y轴显示堆栈深度. 每个函数(stack frame)被绘制成一个矩形, 矩形的宽度与它的采样数量相关. 完整描述见 [CPU火焰图 ](http://www.brendangregg.com/FlameGraphs/cpuflamegraphs) .

可以使用鼠标探索内核CPU时间花在哪里，快速量化代码路径，并确定性能调优工作最好花在哪里。这个示例显示，大部分时间都花在`vp_notify()`代码路径上，所有cpu上的示例中有`70.52%`的时间执行`iowrite16()`，它是由**KVM管理程序处理**的。这些信息对于指导KVM性能工作非常有用。

裸机Linux(bare metal Linux)的network workload看起来是不同的, 因为首先网络的处理不是通过`virtio-net`驱动处理.

### 10.1.2. 生成

火焰图生成

```
# git clone https://github.com/brendangregg/FlameGraph  # or download it from github
# cd FlameGraph
# perf record -F 99 -ag -- sleep 60
# perf script | ./stackcollapse-perf.pl > out.perf-folded
# cat out.perf-folded | ./flamegraph.pl > perf-kernel.svg
```

`perf record`会生成perf.data文件, 可以使用`perf report`查看

```
# perf report --stdio
[...]
# Overhead          Command          Shared Object                               Symbol
# ........  ...............  .....................  ...................................
#
    72.18%            iperf  [kernel.kallsyms]      [k] iowrite16
                      |
                      --- iowrite16
                         |          
                         |--99.53%-- vp_notify
                         |          virtqueue_kick
                         |          start_xmit
                         |          dev_hard_start_xmit
                         |          sch_direct_xmit
                         |          dev_queue_xmit
                         |          ip_finish_output
                         |          ip_output
                         |          ip_local_out
                         |          ip_queue_xmit
                         |          tcp_transmit_skb
                         |          tcp_write_xmit
                         |          |          
                         |          |--98.16%-- tcp_push_one
                         |          |          tcp_sendmsg
                         |          |          inet_sendmsg
                         |          |          sock_aio_write
                         |          |          do_sync_write
                         |          |          vfs_write
                         |          |          sys_write
                         |          |          system_call
                         |          |          0x369e40e5cd
                         |          |          
                         |           --1.84%-- __tcp_push_pending_frames
[...]
```





# 11. perf构建

centos你可以使用yum安装，也可以使用源码安装。

perf 在内核源码包中的位置 tools/perf。

Acme是Linux perf的maintainer，他的`perf/core`分支包含了perf工具的最新功能。所以如果想体验最新版本的perf，可以下载和编译Acme的perf：

## 11.1. 安装依赖库

安装依赖库，有一个小窍门可以找到依赖的库

```
# cat Makefile |grep found
```

```makefile
# for perf_events:
CONFIG_PERF_EVENTS=y
# for stack traces:
CONFIG_FRAME_POINTER=y
# kernel symbols:
CONFIG_KALLSYMS=y
# tracepoints:
CONFIG_TRACEPOINTS=y
# kernel function trace:
CONFIG_FTRACE=y
# kernel-level dynamic tracing:
CONFIG_KPROBES=y
CONFIG_KPROBE_EVENTS=y
# user-level dynamic tracing:
CONFIG_UPROBES=y
CONFIG_UPROBE_EVENTS=y
# full kernel debug info:
CONFIG_DEBUG_INFO=y
# kernel lock tracing:
CONFIG_LOCKDEP=y
# kernel lock tracing:
CONFIG_LOCK_STAT=y
# kernel dynamic tracepoint variables:
CONFIG_DEBUG_INFO=y
```

## 11.2. 测试

```
[root@centos7 linux]# make -C tools/perf -f tests/make
```

## 11.3. 编译

```
[root@centos7 linux]# make -C tools/perf
```

## 11.4. 安装

```
[root@centos7 linux]# make -C tools/perf install
```

## 11.5. 帮助文档

```
man 1 perf
man 1 perf-stat
man 1 perf-top
man 1 perf-record
man 1 perf-report
man 1 perf-list
```

# 12. 简单示例

程序`[pi.c]`是一个简单的计算Pi的CPU密集型程序。很显然，`[pi.c]`的热点在函数`do_pi()`中。

```cpp
#include <stdio.h>
#include <math.h>
#include <sys/types.h>
#include <linux/unistd.h>

int do_pi(double *pi)
{
    double h, sum, x;
    long long n, i;

    n = 5000000;
    h = 1.0/n;
    sum = 0.0;

    for (i = 1; i <= n; i++) {
        x = h * (i - 0.5);
        sum += 4.0 / (1.0 + pow(x,2));
    }

    *pi = h *sum;
    return 0;
}

int main(void)
{
    double pi;

    printf("pid: %d\n", getpid());
    sleep(5);

    if (!do_pi(&pi)) {
        printf("PI is %f\n", pi);
    }
    return 0;
}
```
编译pi程序

```
gcc pi.c -lm -o pi
```

运行pi程序

```
./pi
```

根据程序显示的pid在命令行中执行

```
perf top -p $pid
```

该命令利用**默认的性能事件**"cycles"对`[pi]`进行热点分析。"cycles"是**处理器周期事件**。这条命令能够分析出**消耗处理器周期最多的代码**，在处理器频率稳定的前提下，我们可以认为perf给出的热点代码就是消耗时间最多的代码。

CPU周期(cpu-cycles)是默认的性能事件，所谓的CPU周期是指CPU所能识别的最小时间单元，通常为亿分之几秒，是CPU执行最简单的指令时所需要的时间，例如读取寄存器中的内容，也叫做clock tick。

执行上述命令后，Perf会给出如下结果：

![image](./images/0x01.png)

从上图可以看到，在`[pi]`程序执行期间，函数`do_pi()`消耗了62.57%的CPU周期，是消耗处理器周期最多的热点代码。这跟我们预想的一样。

## 12.1. cycles原理

那么Perf是怎么做到的呢？以`cycles`性能事件为例

首先，perf会通过系统调用`sys_perf_event_open`在内核中注册一个检测"**cycles**"**事件**的性能计数器。内核根据perf提供的信息在**PMU**上初始化一个**硬件性能计数器**（PMC：Performance Monitoring Counter）。PMC随着CPU周期的增加而自动累加。

在**PMU溢出**时，PMU触发一个PMI（Performance Monitoring Interrupt）中断。内核在PMI中断处理函数中保存**PMC的计数值**，触发中断时的**指令地址**（Register IP：Instruction Pointer），**当前时间戳**以及**当前进程**的**PID**，**TID**，**comm**等信息。我们把这些信息统称为一个**采样**（sample）。

内核会将收集到的sample放入用于跟**用户空间**通信的Ring Buffer。**用于空间**的perf分析程序采用**mmap机制**从ring buffer中读入采样，并对其解析。perf根据**pid**, comm等信息可以找到对应的进程。根据**IP**与**ELF文件**中的**符号表**可以查找到触发PMI中断的指令所在的函数。为了能够使perf读到函数名，我们的目标程序必须具备符号表。

如果perf在分析结果中**只看到一串地址**，而**没有对应的函数名**时，通常是由于在**编译时**利用**strip**删除了ELF文件中的符号信息。建议在性能剖析阶段，保留程序中的**sysbol table**与**debug info**等信息。

根据上述的perf采样原理可以得知，perf假设两次采样之间，即两次相邻的PMI中断之间系统执行的是同一个进程的同一个函数。这种假设会带来**一定的误差**，当感觉perf给出的**结果不准**时，不妨提高**采样频率**，perf会给出更加精确的结果。

# 13. 参考

http://www.brendangregg.com/perf.html
