内存屏障是一种底层原语，在不同计算机架构下有不同的实现细节。本文主要在`x86_64`处理器下，通过Linux及其内核代码来分析和使用内存屏障

对大多数应用层开发者来说，“内存屏障”（memory barrier）是一种陌生，甚至有些诡异的技术。实际上，他常被用在操作系统内核中，用于实现同步机制、驱动程序等。

利用它，能实现高效的无锁数据结构，提高多线程程序的性能表现。本文首先探讨了内存屏障的必要性，之后介绍如何使用内存屏障实现一个无锁唤醒缓冲区（队列），用于在多个线程间进行高效的数据交换。

# 理解内存屏障

程序实际运行时很可能并不完全按照开发者编写的顺序访问内存。例如：

```cpp
x = r;
y = 1;
```

这里，y = 1很可能先于x = r执行。这就是**内存乱序访问**。内存乱序访问行为出现的理由是为了提升**程序运行时的性能**.

**编译器**和**CPU**都可能引起**内存乱序访问**：

* 编译时，编译器优化进行**指令重排**而导致内存乱序访问；
* 运行时，**多CPU间交互**引入内存乱序访问。

编译器和CPU引入内存乱序访问通常不会带来什么问题，但在一些特殊情况下（主要是**多线程程序中**），**逻辑的正确性**依赖于**内存访问顺序**，这时，内存乱序访问会带来逻辑上的错误，例如：

```cpp
// thread 1
while(!ok);
do(x);

// thread 2
x = 42;
ok = 1;
```

ok初始化为0， 线程1等待ok被设置为1后执行do函数。假如，**线程2**对内存的**写操作乱序执行**，也就是**x赋值晚于ok赋值**完成，那么do函数接受的实参很有可能出乎开发者的意料，不为42。

我们可以引入内存屏障来避免上述问题的出现。内存屏障能让**CPU或者编译器**在**内存访问上有序**。一个内存屏障之前的内存访问操作必定先于其之后的完成。内存屏障包括两类：**编译器屏障**和**CPU内存屏障**。

# 编译时内存乱序访问

编译器对代码做出优化时，可能改变**实际执行指令的顺序**（例如`g++`下O2或者O3都会改变实际执行指令的顺序），看一个例子:

```cpp
int x, y, r;
void f()
{
    x = r;
    y = 1;
}
```

首先直接编译次源文件：`g++ -S test.cpp`。我们得到相关的汇编代码如下：

```
movl    r(%rip), %eax
movl    %eax, x(%rip)
movl    $1, y(%rip)
```

这里我们可以看到，`x = r`和`y = 1`并**没有乱序执行**。

现使用**优化选项**O2(或O3)编译上面的代码（`g++ -O2 –S test.cpp`），生成汇编代码如下：

```
movl    r(%rip), %eax
movl    $1, y(%rip)
movl    %eax, x(%rip)
```

我们可以清楚地看到经过编译器优化之后，movl $1, y(%rip)先于movl %eax, x(%rip)执行，这意味着，编译器优化导致了内存乱序访问。避免次行为的办法就是使用编译器屏障（又叫优化屏障）。Linux内核提供了函数barrier()，用于让编译器保证其之前的内存访问先于其之后的内存访问完成。（这个强制保证顺序的需求在哪里？换句话说乱序会带来什么问题内？ – 一个线程执行了 y =1 , 但实际上x=r还没有执行完成，此时被另一个线程抢占，另一个线程执行，发现y=1，以为此时x必定=r，执行相应逻辑，造成错误）内核实现barrier()如下：

```cpp
#define barrier() __asm__ __volatile__("": : :"memory")
```

现在把此编译器barrier加入代码中：

```cpp
int x, y, r;
void f()
{
    x = r;
    __asm__ __volatile__("": : :"memory")
    y = 1;
}
```

再编译，就会发现内存乱序访问已经不存在了。除了barrier()函数外，本例还可以使用volatile这个关键字来避免编译时内存乱序访问（且仅能避免编译时的乱序访问，为什么呢，可以参考前面部分的说明，编译器对于volatile声明究竟做了什么 – volatile关键字对于编译器而言，是开发者告诉编译器，这个变量内存的修改，可能不再你可视范围内，不要对这个变量相关的代码进行优化）。volatile关键字能让volatile变量之间的内存访问上有序，这里可以修改x和y的定义来解决问题：

```cpp
volatile int x, y, r;
```

通过volatile关键字，使得x相对y、y相对x在内存访问上是有序的。实际上，Linux内核中，宏ACCESS_ONCE能避免编译器对于连续的ACCESS_ONCE实例进行指令重排，其就是通过volatile实现的：

```cpp
#define ACCESS_ONCE(x) (*(volatile typeof(x) *)&(x))
```

此代码只是将变量x转换为volatile的而已。现在我们就有了第三个修改方案：

```cpp
int x, y, r;
void f()
{
	ACCESS_ONCE(x) = r;
    ACCESS_ONCE(y) = 1;
}
```

到此，基本上就阐述完成了编译时内存乱序访问的问题。下面看看CPU会有怎样的行为。

# 运行时内存乱序访问

运行时，CPU本身是会乱序执行指令的。早期的处理器为有序处理器（in-order processors）,总是按开发者编写的顺序执行指令，如果指令的输入操作对象（input operands）不可用（通常由于需要从内存中获取），那么处理器不会转而执行那些输入操作对象可用的指令，而是等待当前输入操作对象可用。相比之下，**乱序处理器**（`out-of-order processors`）会先处理那些有**可用输入操作对象**的指令（而非顺序执行）从而避免了等待，提高了效率。现代计算机上，处理器运行的速度比内存快很多，有序处理器花在等待可用数据的时间里已可处理大量指令了。即便现代处理器会**乱序执行**，但在**单个CPU上**，指令能通过**指令队列顺序获取并执行**，结果利用**队列顺序返回寄存器堆**（详情可参考 http://en.wikipedia.org/wiki/Out-of-order_execution ），这使得程序执行时所有的内存访问操作看起来像是按程序**代码编写的顺序执行**的，因此内存屏障是没有必要使用的（前提是不考虑编译器优化的情况下）。

SMP架构需要内存屏障的进一步解释：从体系结构上来看，首先在**SMP架构**下，每个CPU与内存之间，都配有自己的高速缓存（Cache），以减少访问内存时的冲突

![2020-04-17-12-26-15.png](./images/2020-04-17-12-26-15.png)

采用**高速缓存**的**写操作**有两种模式：

(1). **穿透(Write through)模式**，每次写时，都**直接将数据写回内存**中，效率相对较低；

(2). **回写(Write back)模式**，写的时候先写回告诉缓存，然后由**高速缓存的硬件**再周转**复用缓冲线**(Cache Line)时自动将数据写回内存，或者由软件主动地“冲刷”有关的缓冲线(Cache Line)。

出于性能的考虑，系统往往采用的是**模式2**来完成**数据写入**。正是由于存在**高速缓存**这一层，正是由于采用了`Write back`模式的数据写入，才导致在**SMP架构**下，对高速缓存的运用可能改变对内存操作的顺序。

以上面的一个简短代码为例：

```cpp
// thread 0 -- 在CPU0上运行
x = 42;
ok = 1;

// thread 1 – 在CPU1上运行
while(!ok);
print(x);
```

这里CPU1执行时， **x一定是打印出42**吗？让我们来看看以下图为例的说明：

![2020-04-17-14-37-22.png](./images/2020-04-17-14-37-22.png)





# 参考

http://lday.me/2017/11/04/0016_what_is_memory_barriers/