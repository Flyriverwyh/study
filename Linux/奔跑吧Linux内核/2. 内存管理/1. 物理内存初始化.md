很多Linux内存管理从**malloc**()这个C函数开始，从而知道**虚拟内存**。**虚拟内存是什么，怎么虚拟**？早期系统没有虚拟内存概念，**为什么**现代OS都有？要搞清楚虚拟内存，可能需要了解**MMU、页表、物理内存、物理页面、建立映射关系、按需分配、缺页中断和写时复制**等机制。

MMU，除了MMU工作原理，还会接触到Linux内核**如何建立页表映射**，其中也包括**用户空间页表的建立**和**内核空间页表**的建立，以及内核是如何**查询页表和修改页表**的。

当了解**物理内存**和**物理页面**时，会接触到**struct pg\_data\_t、struct zone和 struct page**等数据结构，这3个数据结构描述了系统中**物理内存的组织架构**。struct page数据结构除了描述一个4KB大 小（或者其他大小）的物理页面外，还包含很多复杂而有趣的成员。

当了解**怎么分配物理页面**时，会接触到**伙伴系统机制**和**页面分配器**（**page allocator**),页面分配器是内存管理中最复杂的代码之一。

有了**物理内存**，那**怎么和虚拟内存建立映射关系**呢？在 Linux内核中，描述**进程的虚拟内存**用**struct vm\_area\_struct**数据结构。**虚拟内存**和**物理内存**采用**建立页表**的方法来**完成建立映射关系**。为什么**和进程地址空间建立映射的页面**有的叫**匿名页面**，而有的叫**page cache页面**呢？

当了解**malloC()怎么分配出物理内存**时，会接触到**缺页中断**，缺页中断也是内存管理中最复杂的代码之一。

这时，**虚拟内存和物理内存己经建立了映射关系**，这是**以页为基础**的，可是有时内核需要**小于一个页面**大小的内存，那么**slab机制**就诞生了。

上面己经建立起虚拟内存和物理内存的基本框图，但是如果用户**持续分配和使用内存**导致**物理内存不足**了怎么办？此时**页面回收机制**和**反向映射机制**就应运而生了。

虚拟内存和物理内存的映射关系经常是**建立后又被解除**了，时间长了，系统**物理页面布局变得凌乱**不堪，碎片化严重，这时内核如果需要**分配大块连续内存**就会变得很困难，那么**内存规整机制**（Memory Compaction) 就诞生了。

上面就是学习Linux内存管理的历程。

除了依照思考题阅读内存管理代码之外，从用户态API深入了解Linux内核的内存管理机制，下面就是常用用户态内存管理相关的API。

```
void *malloc(size_t size);
void free(void *ptr )；

void *mmap(void *addr, size_t length, int prot, int flags,
            int fd, off_t offset);
int munmap(void *addr, size_t length);

int getpagesize(void);

int mprotect(const void *addr, size_t len, int prot);

int mlock(const void *addr, size _t len);
int munlock(const void *addr, size_t len);

int madvise(void *addr, size_t length, int advice);
void *mremap(void *old_address, size_t old_size,
            size_t new_size/ int flags, ... /* void *new_address */);

int remap_file_pages(void *addr, size_t size, int prot,
            ssize__t pgoff, int flags);
```

整个第二章：

- 忽略对大页面的处理，默认省略CONFIG\_TRANSPARENT\_HUGEPAGE的支持
- 默认忽略对锁的讨论，锁在内存管理中应用见4.7
- 对page cache讨论较少
- 实验对象是ARM Vexpress平台，忽略对NUMA讨论
- 忽略对memory cgroup讨论

下面是该节目录

- 2.1 物理内存初始化

    - 2.1.1 内存管理概述

    - 2.1.2 内存大小

    - 2.1.3 物理内存映射

    - 2.1.4 zone初始化

    - 2.1.5 空间划分

    - 2.1.6 物理内存初始化

本节思考：

1. 在系统启动时，ARM Linux内核如何知道系统中有**多大的内存空间**？
2. 在32bit Linux内核中，**用户空间和内核空间的比例**通常是3:1,可以**修改**成2:2吗？
3. **物理内存页面**如何添加到**伙伴系统**中，是一页一页添加，还是以2的几次幂来加入呢？

现在大部分计算机使用**DDR**（Dual Data Rate SDRAM）的**存储设备**，DDR包括DDR3L、DDR4L、LPDDR3/4等。**DDR初始化**一般在**BIOS或boot loader中**，BIOS或boot loader将DDR大小传给内核，因此从**Linux内核角度**看其实就是**一段物理内存空间**。

## 1. 内存管理概述

分层描述的话，内存空间可以分为3个层次，分别是用户空间层、内核空间层和硬件层。如图2.1。

图2.1  内存管理框图：

![config](images/1.jpg)

用户空间和内核空间的接口是系统调用，因此内核空间层首先需要处理这些**内存管理相关**的**系统调用**，例如sys\_brk、sys\_mmap、sys\_madvise等。接下来就包括VMA管理、缺页中断管理、匿名页面、page cache、页面回收、反向映射、slab分配器、页表管理等模块了。

最下面是硬件层，包括处理器的MMU、TLB和cache部件，以及板载的物理内存，例如LPDDR或DDR。

## 2. 内存大小

ARM Linux中，**各种设备的相关属性描述**都**采用DTS方式**呈现。**DTS是device tree source**，最早由PowerPC等其他体系结构使用的FDT（Flattened Device Tree）转变的，ARM Linux社区自2011年被Linus公开批评后全面支持DTS。

在**ARM Vexpress**平台中，内存的定义在vexpress-v2p-ca9.dts文件中。该DTS文件定义了内存的起始地址为0x60000000,大小为0x40000000,即1GB大小内存空间。

```
[arch/arm/boot/dts/vexpress-v2p-ca9.dts]

memory@60000000 {
    device_type = "memory";
    reg = <0x60000000 0x40000000>;
};
```

内核启动中，需要解析这些DTS文件，在early\_init\_dt\_scan\_memory()函数中。代码调用关系是：start\_kernel()\->setup\_arch()\->setup\_machine\_fdt()\->early\_init\_dt\_scan\_nodes()\->early\_init\_scan\_memory()。

```
[drivers/of/fdt.c]

int _init early_init_dt_scan_memory(unsigned long node, const char *uname,
                        int depth, void *data)
{
    const char *type = of_get_flat_dt_prop (node, "device_type", NULL);
    const _be32 *reg, *endp;
    int l;
    
    if (strcmp(type, "memory") != 0)  #重要：匹配memory
        return 0;
        
    reg = of_get_flat_dt_prop(node, "reg", &l);  #重要：取得reg
    endp = reg + (l / sizeof(_be32));
    
    while ((endp - reg) >= (dt_root_addr_cells + dt_root_size_cells)) {
        u64 base, size ；
        
        base = dt_mem_next_cell(dt_root_addr cells, &reg);
        size = dt_mem_next_cell(dt_root_size cells, &reg);
        
        if (size == 0)
            continue;
            
        early_init_dt_add_memory_arch(base, size); #重要
    }
    return 0;
}
```

解析 “memory” 描述的信息从而**得到内存的base\_address和 size信息**，最后**内存块信息**通过early\_init\_dt\_add\_memory\_arch()\-〉memblock\_add()函数**添加到memblock子系统**中。

## 3. 物理内存映射

在内核**使用内存前**，需要**初始化内核的页表**，初始化页表主要在**map\_lowmem**()函数中。在**映射页表之前**，需要**把页表的页表项清零**，主要在**prepare\_page\_table**()函数中实现。

```
[start_kemel() ->setup_arch() ->paging_init()]


static inline void prepare_page_table(void)
{
    unsigned long addr ；
    phys_addr_t end;
    
    /*
     * Clear out all the mappings below the kernel image.
     */
    for (addr = 0; addr < MODULES_VADDR; addr += PMD_SIZE)
        pmd_clear(pmd_off_k(addr));        # 重要
        
    for ( ; addr < PAGE_OFFSET; addr += PMD_SIZE)
        pmd_clear(pmd_off_k(addr));       # 重要
    
    /*
     * Find the end of the first block of lowrnem.
     */
    end = memblock.memory.regions[0].base + memblock.memory.regions[0].size;
    /*
     * Clear out all the kernel space mappings, except for the first
     * memory bank, up to the vmalloc region.
     */
    for (addr = _ phys_to_virt (end);
        addr < VMALLOC_START; addr += PMD_SIZE)
        pmd_clear(pmd_off_k(addr));         # 重要
}
```

这里对如下3段地址调用pmd\_clear()函数来**清除一级页表项**的内容。

- 0x0\~MODULES\_VADDR。
- MODULES\_VADDR\~PAGE_OFFSET。
- arm\_lowmem\_limit\~VMALLOC\_START。

```
[start_kernel() ->setup_arch() ->paging_init() ->map_lowmem()]

static void  __init map_lowmem(void)
{
    struct memblock_region *reg;
    phys_addr_t kernel_x_start = round_down(__pa(_stext), SECTION_SIZE);
    phys_addr_t kernel_x_end = round_up(__pa(__init_end), SECTION_SIZE);
    
    /* Map all the 1owmem memory banks.  */
    for_each_memblock(memory, reg) {
        phys_addr_t start = reg->base;
        phys_addr_t end = start + reg->size;
        struct map_desc map;
        
        if (end > arm_1owmem_limit)
            end = arm_1owmem_limit;
        
        //映射kernel image区域
        map.pfn =  __phys_to_pfn(kernel_x_start);
        map.virtual = __phys_to_virt(kernel_x_start)；
        map.length = kernel_x_end - kernel_x_start;
        map.type = MT_MEMORY_RWX；
        
        create_mapping(&map);    # 重要
        
        //映射低端内存
        if (kernel_x_end < end) {
            map.pfn = __phys_to_pfn(kernel_x_end);
            map.virtual = __phys_to_virt(kernel_x_end);
            map.length = end - kernel_x_end;
            map.type = MT_MEMORY_RW;
            
            create_mapping(&map);
        }
    }
}
```

真正创建页表是在**map\_lowmem()函数**中，会从内存开始的地方覆盖到arm\_lowmem\_limit处。这里需要考虑kernel代码段的问题，kernel的代码段从\_stext幵始，到\_init\_end结束。以ARM Vexpress平台为例。

- 内存开始地址0x60000000。
- \_stext: 0x60000000。
- \_init\_end: 0x60800000（该值与实际内核配置和image大小相关）。
- arm\_lowmem\_limit: 0x8f800000。

其中，arm\_lowmem\_limit地址需要考虑高端内存的情况，该值的计算是在sanity\_check\_meminfo()函数中。在ARM Vexpress平台中，arm\_lowmem\_limit等于vmalloc\_min，其定义如下:

```
static void * __initdata vmalloc_min =
    (void *) (VMALLOC_END - (240 « 20) - VMALLOC_OFFSET);

phys_addr_t vmalloc_limit = __pa(vmalloc_min - 1) + 1 
```

map\_lowmem()会对两个内存区间创建映射。

（1）区间1

- 物理地址：0x60000000\~0x60800000。
- 虚拟地址：0xc0000000\~0xc0800000。
- 属性：可读、可写并且可执行（MT\_MEMORY\_RWX）。

（2）区间2

- 物理地址：0x60800000\~0x8f800000。
- 虚拟地址：0xc0800000\~0xef800000。
- 属性：可读、可写（MT\_MEMORY\_RW )。

MT\_MEMORY\_RWX和MT\_MEMORY\_RW的区别在于ARM页表项有一个XN比特位，XN比特位置为1 , 表示这段内存区域不允许执行。

映射函数为create\_mapping(),这里创建的映射就是物理内存直接映射，或者叫作线性映射，该函数会在第2.2节中详细介绍。

## 4. zone初始化

对页表的初始化完成之后，内核就可以对内存进行管理了，但是内核并不是统一对待
这些页面，而是采用区块zone的方式来管理。struct zone数据结构的主要成员如下：

```
struct zone {
    /* Read-mostly fields */
            
    /* zone watermarks, access with *_wmark_pages(zone) macros */
    unsigned long watermark[NR_WMARK];
    long lowmem_reserve[MAX_NR_ZONES];
            
#ifdef CONFIG_NUMA
    int node;
#endif      
    struct pglist_data  *zone_pgdat;
    struct per_cpu_pageset __percpu *pageset;
 
    /* zone_start_pfn == zone_start_paddr >> PAGE_SHIFT */
    unsigned long       zone_start_pfn;
    unsigned long       managed_pages;
    unsigned long       spanned_pages;
    unsigned long       present_pages;

    const char      *name;

    /* Write-intensive fields used from the page allocator */
    ZONE_PADDING(_pad1_)           ## 重要
    /* free areas of different sizes */
    struct free_area    free_area[MAX_ORDER];
    /* zone flags, see below */
    unsigned long       flags;
    /* Primarily protects free_area */
    spinlock_t      lock;         ## 重要

    /* Write-intensive fields used by compaction and vmstats. */
    ZONE_PADDING(_pad2_)
    spinlock_t  lru_lock;         ## 重要
    struct lruvec  lruvec;         ## 重要
    
    ZONE_PADDING(_pad3_)         ## 重要
    /* Zone statistics */
    atomic_long_t       vm_stat[NR_VM_ZONE_STAT_ITEMS];
} ____cacheline_internodealigned_in_smp;
```

首先struct zone是经常会被访问到的，因此这个数据结构要求**以L1 Cache对齐**。另外，这里的**ZONE\_PADDING**()是让zone->lock和zone->lru\_lock这两个很热门的锁可以分布在不同的cache line中。**一个内存节点最多也就几个zone**，因此zone数据结构**不需要**像**struct page**—样关注**数据结构的大小**，因此这里ZONE\_PADDING()可以**为了性能而浪费空间**。在内存管理开发过程中，内核开发者逐步发现有一些**自旋锁**会**竞争**得非常厉害，**很难获取**。像zone->lock和zone->lru_lock这两个锁有时需要**同时获取锁**，因此保证它们**使用不同的cache line**是内核常用的一种优化技巧。

- watermark: 每个zone在系统启动时会计算出3个水位值，分别是WMARK\_MIN、WMARK\_LOW和WMARK\_HIGH水位，这在**页面分配器**和**kswapd页面回收**中会用到。
- lowmem\_reserve: zone中预留的内存。
- zone\_pgdat: 指向**内存节点**。
- pageset: 用于维护Per-CPU上的**一系列页面**，以**减少自旋锁的争用**。
- zone\_start_pfn: zone中**开始页面**的**页帧号**。
- managed\_pages: zone中被**伙伴系统管理**的**页面数量**。
- spanned\_pages: zone包含的**页面数量**。
- present\_pages: zone里**实际管理的页面数量**。对一些体系结构来说，其值和spanned\_pages相等。
- free\_area: 管理**空闲区域的数组**，包含管理链表等。
- lock: 并行访问时用于对**zone保护的自旋锁**。
- lru\_lock: 用于对zone中**LRU链表**并行访问时进行保护的**自旋锁**。
- lruvec: **LRU链表集合**。
- vm_stat：**zone计数**。

通常情况下，内核的zone分为ZONE\_DMA、ZONE\_DMA32、ZONE\_NORMAL和ZONE\_HIGHMEM。在ARM Vexpress平台中，没有定义CONFIG\_ZONE\_DMA和CONFIG\_ZONE\_DMA32,所以只有ZONE\_NORMAL和ZONE\_HIGHMEM两种。zone类型的定义在include/linux/mmzone.h 文件中。

```
enum zone_type {
    ZONE_NORMAL,
#ifdef CONFIG_HIGHMEM
    ZONE_HIGHMEM,
#endif
    ZONE_MOVABLE,
    _MAX_NR_ZONES
}；
```

**zone的初始化函数**集中在**bootmem\_init**()中完成，所以需要确定**每个zone的范围**。在**find\_limits**()函数中会计算出min\_low\_pfn、max\_low\_pfn和max\_pfn这3个值。其中，min\_low\_pfn是**内存块**的**开始地址**的**页帧号**（0x60000)，max\_low\_pfn(0x8f800)表示**normal区域**的**结束页帧号**，它由arm\_lowmem\_limit这个变量得来，max\_pfn(Oxa0000) 是**内存块**的**结束地址的页帧号**。

下面是ARM Vexpress平台运行之后打印出来的zone的信息。

```
Normal zone: 1520 pages used for memmap
Normal zone: 0 pages reserved
Normal zone: 194560 pages, LIFO batch:31 //ZONE_NORMAL
HighMem zone: 67584 pages, LIFO batch:15 //ZONE_HIGHMEM

Virtual kernel memory layout:
    vector  : 0xffff0000 - 0xffff1000       (   4 KB)
    fixmap  ： 0xffc00000 - 0xfff00000      (3072 KB)
    vmalloc : 0x£0000000 - 0xff000000       ( 240 MB)
    lowmem : 0xc0000000 - 0xef800000        ( 760 MB)
    pkmap  : 0xbfe00000 - 0xc0000000        (   2 MB)
    modules  ： 0xbf000000 - 0xbfe00000     (  14 MB)     
    .text : 0xc0008000 - 0xc0676768         (6586 KB)
    .init : 0xc0677000 - 0xc07a0000         (1188 KB)
    .data : 0xc07a0000 - 0xc07cf938         ( 191 KB)
    .bss : 0xc07cf938 - 0xc07f9378          ( 167 KB)
```

可以看出ARM Vexpress平台分为两个zone，ZONE\_NORMAL和ZONE\_HIGHMEM。其中ZONE\_NORMAL是从0xc0000000到0xef800000，这个地址空间有多少个页面呢？

```
(Oxef800000 - Oxc0000000 ) / 4096 = 194560
```

所以ZONE_NORMAL有194560个页面。

另外ZONE\_NORMAL的虚拟地址的结束地址是Oxef800000, 减去PAGE\_OFFSET(Oxc00000)，再加上PHY\_OFFSET(0x60000000)，正好等于 0x8f80\_0000,这个值等于我们之前计算出的arm\_lowmem\_limit。

zone的初始化函数在free\_area\_init\_core()中。

```
[start_kernel->setup_arch->paging_init->bootmem_init->zone_sizes_init->free_area_init_node -> free_area_init_core]

```

另外系统中会有一个**zondist的数据结构**,**伙伴系统**分配器会**从zonelist开始分配内存**，zonelist有一个**zoneref数组**，数组里有一个成员会**指向zone数据结构**。zoneref数组的第一个成员指向的zone是页面分配器的第一个候选者，其他成员则是第一个候选者分配失败之后才考虑，**优先级逐渐降低**。zonelist的初始化路径如下：

```
[start_kernel->build_all_zonelists->build_all_zonelists_init-> 
__build_all_zonelists->build_zonelists->build_zonelists_node]

static int build_zonelists_node(pg_data_t *pgdat, struct zonelist *zonelist,
                    int nr_zones)
{
    struct zone *zone;
    enum zone_type zone_type = MAX_NR_ZONES;
    
    do {
        zone_type--;
        zone = pgdat->node_zones + zone_type;
        if (populated_zone(zone)) {
            zoneref_set_zone(zone,
                &zonelist->_zonerefs[nr_zones++]);
            check_highest_zone (zone_type);
        }
    } while (zone_type);
    
    return nr_zones;
}
```

从最高的MAX\_NR\_ZONES的zone开始，设置到_zonerefs[0]数组中。在ARM Vexpress平台中，运行结果如下：

```
HighMem  _zonerefs[0]->zone_index=l
Normal   _zonerefs[1]->zone_index=0
```

这个页面分配器在2.4会讲。

另外，系统中还有一个非常重要的**全局变量mem_map**，它是一个**struct page的数组**，可以实现快速地把**虚拟地址**映射到**物理地址**中，这里指**内核空间的线性映射**，它的初始化是在 free\_area\_init\_node()->alloc\_node\_mem\_map()函数中。

## 5. 空间划分

在32bit Linux中 ，一共能使用的**虚拟地址空间是4GB**,用户空间和内核空间的划分通常是按照3:1来划分，也可以按照2:2来划分。

```
[arch/arm/Kconfig]

choice
    prompt "Memory split"
    depends on MMU
    default VMSPLIT_3G
    help 
      Select the desired split between kernel and user memory.
    
      If you are not absolutely sure what you are doing, leave this 
      option alone!
    
    config VMSPLIT_3G
        bool "3G/1G user/kernel split"
    config VMSPLIT_3G_OPT
        depends on !ARM_LPAE
        bool "3G/1G user/kernel split (for full 1G low memory)"
    config VMSPLIT_2G                     ### !!!  
        bool "2G/2G user/kernel split"
    config VMSPLIT_1G
        bool "1G/3G user/kernel split"
endchoice
    
config PAGE_OFFSET
    hex
    default PHYS_OFFSET if !MMU
    default 0x40000000 if VMSPLIT_1G
    default 0x80000000 if VMSPLIT_2G
    default 0xB0000000 if VMSPLIT_3G_OPT
    default 0xC0000000
```

在 ARM Linux中有一个配置选项“memory split”，可以用于**调整内核空间和用户空间的大小划分**。通常使用“VMSPLIT\_3G”选项，用户空间大小是3GB , 内核空间大小是1GB ,那么**PAGE\_OFFSET**描述**内核空间的偏移量**就等于**0xC0000000**(**等于2\^31+2\^30=3GB**)。也可以选择“VMSPLIT\_2G”选项，这时内核空间和用户空间的大小都是2GB,PAGE\_OFFSET就等于**0x80000000**(**等于2\^31=2GB**)。

内核中通常会使用**PAGE\_OFFSET这个宏**来计算**内核线性映射中虚拟地址和物理地址的转换**。

```
[arch/arm/include/asm/memory.h]

/* PAGE_OFFSET - the virtual address of the start of the kernel image */
#define PAGE_OFFSET  UL(CONFIG_PAGE_OFFSET)
```

线性映射的**物理地址**等于虚拟地址vaddr减去PAGE\_OFFSET (0xC000\_0000)再加上PHYS\_OFFSET(在
部分ARM系统中该值为0)。

```
[arch/arm/include/asm/memory.h]

static inline phys_addr_t __virt_to_phys_nodebug(unsigned long x)
{
    return (phys_addr_t)x - PAGE_OFFSET + PHYS_OFFSET;
}

static inline unsigned long __phys_to_virt(phys_addr_t x)
{
    return x - PHYS_OFFSET + PAGE_OFFSET;
}
```

## 6. 物理内存初始化

在内核启动时，内核知道物理内存DDR的大小并且计算出**高端内存**的**起始地址**和**内核空间的内存布局**后，物理内存页面page就要加入到伙伴系统中，那么**物理内存页面**如何添加到**伙伴系统**中呢？

伙伴系统(**Buddy System**)是操作系统中最常用的一种**动态存储管理方法**，在用户提出申请时，分配一块大小合适的内存块给用户，反之在用户释放内存块时回收。在伙伴系统中，**内存块是2的order次幂**。Linux内核中**order的最大值用MAX\_ORDER**来表示，通常是11,也就是把所有的空闲页面分组成**11个内存块链表**，每个内存块链表分别包括1、2、4、8、16、32、…、1024个**连续的页面**(**连续页面！！！**)。**1024个页面对应着4MB大小的连续物理内存**。

**物理内存**在Linux内核中分出**几个zone**来管理，zone根据内核的配置来划分，例如在ARM Vexpress平台中，zone分为ZONE\_NORMAL和ZONE\_HIGHMEM。

伙伴系统的空闲页块的管理如图2.2所示，zone数据结构中有一个**free\_area数组**，**数组的大小是MAX\_ORDER**。free\_area数据结构中包含了**MIGRATE\_TYPES个链表**，这里相当于zone中根据order的大小有0到MAX\_ORDER - l个free\_area，每个free\_area根据MIGRATE\_TYPES类型有几个相应的链表。

图2.2  伙伴系统的空闲页块管理:

![config](images/2.jpg)

```
[include/linux/mmzone.h]

struct zone{
    ...
    /* free areas of different sizes */
    struct free_area    free_area[MAX_ORDER];
    ...
};

struct free_area {
    struct list_head    free_list[MIGRATE_TYPES];
    unsigned long       nr_free;
};
```

MIGRATE\_TYPES 类型的定义也在mmzone.h 文件中。

```
[include/1inux/mmzone.h]

enum migratetype {
    MIGRATE_UNMOVABLE,
    MIGRATE_MOVABLE,
    MIGRATE_RECLAIMABLE,
    MIGRATE_PCPTYPES,   /* the number of types on the pcp lists */
    MIGRATE_HIGHATOMIC = MIGRATE_PCPTYPES,
#ifdef CONFIG_CMA
    MIGRATE_CMA,
#endif
#ifdef CONFIG_MEMORY_ISOLATION
    MIGRATE_ISOLATE,    /* can't allocate from here */
#endif
    MIGRATE_TYPES
};
```

MIGRATE\_TYPES 类型包含MIGRATE\_UNMOVABLE、MIGRATE\_RECLAIMABLE、MIGRATE\_MOVABLE等几种类型。当前页面分配的状态可以从**/proc/pagetypeinfo**中获取得到。

图2.3  ARM Vexpress平台pagetypeinfo信息:

![config](images/3.png)

从 pagetypeinfo可以看出两个特点：

- 大部分物理内存页面都存放在MIGRATE\_MOVABLE链表中。
- 大部分物理内存页面初始化时存放在2的10次幂的链表中。

Linux内核初始化时究竟有多少页面是MIGRATE\_MOVABLE?

内存管理中有一个**pageblock**的概念，一个pageblock的大小通常是（MAX\_ORDER - l)个页面。如果体系结构中提供了**HUGETLB\_PAGE**特性，那么pageblock\_order定义为HUGETLB\_PAGE\_ORDER。

```
[include/linux/pageblock-flags.h]

#ifdef CONFIG_HUGETLB_PAGE

#ifdef CONFIG_HUGETLB_PAGE_SIZE_VARIABLE
 
/* Huge page sizes are variable */
extern unsigned int pageblock_order;
 
#else /* CONFIG_HUGETLB_PAGE_SIZE_VARIABLE */
 
/* Huge pages are a constant size */
#define pageblock_order     HUGETLB_PAGE_ORDER
#endif /* CONFIG_HUGETLB_PAGE_SIZE_VARIABLE */
 
#else /* CONFIG_HUGETLB_PAGE */
 
/* If huge pages are not used, group by MAX_ORDER_NR_PAGES */
#define pageblock_order     (MAX_ORDER-1)
 
#endif /* CONFIG_HUGETLB_PAGE */
```

**每个pageblock**有一个**相应的MIGRATE\_TYPES类型**。**zone数据结构**中有一个成员指针**pageblock\_flags**,它指向用于存放**每个pageblock**的**MIGRATE\_TYPES类型的内存空间**。pageblock\_flags指向的内存空间的大小通过usemap\_size()函数来计算，每个pageblock用4个比特位来存放MIGRATE\_TYPES类型。

zone的初始化函数free\_area\_init\_core()会调用setup\_usemap()函数来计算和分配pageblock\_flags所需要的大小，并且分配相应的内存。

```
[free_area_init_core -> setup_usemap -> usemap_size]

[mm/page_alloc.c]

static unsigned long __init usemap_size(unsigned long zone_start_pfn, unsigned long zonesize)
{   
    unsigned long usemapsize;   
    
    zonesize += zone_start_pfn & (pageblock_nr_pages-1);
    usemapsize = roundup(zonesize, pageblock_nr_pages);
    usemapsize = usemapsize >> pageblock_order;
    usemapsize *= NR_PAGEBLOCK_BITS;
    usemapsize = roundup(usemapsize, 8 * sizeof(unsigned long));
    
    return usemapsize / 8;
}
```

usemap\_size()函数**首先计算zone有多少个pageblock**,每个pageblock需要4bit来存放MIGRATE\_TYPES类型，最后可以计算出需要多少Byte。然后通过memblock\_virt\_alloc\_try\_nid\_nopanic()来分配内存，并且zone->pageblock\_flags成员指向这段内存。

例如在ARM Vexpress平台，ZONE\_NORMAL的大小是760MB，每个pageblock大小是4MB,那么就有190个pageblock,每个pageblock的MIGRATE_TYPES类型需要4bit,所以管理这些pageblock，需要96Byte。

内核有两个函数来管理这些迁移类型：get\_pageblock\_migratetype()和set\_pageblock\_migratetype()。内核初始化时所有的页面最初都标记为MIGRATE\_MOVABLE类型，见free\_area\_init\_core()->memmap\_init()函数。

```
[start_kernel()->setup_arch()->paging_init()->bootmem_init()->zone_sizes_init()
->free_area_init_node()->free_area_init_core()->memmap_init()]

void __meminit memmap_init_zone (unsigned long size, int nid, unsigned long zone,
        unsigned long start_jpfn, enum memmap_context context)
{
    struct page *page;
    unsigned long end_pfn = start_pfn + size;
    unsigned long pfn;
    struct zone *z;
    
    z =  &NODE_DATA (nid) ->node zones [zone];
    for (pfn = start_pfn; pfn < end_pfn; pfn++) {
        page = pfn_to._page (pfn)；
        init_page_count(page);
        page_mapcount_reset(page);
        page_cpupid—reset—last(page);
        SetPageReserved(page);
        
        if ((z->zone_start_pfn <= pfn)
            && (pfn < zone end_pfn(z))
            && ! (pfn & (pageblock_nr_pages - 1)))
            set_pageblock_migratetype  (page, MIGRATE_MOVABLE);
        
        INIT_LIST_HEAD(&page->lru);
    }
}
```

set\_pageblock\_migratetype()用于设置指定pageblock的MIGRATE\_TYPES类型，最后调用set\_pfnblock\_flags\_mask()来设置pagelock的迁移类型。

**物理页面是如何加入到伙伴系统的？是一页一页地添加，还是以2的几次幂来加入吗**？

在free\_low\_memory\_core\_early()函数中，通过for\_each\_free\_mem\_range()函数来遍历所有的memblock内存块，找出内存块的起始地址和结束地址。

```
[staxt_kemel-> mm_init-> mem_init-> free_all_bootmem-> free_low_memory_core_early]

[mm/nobootmem.c]

static unsigned long __init free_low_memory_core_early(void)
{   
    unsigned long count = 0;
    phys_addr_t start, end;
    u64 i;
    
    memblock_clear_hotplug(0, -1);
    
    for_each_free_mem_range(i, NUMA_NO_NODE, &start, &end,NULL)
        count += __free_memory_core(start, end);
    
    return count;
}
```

把内存块传递函数中 ，该函数定义如下：

```
[mm/nobootmem.c]

static inline unsigned long _ffs(unsigned long x)
{
    return ffs(x) - 1;
}

static void __init __free_pages_memory(unsigned long start, unsigned long end) 
{    
    int order;
     
    while (start < end) {
        order = min(MAX_ORDER - 1UL, __ffs(start));
     
        while (start + (1UL << order) > end) 
            order--;
     
        __free_pages_bootmem(pfn_to_page(start), start, order);
        start += (1UL << order);   
    }
}
```

注意这里参数start和end指页帧号，while循环一直从起始页帧号start遍历到end，循环的步长和order有关。首先计算order的大小，取MAX\_ORDER-l 和\_\_ffs(start)的最小值。ffs(start)函数计算start中第一个bit为 1 的位置，注意\_\_ffs() = ffs()-1。因为伙伴系统的链表都是2的A7次幂,最大的链表是2的10次方，也就是1024,即0x400。所以，通过ffs()函数可以很方便地计算出地址的对齐边界。例如start等于0x63300，那么\_\_ffs(0x63300)等于8，那么这里order选用8。

得到order值后，我们就可以把这块内存通过\_\_free\_pages\_bootmem()函数添加到伙伴系统了。

```
void __init __free_pages_bootmem(struct page *page, unsigned int order)
{
    unsigned int nr_pages = 1 << order;
    struct page *p = page;
    
    page_zone(page)->managed_pages += nr_pages;
    set_page_refcounted (page);
    __free_pages(page, order};
}
```

\_\_free\_pages()函数是伙伴系统的核心函数，这里按照order的方式添加到伙伴系统中，该函数在第2.4节中会详细介绍。

下面是向系统中添加一段内存的情况，页帧号范围为[0x8800e, Oxaecea]，以start为起始来计算其order，一开始order的数值还比较凌乱，等到start和 0x400对齐，以后基本上order都取值为10 了，也就是都挂入order为 10的 free\_list链表中。

```
__free_pages_memory： start=0x8800e, end=0xaecea

__free_pages_memory： start=0x8800e, order=1, __ffs()=1, ffs()=2
__free_pages_memory： start=0x88010, order=4, __ffs()=4, ffs()=5
__free_pages_memory： start=0x88020, order=5, __ffs()=5, ffs()=6
__free_pages_memory： start=0x88040, order=6, __ffs()=6, ffs()=7
__free_pages_memory： start=0x88080, order=7, __ffs()=7, ffs()=8
__free_pages_memory： start=0x88100, order=8, __ffs()=8, ffs()=9
__free_pages_memory： start=0x88200, order=9, __ffs()=9, ffs()=10
__free_pages_memory： start=0x88400, order=10, __ffs()=10, ffs()=11
__free_pages_memory： start=0x88800, order=10, __ffs()=11, ffs()=12
__free_pages_memory： start=0x88c00, order=10, __ffs()=10, ffs()=11
__free_pages_memory： start=0x89000, order=10, __ffs()=12, ffs()=13
__free_pages_memory： start=0x89400, order=10, __ffs()=10, ffs()=11
__free_pages_memory： start=0x89800, order=10, __ffs()=11, ffs()=12
__free_pages_memory： start=0x89c00, order=10, __ffs()=10, ffs()=11
```