
<!-- @import "[TOC]" {cmd="toc" depthFrom=1 depthTo=6 orderedList=false} -->

<!-- code_chunk_output -->

- [1. Docker支持的4类网络模式](#1-docker支持的4类网络模式)
- [2. Bridge模式](#2-bridge模式)
  - [2.1. 虚拟网桥docker0](#21-虚拟网桥docker0)
  - [2.2. 容器的veth设备对](#22-容器的veth设备对)
  - [2.3. docker的默认桥接网络模型](#23-docker的默认桥接网络模型)
  - [2.4. 容器跨节点通信](#24-容器跨节点通信)
- [3. 查看Docker启动后的系统情况(未启动容器)](#3-查看docker启动后的系统情况未启动容器)
- [4. 查看容器启动后的情况(容器无端口映射)](#4-查看容器启动后的情况容器无端口映射)
- [5. 查看容器启动后的情况（容器有端口映射）](#5-查看容器启动后的情况容器有端口映射)
  - [5.1. Docker的网络局限](#51-docker的网络局限)

<!-- /code_chunk_output -->

# 1. Docker支持的4类网络模式

标准的Docker支持以下4类网络模式。

* host模式：使用\-\-net=host指定。
* container模式：使用\-\-net=container:NAME\_or\_ID指定。
* none模式：使用\-\-net=none指定。
* bridge模式：使用\-\-net=bridge指定，为**默认设置**。

# 2. Bridge模式

在**Kubernetes管理模式**下通常**只会使用bridge模式**，所以本节只介绍在bridge模式下Docker是如何支持网络的。

## 2.1. 虚拟网桥docker0

在**bridge模式**下，Docker Daemon**第1次启动**时会**创建一个虚拟的网桥！！！**，**默认的名称**是**docker0**，然后按照**RPC1918的模型**在**私有网络空间！！！** 中给**这个网桥**分配一个**子网**。

## 2.2. 容器的veth设备对

针对由**Docker**创建的**每一个容器**，都会创建一个**虚拟的以太网设备（Veth设备对**），其中**一端关联到网桥**上，另一端使用**Linux的网络命名空间技术！！！**，映射到**容器内的eth0设备**，然后从**网桥的地址段！！！** 内给eth0接口分配一个IP地址。

## 2.3. docker的默认桥接网络模型

如图7.6所示就是Docker的**默认桥接网络模型**。

![2019-09-19-11-32-43.png](./images/2019-09-19-11-32-43.png)

其中**ip1**是**网桥的IP地址**，Docker Daemon会在**几个备选地址段**里给它选一个地址，通常是以**172开头**的一个地址。这个地址和主机的IP地址是**不重叠**的。

**ip2**是Docker在**启动容器**时，在这个地址段选择的一个没有使用的IP地址分配给容器。相应的**MAC地址**也**根据这个IP地址**，在**02:42:ac:11:00:00**和**02:42:ac:11:ff:ff**的范围内生成，这样做可以确保**不会有ARP冲突**。

启动后，Docker还将**Veth对**的名称映射到**eth0网络接口**。**ip3**就是**主机的网卡地址**。

在一般情况下，ip1、ip2和ip3是**不同的IP段**，所以在默认不做任何特殊配置的情况下，在**外部是看不到ip1和ip2的！！！**。

这样做的结果就是，在**同一台机器内**的**容器之间**可以**相互通信**，**不同主机**上的**容器不能相互通信**，实际上它们甚至有可能在相同的网络地址范围内（不同主机上的docker0的地址段可能是一样的）。

## 2.4. 容器跨节点通信

为了让它们**跨节点互相通信**，就必须在**主机的地址**上**分配端口**，然后通过这个**端口路由**或**代理到容器**上。这种做法显然意味着一定要在**容器之间**小心谨慎地协调好**端口的分配**，或者使用**动态端口的分配技术**。

在不同应用之间协调好端口分配是十分困难的事情，特别是集群水平扩展时。

而**动态的端口分配**也会带来高度复杂性，例如：每个应用程序都**只能将端口看作一个符号**（因为是动态分配的，所以**无法提前设置**）。

而且API Server要在分配完后，将动态端口插入配置的合适位置，服务也必须能互相找到对方等。这些都是Docker的网络模型在跨主机访问时面临的问题。

# 3. 查看Docker启动后的系统情况(未启动容器)

**Docker网络**在**bridge模式**下Docker Daemon启动时**创建docker0网桥**，并在网桥使用的网段为容器分配IP。让我们看看实际的操作。

在**刚刚启动Docker Daemon**并且**还没有启动任何容器**时，网络协议栈的配置情况如下：

![2019-09-19-12-03-52.png](./images/2019-09-19-12-03-52.png)

![2019-09-19-12-03-57.png](./images/2019-09-19-12-03-57.png)

可以看到，Docker创建了**docker0网桥**，并添加了**iptables规则**。

**docker0网桥**和**iptables规则**都处于**root命名空间**中。

通过解读这些规则，我们发现，在还**没有启动任何容器**时，如果**启动了D1ocker Daemon**，那么它已经做好了**通信准备**。对这些规则的说明如下。

（1）在**NAT表**中有**3条记录**，**前两条匹配生效**后，都会继续执行**DOCKER链**，而此时DOCKER链为空，所以前两条只是做了一个框架，并没有实际效果。

（2）**NAT表**第3条的含义是，若**本地发出的数据包不是发往docker0**的，即是发往**主机之外的设备**的，则都需要进行**动态地址修改（MASQUERADE！！！**），将**源地址**从**容器的地址（172段**）修改为**宿主机网卡的IP地址**，之后就可以发送给外面的网络了。

（3）在**FILTER表**中，第1条也是一个框架，因为后继的DOCKER链是空的。

（4）在FILTER表中，第3条是说，docker0发出的包，如果需要Forward到非docker0的本地IP地址的设备，则是允许的。这样，docker0设备的包就可以根据路由规则中转到宿主机的网卡设备，从而访问外面的网络。

（5）FILTER表中，第4条是说，docker0的包还可以被中转给docker0本身，即连接在docker0网桥上的不同容器之间的通信也是允许的。

（6）FILTER表中，第2条是说，如果接收到的数据包属于以前已经建立好的连接，那么允许直接通过。这样接收到的数据包自然又走回docker0，并中转到相应的容器。

除了这些Netfilter的设置，Linux的ip\_forward功能也被Docker Daemon打开了：

```
# cat /proc/sys/net/ipv4/ip_forward
1
```

另外，我们可以看到刚刚启动Docker后的Route表，和启动前没有什么不同：

![2019-09-19-14-03-40.png](./images/2019-09-19-14-03-40.png)

# 4. 查看容器启动后的情况(容器无端口映射)

刚才查看了Docker服务启动后的网络情况。现在**启动一个Registry容器**（不使用任何端口镜像参数），看一下网络堆栈部分相关的变化：

![2019-09-19-14-09-40.png](./images/2019-09-19-14-09-40.png)

![2019-09-19-14-09-46.png](./images/2019-09-19-14-09-46.png)

![2019-09-19-14-10-50.png](./images/2019-09-19-14-10-50.png)

可以看到如下情况。

（1）宿主机器上的Netfilter和路由表都没有变化，说明在不进行端口映射时，Docker的默认网络是没有特殊处理的。相关的NAT和FILTER这两个Netfilter链还是空的。

（2）宿主机上的Veth对已经建立，并连接到容器内。

我们再次进入刚刚启动的容器内，看看网络栈是什么情况。容器内部的IP地址和路由如下：

![2019-09-19-14-42-30.png](./images/2019-09-19-14-42-30.png)

可以看到，默认停止的回环设备lo已经被启动，外面宿主机连接进来的Veth设备也被命名成了eth0，并且已经配置了地址172.17.0.10。

路由信息表包含一条到docker0的子网路由和一条到docker0的默认路由。

# 5. 查看容器启动后的情况（容器有端口映射）

下面用带端口映射的命令启动registry：

```
docker run --name register -d -p 1180:5000 registry
```

在启动后查看iptables的变化：

![2019-09-19-14-44-51.png](./images/2019-09-19-14-44-51.png)

从**新增的规则**可以看出，**Docker服务**在**NAT**和**FILTER两个表**内添加的**两个DOCKER子链**都是给**端口映射**用的。

在本例中我们需要把**外面宿主机**的**1180端口**映射到**容器**的**5000端口**。通过前面的分析我们知道，无论是**宿主机接收到**的还是**宿主机本地协议栈发出**的，**目标地址**是**本地IP地址**的包都会经过**NAT表中的DOCKER子链**。Docker为**每一个端口映射**都在**这个链**上增加了到**实际容器目标地址和目标端口的转换**。

经过这个DNAT的规则修改后的IP包，会重新经过路由模块的判断进行转发。由于目标地址和端口已经是容器的地址和端口，所以数据自然就被转发到docker0上，从而被转发到对应的容器内部。

当然在Forward时，也需要在DOCKER子链中添加一条规则，如果目标端口和地址是指定容器的数据，则允许通过。

在Docker按照端口映射的方式启动容器时，**主要的不同**就是上述**iptables部分**。而**容器内部**的**路由和网络设备**，都和不做端口映射时一样，没有任何变化。

## 5.1. Docker的网络局限

我们从Docker对Linux网络协议栈的操作可以看到，**Docker**一开始**没有考虑**到**多主机互联**的网络解决方案。

Docker一直以来的理念都是“简单为美”，几乎所有尝试Docker的人都被它“用法简单，功能强大”的特性所吸引，这也是Docker迅速走红的一个原因。

我们都知道，**虚拟化技术**中最为复杂的部分就是**虚拟化网络技术**，即使是单纯的物理网络部分，也是一个门槛很高的技能领域，通常只被少数网络工程师所掌握，所以我们可以理解结合了物理网络的虚拟网络技术有多难。在**Docker之前**，所有接触过OpenStack的人都对其网络问题讳莫如深，Docker明智地避开这个“雷区”，让其他专业人员去用现有的虚拟化网络技术解决Docker主机的互联问题，以免让用户觉得Docker太难，从而放弃学习和使用Docker。

Docker成名以后，重新开始重视网络解决方案，收购了一家Docker网络解决方案公司—**Socketplane**，原因在于这家公司的产品广受好评，但有趣的是Socketplane的方案就是以**Open vSwitch为核心**的，其还为Open vSwitch提供了Docker镜像，以方便部署程序。之后，Docker开启了一个宏伟的**虚拟化网络解决方案**—**Libnetwork**，如图7.7所示是其概念图。

![2019-09-19-16-35-23.png](./images/2019-09-19-16-35-23.png)

这个概念图没有了IP，也没有了路由，已经颠覆了我们的网络常识，对于不怎么懂网络的大多数人来说，它的确很有诱惑力，未来是否会对虚拟化网络的模型产生深远冲击，我们还不得而知，但它仅仅是Docker官方当前的一次“尝试”。

针对目前Docker的网络实现，Docker使用的Libnetwork组件**只是**将**Docker平台中的网络子系统模块化**为一个**独立库**的简单尝试，离成熟和完善还有一段距离。