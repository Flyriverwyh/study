
<!-- @import "[TOC]" {cmd="toc" depthFrom=1 depthTo=6 orderedList=false} -->

<!-- code_chunk_output -->

- [1. kvm中与内存有关的成员](#1-kvm中与内存有关的成员)
- [2. kvm_memslots: 虚拟机所有slot信息](#2-kvm_memslots-虚拟机所有slot信息)
- [3. kvm_mem_slot 结构体: 一个代表一段空间, 虚拟机GPA到主机HVA的映射关系](#3-kvm_mem_slot-结构体-一个代表一段空间-虚拟机gpa到主机hva的映射关系)
- [4. kvm_mmu 结构体:](#4-kvm_mmu-结构体)
  - [4.1. 与kvm_vcpu, kvm_vcpu_arch之间的关系](#41-与kvm_vcpu-kvm_vcpu_arch之间的关系)
  - [4.2. kvm_mmu 定义: mmu的回调函数](#42-kvm_mmu-定义-mmu的回调函数)

<!-- /code_chunk_output -->


# 1. kvm中与内存有关的成员

```cpp
// include/linux/kvm_host.h
struct kvm {
        // 保护mmu的spinlock, mmu范围最大的锁
	spinlock_t mmu_lock;
        // 内存槽操作锁
	struct mutex slots_lock;
	// 指向qemu用户态进程的mm_struct
	struct mm_struct *mm; /* userspace tied to this vm */
        // 该kvm所有的memslot
        struct kvm_memslots __rcu *memslots[KVM_ADDRESS_SPACE_NUM];
```

其中`address_space_id = mem->slot >> 16;`, 详细见`虚拟机物理内存注册`.

# 2. kvm_memslots: 虚拟机所有slot信息

一个`struct kvm`代表一个虚拟机, memslots是该虚拟机所有内存条, 注意最大`KVM_ADDRESS_SPACE_NUM`(这里是1), 用于将**GPA转换为HVA**. 

```cpp
/*
 * Note:
 * memslots are not sorted by id anymore, please use id_to_memslot()
 * to get the memslot by its id.
 */
struct kvm_memslots {
        u64 generation;
        /* The mapping table from slot id to the index in memslots[]. */
        short id_to_index[KVM_MEM_SLOTS_NUM];
        atomic_t lru_slot;
        int used_slots;
        // 所有插槽
        struct kvm_memory_slot memslots[];
};
```

kvm_memslots结构体是`kvm_mem_slot`的封装，其中包含一个`kvm_mem_slot`的数组，对应于**该虚拟机**使用的**所有内存区域(slot**)。以**数组形式**存储这些**slot的地址信息**。

`kvm_mem_slot`是kvm内存管理相关主要数据结构，用来表示**虚拟机GPA**和**主机HVA**之间的**映射关系**，一个`kvm_mem_slot`表示一段**内存区域(slot)的映射关系**.

获取某一个`kvm_memory_slot`, 通过`id_to_memslot(struct kvm_memslots *slots, int id)`实现, `虚拟机物理内存注册`有**具体代码**.

`kvm->memslots`结构在创建虚拟机时被创建. `kvm_create_vm`, 而插槽ID`slot id`和其索引index是在`id_to_index`中维护, 即`slots->id_to_index[i] = slots->memslots[i].id = i`, 而这个映射关系是**新加一个内存条**(即虚拟机物理内存注册)时候建立的.

```cpp
static struct kvm *kvm_create_vm(unsigned long type)
{
        ...
        for (i = 0; i < KVM_ADDRESS_SPACE_NUM; i++) {
                struct kvm_memslots *slots = kvm_alloc_memslots();

                if (!slots)
                        goto out_err_no_arch_destroy_vm;
                /* Generations must be different for each address space. */
                slots->generation = i;
                rcu_assign_pointer(kvm->memslots[i], slots);
        }
        ...
}

static struct kvm_memslots *kvm_alloc_memslots(void)
{
        int i;
        struct kvm_memslots *slots;

        slots = kvzalloc(sizeof(struct kvm_memslots), GFP_KERNEL_ACCOUNT);
        if (!slots)
                return NULL;
        // 这里并没有建立, 而是在虚拟机物理内存注册时候建立
        for (i = 0; i < KVM_MEM_SLOTS_NUM; i++)
                slots->id_to_index[i] = -1;

        return slots;
}
```

# 3. kvm_mem_slot 结构体: 一个代表一段空间, 虚拟机GPA到主机HVA的映射关系

由于**GPA不能直接用于物理 MMU 进行寻址！！！**，所以需要**将GPA转换为HVA**，kvm中利用 `kvm_memory_slot` 数据结构来记录**每一个地址区间**(**Guest中的物理地址区间**)中**GPA与HVA**的**映射关系**.

```cpp
/* KVM Hugepage definitions for x86 */
enum {
        PT_PAGE_TABLE_LEVEL   = 1,
        PT_DIRECTORY_LEVEL    = 2,
        PT_PDPE_LEVEL         = 3,
        /* set max level to the biggest one */
        PT_MAX_HUGEPAGE_LEVEL = PT_PDPE_LEVEL,
};
// 这里是3
#define KVM_NR_PAGE_SIZES       (PT_MAX_HUGEPAGE_LEVEL - \
                                 PT_PAGE_TABLE_LEVEL + 1)
struct kvm_rmap_head {
        unsigned long val;
};

struct kvm_lpage_info {
        int disallow_lpage;
};

struct kvm_arch_memory_slot {
        // 反向映射结构（reverse map）
        struct kvm_rmap_head *rmap[KVM_NR_PAGE_SIZES];
        // Large page结构（如2MB、1GB大小页面）
        struct kvm_lpage_info *lpage_info[KVM_NR_PAGE_SIZES - 1];
        unsigned short *gfn_track[KVM_PAGE_TRACK_MAX];
};

struct kvm_memory_slot {
        // 虚拟机物理地址(即GPA)对应的页框号
        gfn_t base_gfn;
        // 当前slot中包含的page数目
        unsigned long npages;
        // 一个slot由许多客户机虚拟页面构成, 通过这个标识每个页是否可用
        unsigned long *dirty_bitmap;
        // 架构相关部分
        struct kvm_arch_memory_slot arch;
        /*
         * GPA对应的host虚拟地址(HVA), 由于虚拟机都运行在qemu的地址空间中
         * 而qemu是用户态程序, 所以通常使用root-module下的用户地址空间.
         */
        unsigned long userspace_addr;
        // 标志位
        u32 flags;
        // slot的id
        short id;
};
```

虚拟机线性地址被分成若干个`kvm_memory_slot`，**每个memslot**是**不能重叠**的，也就是说每一段内存区间都必须有独立的作用。一般来说Qemu会对RAM、IO memory、High memory等分别注册若干个memslot

至于`kvm_userspace_memory_region`可以看qemu部分

# 4. kvm_mmu 结构体:

## 4.1. 与kvm_vcpu, kvm_vcpu_arch之间的关系

![2020-03-20-10-46-36.png](./images/2020-03-20-10-46-36.png)

从上图可以看到，`struct kvm_mmu`是`struct kvm_vcpu_arch`的一个字段。

vcpu->arch中与MMU相关的结构：

```cpp
struct kvm_vcpu_arch {
    ......
    /*
     * Paging state of the vcpu
     *
     * If the vcpu runs in guest mode with two level paging this still saves
     * the paging mode of the l1 guest. This context is always used to
     * handle faults.
     */
    //内存管理，更多的是附带了直接操作函数
    struct kvm_mmu mmu; 
 
    /*
     * Paging state of an L2 guest (used for nested npt)
     *
     * This context will save all necessary information to walk page tables
     * of the an L2 guest. This context is only initialized for page table
     * walking and not for faulting since we never handle l2 page faults on
     * the host.
     */
    struct kvm_mmu nested_mmu;
 
    /*
     * Pointer to the mmu context currently used for
     * gva_to_gpa translations.
     */
    struct kvm_mmu *walk_mmu;
 
    struct kvm_mmu_memory_cache mmu_pte_list_desc_cache;
    struct kvm_mmu_memory_cache mmu_page_cache;
    struct kvm_mmu_memory_cache mmu_page_header_cache;
    ......
```

注释已经很清楚了，我就不做过多的解释了，说一下三个cache：
- `mmu_pte_list_desc_cache`：用来分配`struct pte_list_desc`结构，该结构主要用于**反向映射**，参考`rmap_ad`函数，**每个rmapp**指向的就是**一个**`pte_list`。后面介绍反向映射的时候会详细介绍。
- `mmu_page_cache`：用来**分配spt页结构**，spt页结构是存储`spt paging structure`的页，对应`kvm_mmu_page.spt`
- `mmu_page_header_cache`：用来分配`struct kvm_mmu_page`结构，从该cache分配的页面可能会调用**kmem_cache机制**来分配

这三个cache使用的是`kvm_mmu_memory_cache`结构，该结构是KVM定义的cache结构，进一步优化了MMU分配的效率。有**两个对应的kmem_cache结构**：

```cpp
static struct kmem_cache *pte_list_desc_cache;
static struct kmem_cache *mmu_page_header_cache;
```

他们分别对应`mmu_pte_list_desc_cache`和`mmu_page_header_cache`，也就是说如果这**两个cache**中缓存的**object数目不够**，则会从上述对应的`kmem_cache`中获取，对应的代码可以参考函数`mmu_topup_memory_cache`；

```cpp
static int mmu_topup_memory_cache(struct kvm_mmu_memory_cache *cache,
                                  struct kmem_cache *base_cache, int min)
{
        void *obj;

        if (cache->nobjs >= min)
                return 0;
        while (cache->nobjs < ARRAY_SIZE(cache->objects)) {
                obj = kmem_cache_zalloc(base_cache, GFP_KERNEL_ACCOUNT);
                if (!obj)
                        return cache->nobjs >= min ? 0 : -ENOMEM;
                cache->objects[cache->nobjs++] = obj;
        }
        return 0;
}
```

而`mmu_page_cache`中的object数目不够时，则调用`mmu_topup_memory_cache_page`函数，其中直接调用了`__get_free_page`函数来获得页面。在一些**初始化函数**中，需要**初始化这些cache**以便**加速运行时的分配**，初始化函数为`mmu_topup_memory_caches`，该初始化过程在**mmu page fault处理函数**（如`tdp_page_fault`）、**MMU初始化函数**（`kvm_mmu_load`）和**写SPT的pte函数**（`kvm_mmu_pte_write`）中被调用。



## 4.2. kvm_mmu 定义: mmu的回调函数

```cpp
/*
 * x86 supports 4 paging modes (5-level 64-bit, 4-level 64-bit, 3-level 32-bit,
 * and 2-level 32-bit).  The kvm_mmu structure abstracts the details of the
 * current mmu mode.
 */
struct kvm_mmu {
        // 所属的vcpu
        unsigned long (*get_guest_pgd)(struct kvm_vcpu *vcpu);
        // 
        u64 (*get_pdptr)(struct kvm_vcpu *vcpu, int index);
        int (*page_fault)(struct kvm_vcpu *vcpu, gpa_t cr2_or_gpa, u32 err,
                          bool prefault);
        void (*inject_page_fault)(struct kvm_vcpu *vcpu,
                                  struct x86_exception *fault);
        gpa_t (*gva_to_gpa)(struct kvm_vcpu *vcpu, gpa_t gva_or_gpa,
                            u32 access, struct x86_exception *exception);
        gpa_t (*translate_gpa)(struct kvm_vcpu *vcpu, gpa_t gpa, u32 access,
                               struct x86_exception *exception);
        int (*sync_page)(struct kvm_vcpu *vcpu,
                         struct kvm_mmu_page *sp);
        void (*invlpg)(struct kvm_vcpu *vcpu, gva_t gva, hpa_t root_hpa);
        void (*update_pte)(struct kvm_vcpu *vcpu, struct kvm_mmu_page *sp,
                           u64 *spte, const void *pte);
        hpa_t root_hpa;
        gpa_t root_cr3;
        union kvm_mmu_role mmu_role;
        u8 root_level;
        u8 shadow_root_level;
        u8 ept_ad;
        bool direct_map;
        struct kvm_mmu_root_info prev_roots[KVM_MMU_NUM_PREV_ROOTS];

        /*
         * Bitmap; bit set = permission fault
         * Byte index: page fault error code [4:1]
         * Bit index: pte permissions in ACC_* format
         */
        u8 permissions[16];

        /*
        * The pkru_mask indicates if protection key checks are needed.  It
        * consists of 16 domains indexed by page fault error code bits [4:1],
        * with PFEC.RSVD replaced by ACC_USER_MASK from the page tables.
        * Each domain has 2 bits which are ANDed with AD and WD from PKRU.
        */
        u32 pkru_mask;

        u64 *pae_root;
        u64 *lm_root;

        /*
         * check zero bits on shadow page table entries, these
         * bits include not only hardware reserved bits but also
         * the bits spte never used.
         */
        struct rsvd_bits_validate shadow_zero_check;

        struct rsvd_bits_validate guest_rsvd_check;

        /* Can have large pages at levels 2..last_nonleaf_level-1. */
        u8 last_nonleaf_level;

        bool nx;

        u64 pdptrs[4]; /* pae */
};

```

