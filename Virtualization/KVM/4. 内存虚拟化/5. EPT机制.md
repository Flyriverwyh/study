

# 背景

在虚拟化环境下，intel CPU在处理器级别加入了对内存虚拟化的支持。即扩展页表EPT，而AMD也有类似的成为NPT。在此之前，内存虚拟化使用的一个重要技术为影子页表。

在**虚拟化环境**下，虚拟机使用的是**客户机虚拟地址GVA**，而其**本身页表机制**只能把**客户机的虚拟地址**转换成**客户机的物理地址**也就是完成`GVA->GPA`的转换，但是GPA并不是被用来真正的访存，所以需要想办法把**客户机的物理地址GPA**转换成**宿主机的物理地址HPA**。

**影子页表**采用的是一步到位式，即完成**客户机虚拟地址GVA**到**宿主机物理地址HPA**的转换，由VMM为每个客户机进程维护。本节对于影子页表不做过多描述，重点在于EPT。

内容第一部分根据intel手册分析EPT地址转换机制；第二部分借助于KVM源代码分析EPT构建过程。

# EPT地址转换机制

具体见`<系统虚拟化/处理器虚拟化技术>`, 当然最权威是Intel手册

当一个逻辑CPU处于非根模式下运行客户机代码时，使用的地址是客户机虚拟地址，而访问这个虚拟地址时，同样会发生地址的转换，这里的转换还没有设计到VMM层，和正常的系统一样，这里依然是采用CR3作为基址，利用客户机页表进行地址转换，只是到这里虽然已经转换成物理地址，但是由于是客户机物理地址，不等同于宿主机的物理地址，所以并不能直接访问，需要借助于第二次的转换，也就是EPT的转换。注意EPT的维护有VMM维护，其转换过程由硬件完成，所以其比影子页表有更高的效率。

我们假设已经获取到了客户机的物理地址，下面分析下如何利用一个客户机的物理地址，通过EPT进行寻址。

![2020-03-17-16-14-05.png](./images/2020-03-17-16-14-05.png)

注意不管是32位客户机还是64位客户机，这里统一按照64位物理地址来寻址。EPT页表是4级页表，页表的大小仍然是一个页即4KB，但是一个表项是8个字节，所以一张表只能容纳512个表项，需要9位来定位具体的表项。客户机的物理地址使用低48位来完成这一工作。从上图可以看到，一个48位的客户机物理地址被分为5部分，前4部分按9位划分，最后12位作为页内偏移。当处于非根模式下的CPU使用客户机操作一个客户机虚拟地址时，首先使用客户机页表进行地址转换，得到客户机物理地址，然后CPU根据此物理地址查询EPT，在VMCS结构中有一个EPTP的指针，其中的12-51位指向EPT页表的一级目录即PML4 Table.这样根据客户机物理地址的首个9位就可以定位一个PML4 entry，一个PML4 entry理论上可以控制512GB的区域，这里不是重点，我们不在多说。PML4 entry的格式如下：

![2020-03-17-16-14-17.png](./images/2020-03-17-16-14-17.png)

1、其实这里我们只需要知道PML4 entry的12-51位记录下一级页表的地址，而这40位肯定是用不完的，根据CPU的架构，采取不同的位数，具体如下：

在Intel中使用MAXPHYADDR来表示最大的物理地址，我们可以通过CPUID的指令来获得处理支持的最大物理地址，然而这已经不在此次的讨论范围之内，我们需要知道的只是：
当MAXPHYADDR 为36位，在Intel平台的桌面处理器上普遍实现了36位的最高物理地址值，也就是我们普通的个人计算机，可寻址64G空间；
当MAXPHYADDR 为40位，在Inter的服务器产品和AMD 的平台上普遍实现40位的最高物理地址，可寻址达1TB；
当MAXPHYADDR为52位，这是x64体系结构描述最高实现值，目前尚未有处理器实现。

而对下级表的物理地址的存储4K页面寻址遵循如下规则：
① 当MAXPHYADDR为52位时，上一级table entry的12~51位提供下一级table物理基地址的高40位，低12位补零，达到基地址在4K边界对齐；
② 当MAXPHYADDR为40位时，上一级table entry的12~39位提供下一级table物理基地址的高28位，此时40~51是保留位，必须置0，低12位补零，达到基地址在4K边界对齐；
③ 当MAXPHYADDR为36位时，上一级table entry的12~35位提供下一级table物理基地址的高24位，此时36~51是保留位，必须置0，低12位补零，达到基地址在4K边界对齐。

而MAXPHYADDR为36位正是普通32位机的PAE模式。

2、就这么定位为下一级的页表EPT Page-Directory-Pointer-Table ，根据客户物理地址的30-38位定位此页表中的一个表项EPT Page-Directory-Pointer-Table entry。注意这里如果该表项的第7位为1，该表项指向一个1G字节的page.为0，则指向下一级页表。下面我们只考虑的是指向页表的情况。

3、然后根据表项中的12-51位，继续往下定位到第三级页表EPT Page-Directory-Pointer-Table，在根据客户物理地址的21-29位来定位到一个EPT Page-Directory-Pointer-Table Entry。如果此entry的第7位为1，则表示该entry指向一个2M的page，为0就指向下一级页表。

4、根据entry的12-51位定位第四级页表EPT Page-Directory ，然后根据客户物理地址的12-20位定位一个PDE。

PDE的12-51位指向一个4K物理页面，最后根据客户物理地址的最低12位作为偏移，定位到具体的物理地址。

# EPT寻址过程

先了解下KVM虚拟机的物理内存组织方式，众所周知，**KVM虚拟机**运行在**qemu的进程地址空间**中，所以其实**虚拟机使用的物理地址**是从对应**qemu进程的地址空间中分配**的。

具体由一个`kvm_memory_slot`结构管理，**每个虚拟机**的**物理内存**由**多个slot**组成，**每个slot**对应一个`kvm_memory_slot`结构，从结构体的字段可以看出，该结构记录**slot映射**的是**哪些客户物理page**，由于**映射多个页面**，所以有一个`ditty_bitmap`来标识**各个页的状态**，注意这个页是客户机的虚拟page。映射架构如下：

![2020-03-17-16-17-51.png](./images/2020-03-17-16-17-51.png)

下面借助于KVM源代码分析下EPT的构建过程，其构建模式和普通页表一样，属于**中断触发式**。即**初始页表是空的**，只有在**访问未命中**的时候**引发缺页中断**，然后缺页处理程序**构建页表**。

**初始状态EPT页表为空**，当**客户机运行**时，其使用的**GVA转化成GPA**后，还需要CPU根据**GPA查找EPT**，从而**定位具体的HPA**，但是由于此时**EPT为空**，所以会引发**缺页中断**，发生**VM-exit**, 此时**CPU进入到根模式**，运行VMM（这里指KVM），在KVM中定义了一个**异常处理数组**来处理**对应的VM-exit**，

```cpp
static int (*kvm_vmx_exit_handlers[])(struct kvm_vcpu *vcpu) = {
    ......
        [EXIT_REASON_EPT_VIOLATION]           = handle_ept_violation,
        [EXIT_REASON_EPT_MISCONFIG]           = handle_ept_misconfig,
    ......
};
```

所以在发生EPT violation的时候，KVM中会执行`handle_ept_violation`：

```cpp
static int handle_ept_violation(struct kvm_vcpu *vcpu)
{
        unsigned long exit_qualification;
        gpa_t gpa;
        u64 error_code;
        // 读取
        exit_qualification = vmcs_readl(EXIT_QUALIFICATION);

        /*
         * EPT violation happened while executing iret from NMI,
         * "blocked by NMI" bit has to be set before next VM entry.
         * There are errata that may cause this bit to not be set:
         * AAK134, BY25.
         */
        if (!(to_vmx(vcpu)->idt_vectoring_info & VECTORING_INFO_VALID_MASK) &&
                        enable_vnmi &&
                        (exit_qualification & INTR_INFO_UNBLOCK_NMI))
                vmcs_set_bits(GUEST_INTERRUPTIBILITY_INFO, GUEST_INTR_STATE_NMI);

        gpa = vmcs_read64(GUEST_PHYSICAL_ADDRESS);
        trace_kvm_page_fault(gpa, exit_qualification);

        /* Is it a read fault? */
        error_code = (exit_qualification & EPT_VIOLATION_ACC_READ)
                     ? PFERR_USER_MASK : 0;
        /* Is it a write fault? */
        error_code |= (exit_qualification & EPT_VIOLATION_ACC_WRITE)
                      ? PFERR_WRITE_MASK : 0;
        /* Is it a fetch fault? */
        error_code |= (exit_qualification & EPT_VIOLATION_ACC_INSTR)
                      ? PFERR_FETCH_MASK : 0;
        /* ept page table entry is present? */
        error_code |= (exit_qualification &
                       (EPT_VIOLATION_READABLE | EPT_VIOLATION_WRITABLE |
                        EPT_VIOLATION_EXECUTABLE))
                      ? PFERR_PRESENT_MASK : 0;

        error_code |= (exit_qualification & 0x100) != 0 ?
               PFERR_GUEST_FINAL_MASK : PFERR_GUEST_PAGE_MASK;

        vcpu->arch.exit_qualification = exit_qualification;
        return kvm_mmu_page_fault(vcpu, gpa, error_code, NULL, 0);
}
```

# 参考

https://www.cnblogs.com/ck1020/p/6043054.html