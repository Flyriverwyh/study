
<!-- @import "[TOC]" {cmd="toc" depthFrom=1 depthTo=6 orderedList=false} -->

<!-- code_chunk_output -->

- [1. 基本原理](#1-基本原理)
- [2. Time Tick](#2-time-tick)
  - [2.1. 虚拟化下的timer](#21-虚拟化下的timer)
- [3. 相关代码](#3-相关代码)
- [4. 物理芯片介绍](#4-物理芯片介绍)
  - [4.1. PIT主要为Intel 8254 PIT芯片](#41-pit主要为intel-8254-pit芯片)
  - [4.2. PIC主要为8259A PIC芯片](#42-pic主要为8259a-pic芯片)
- [5. 整体流程](#5-整体流程)
- [6. 初始化中断控制器(PIC)](#6-初始化中断控制器pic)
  - [6.1. QEMU](#61-qemu)
  - [6.2. 整体流程](#62-整体流程)
  - [6.3. 入口代码](#63-入口代码)
  - [6.4. kvm_pic_init(): 虚拟pic(8259A)的初始化](#64-kvm_pic_init-虚拟pic8259a的初始化)
    - [6.4.1. kvm_io_bus_register_dev(): 在相应的io_bus总线上注册设备](#641-kvm_io_bus_register_dev-在相应的io_bus总线上注册设备)
    - [6.4.2. 三种设备在虚拟bus上的结构](#642-三种设备在虚拟bus上的结构)
  - [6.5. kvm_ioapic_init(): ioapic的初始化](#65-kvm_ioapic_init-ioapic的初始化)
  - [6.6. kvm_setup_default_irq_routing(): 默认中断路由表的初始化](#66-kvm_setup_default_irq_routing-默认中断路由表的初始化)
- [7. 初始化虚拟PIT](#7-初始化虚拟pit)
  - [7.1. QEMU](#71-qemu)
- [参考](#参考)

<!-- /code_chunk_output -->

# 1. 基本原理

中断虚拟化**起始关键**在于**对中断控制器的虚拟化**.

在正常系统中:

中断控制器目前主要有**APIC**，这种架构下**设备控制器**通过**某种触发方式**通知**IO APIC**，**IO APIC**根据**自身维护**的**重定向表pci irq routing table**格式化出**一条中断消息**，把中断消息发送给**local APIC**，local APIC局部于CPU，即**每个CPU一个**，local APIC 具备**传统中断控制器的相关功能**以及各个寄存器，中断请求寄存器IRR，中断屏蔽寄存器IMR，中断服务寄存器ISR等.

针对这些关键部件的虚拟化是中断虚拟化的重点。

# 2. Time Tick

一个操作系统要跑起来，必须有**Time Tick**，它就像是身体的脉搏。

普通情况下，OS Time Tick由**PIT**(i8254)或**APIC Timer**设备提供

- PIT定期(**1ms in Linux**)产生一个**timer interrupt**，作为**global tick**, 
- **APIC Timer**产生一个**local tick**。

## 2.1. 虚拟化下的timer

在虚拟化情况下，必须为**guest OS**模拟一个**PIT**和**APIC Timer**。

模拟的**PIT**和**APIC Timer**不能像真正硬件那样**物理计时**，所以一般用**HOST的某种系统服务**或**软件计时器**来为这个模拟 PIT 提供模拟”**时钟源**”。

目前两种方案：1. **用户态模拟方案**（QEMU）； 2. **内核态模拟方案**（KVM）；

在**QEMU**中，用**SIGALARM信号**来实现：QEMU利用**某种机制**，使**timer interrupt handler**会向**QEMU process**发送一个**SIGALARM信号**，处理该信号过程中再**模拟PIT**中**产生一次时钟**。QEMU再通过某种机制，将**此模拟PIT**发出的**模拟中断交付给kvm**，再由kvm**注入**到虚拟机中去。

目前的kvm版本支持内核PIT、APIC和内核PIC，因为这两个设备是**频繁使用**的，在**内核模式中模拟**比在**用户模式模拟**性能更高。

这里重点是讲内核PIT的模拟实现，弄清楚它是如何为guest OS提供时钟的。

# 3. 相关代码

![2020-05-04-13-06-31.png](./images/2020-05-04-13-06-31.png)

# 4. 物理芯片介绍

## 4.1. PIT主要为Intel 8254 PIT芯片

**PIT**(**Programmable Interval Timer**), **可编程间隔定时器**

**每个PC机**中都有一个**PIT**, 通过**IRQ**产生**周期性的时钟中断信号**来充当**系统定时器**.

i386使用通常是Intel 8254 PIT芯片, 它的I/O端口地址范围是`40h ~ 43h`.

8254 PIT有**3个计时通道**, 每个通道都有其不同的用途:

- **通道0**用来负责**更新系统时钟**. 它在**每个时钟滴答**会通过**IRQ0**向系统发出一次**时钟中断信号**.
- **通道1**通常用来控制**DMAC对RAM的刷新**
- **通道3**被连接到**PC机的扬声器**, 以产生**方波信号**.

## 4.2. PIC主要为8259A PIC芯片

**PIC**(**Programmable Interrupt Controller**), **可编程中断控制器**

它具有`IR0 ~ IR7`共**8个中断管脚**连接到**外部设备**. **中断管脚**具有**优先级**, 其中IR0优先级最高, IR7最低.

PIC有三个重要的寄存器:

(1) IRR(Interrupt Request Register, 中断请求寄存器)共8位, 对应IR0到IR7这8个中断管脚. 某位置为1表明收到了对应管脚的中断但未提交到CPU.

(2) ISR(Interrupt Service Register, 中断请求寄存器): 共8位, 某位置为1表明对应管脚的中断已经提交到CPU处理, 但CPU还未处理完.

(3) IMR(Interrupt Mask Register, 中断屏蔽寄存器): 共8位, 某位置为1表明对应的中断管脚被屏蔽.

# 5. 整体流程

整个主要流程:

![2020-04-18-17-59.png](./images/2020-04-18-17-59.png)

修正: 重定向表中有目标lapic的id

# 6. 初始化中断控制器(PIC)

考虑到中断实时性对性能的影响，**PIC和IOAPIC**的**设备模拟主要逻辑**都放到了**kvm模块**进行实现，**每个VCPU**的**LAPIC**则**完全放到kvm**中进行实现。 

**i8259控制器**和**IOAPIC**的创建和初始化由**qemu和kvm配合完成**，包括了2个方面：

- **kvm**中**设备相关数据结构初始化！！！**
- **qemu中设备模拟的初始化！！！**

**中断处理的逻辑**放在**kvm内核模块**中进行实现，但**设备的模拟**呈现还是需要**qemu设备模拟器**来搞定，最后qemu和kvm一起配合完成快速中断处理的流程。

所以在**qemu**中也会创建i8259A和ioapic

## 6.1. QEMU

qemu代码中中断控制器的kvm内核初始化流程为：

```cpp
configure_accelerator
    |--> accel_init_machine
        |--> kvm_init
            |--> kvm_irqchip_create
                |--> kvm_vm_ioctl(s, KVM_CREATE_IRQCHIP)
                |--> kvm_init_irq_routing

// kvm-all.c/kvm_init/kvm_irqchip_create
kvm_vm_ioctl(s, KVM_CREATE_IRQCHIP)
```

qemu通过kvm的ioctl命令`KVM_CREATE_IRQCHIP`调用到kvm内核模块中，在**内核模块**中**创建和初始化PIC/IOAPIC设备**（创建设备对应的数据结构并将设备注册到总线上）。

## 6.2. 整体流程

```cpp
kvm_vm_ioctl()  // vm ioctl的入口
 ├─  kvm_arch_vm_ioctl()     
 |   ├─ irqchip_in_kernel(kvm)  // 如果irqchip在kvm中实现, 则直接返回, 不执行任何动作
 |   ├─ kvm_pic_init()   // pic创建, 8259
 |   |   |─ struct kvm_pic *s = kzalloc(sizeof(struct kvm_pic), GFP_KERNEL_ACCOUNT);   // 创建kvm_pic结构
 |   |   |─ kvm_iodevice_init(&s->dev_master, &picdev_master_ops); // 注册master的IO端口读写函数
 |   |   |─ kvm_iodevice_init(&s->dev_slave, &picdev_slave_ops); // 注册slave的IO端口读写函数
 |   |   |─ kvm_iodevice_init(&s->dev_eclr, &picdev_eclr_ops); // 注册eclr的IO端口读写函数
 |   |   |─ kvm_io_bus_register_dev(kvm, KVM_PIO_BUS, 0x20, 2, &s->dev_master); // 注册了PIO型的bus访问形式；另一种IO形式为MMIO；
 |   |   |─ kvm_io_bus_register_dev(kvm, KVM_PIO_BUS, 0xa0, 2, &s->dev_slave); // 注册了PIO型的bus访问形式；另一种IO形式为MMIO；
 |   |   |─ kvm_io_bus_register_dev(kvm, KVM_PIO_BUS, 0x4d0, 2, &s->dev_eclr); // 注册了PIO型的bus访问形式；另一种IO形式为MMIO；
 |   |   └─ kvm->arch.vpic = s;   // 将s赋值给kvm->arch.vpic
 |   ├─ kvm_ioapic_init()   // ioapic的初始化
 |   |   ├─ struct kvm_ioapic *ioapic = kzalloc(sizeof(struct kvm_ioapic), GFP_KERNEL_ACCOUNT);  // 创建kvm_pic结构
 |   ├─ kvm_setup_default_irq_routing();   // 设置默认的irq路由表
 |   └─ kvm->arch.irqchip_mode = KVM_IRQCHIP_KERNEL;  // irqchip为kernel模式, 即在kernel中实现


 |   |   |─ exit_qualification = vmcs_readl(EXIT_QUALIFICATION);   // 读取exit_qualification字段
 |   |   |─ gpa = vmcs_read64(GUEST_PHYSICAL_ADDRESS);   // 读取虚拟机的物理地址
 |   |   |─ error_code = XXXX;   // 拼凑error
 |   |   |─ kvm_mmu_page_fault(vcpu, gpa, error_code, NULL, 0);   // 处理page fault异常
 |   |   |   ├─ kvm_mmu_do_page_fault(vcpu, cr2_or_gpa, lower_32_bits(error_code), false); // 处理内存访问异常, mmio的见io部分
 |   |   |   |   └─ vcpu->arch.mmu->page_fault(vcpu, cr2_or_gpa, err, prefault);   // EPT下会调用kvm_tdp_page_fault
 |   |   |   |       └─ direct_page_fault(vcpu, gpa, error_code, prefault, max_level, true);   // EPT下会调用kvm_tdp_page_fault
 |   |   |   |           ├─ gfn = gpa >> PAGE_SHIFT;   // 虚拟机物理地址右移12位得到虚拟机物理页框号, 这是标准页面下的 GFN
 |   |   |   |           ├─ mmu_topup_memory_caches(vcpu);   // 分配缓存池
 |   |   |   |           ├─ fast_page_fault();   // 快速page fault处理
 |   |   |   |           ├─ try_async_pf();   // 根据gfn, 在memslots中查找, 得到pfn, 主机物理页框号, HPA
 |   |   |   |           |   ├─ slot = kvm_vcpu_gfn_to_memslot(vcpu, gfn);   // 得到该gfn(虚拟机页框号)对应的kvm_memory_slot
 |   |   |   |           |   └─ *pfn = __gfn_to_pfn_memslot();   // 得到该gfn(虚拟机页框号)对应的pfn(主机物理页框号), 即GPA到HPA的转换
 |   |   |   |           |        ├─ addr = __gfn_to_hva_many();   // 得到该gfn(虚拟机页框号)对应的qemu中分配的页面的HVA
 |   |   |   |           |        |   └─ return __gfn_to_hva_memslot();
 |   |   |   |           |        |       └─ return slot->userspace_addr + (gfn - slot->base_gfn) * PAGE_SIZE; // 这是gfn(虚拟机页框号)转换成主机虚拟地址(hva)
 |   |   |   |           |        └─ return hva_to_pfn(); // 得到这个主机虚拟地址(HVA)的主机物理页框号(HPA), 当然这只是一个PFN, 还需要PF完成真正页面的分配, 如果HVA对应的地址并不在内存中，还需要HOST自己处理缺页中断
 |   |   |   |           ├─ handle_abnormal_pfn();   // 处理反常的物理页
 |   |   |   |           └─ __direct_map();   // 完成EPT页表的构造，并在最后一级页表项中将gfn同pfn映射起来
 |   |   |   |               ├─ level = kvm_mmu_hugepage_adjust(vcpu, gfn, max_level, &pfn);   // 获取到该gfn对应的level, 基于vcpu->kvm->mm(qemu的mm_struct)
 |   |   |   |               ├─ for_each_shadow_entry(vcpu, gpa, it);   // 遍历EPT页表
 |   |   |   |               ├─ it.level == level: break;   //  如果页表的level等于请求的level, 表明是该entry引起的violation(说明到了叶子节点), 跳出
 |   |   |   |               ├─ sp = kvm_mmu_get_page();   // 对于非叶子节点, 如果该entry页表项值为0, 表明下一级页表页不存在, 则分配当前entry的下一级(level-1, 指向的页表)页表的kvm_mmu_page(sp)
 |   |   |   |               ├─ link_shadow_page(vcpu, it.sptep, sp);   // 非叶子结点, 下一级页表页不存在时, 将分配的下一级页表页链接到当前entry, 这是HPA
 |   |   |   |           |        ├─ mmu_spte_set(sptep, spte);   // 将sp处理后成为spte, 将其添加到当前entry(sptep), HPA
 |   |   |   |           |        └─ mmu_page_add_parent_pte(vcpu, sp, sptep); // 当前页表页(sp)会被多个上级页表项引用, 将所有上级页表项的parent_spte添加到当前页表页的patent_ptes链表中
 |   |   |   |           |   └─ mmu_set_spte();   // 设置最后一级页表项(即表项指向真正的页面), sptep指向pfn, HPA
 |   |   |   └─ x86_emulate_instruction(vcpu, cr2_or_gpa, emulation_type, insn, insn_len);   // 
```

## 6.3. 入口代码

```cpp
        case KVM_CREATE_IRQCHIP: {
                mutex_lock(&kvm->lock);

                r = -EEXIST;
                // 如果irqchip在kvm中实现, 则不用创建
                if (irqchip_in_kernel(kvm))
                        goto create_irqchip_unlock;

                r = -EINVAL;
                if (kvm->created_vcpus)
                        goto create_irqchip_unlock;
                // 主要过程, 是8259A pic初始化
                r = kvm_pic_init(kvm);
                if (r)
                        goto create_irqchip_unlock;
                // ioapic的初始化
                r = kvm_ioapic_init(kvm);
                if (r) {
                        kvm_pic_destroy(kvm);
                        goto create_irqchip_unlock;
                }
                // 建立默认中断路由表
                r = kvm_setup_default_irq_routing(kvm);
                if (r) {
                        kvm_ioapic_destroy(kvm);
                        kvm_pic_destroy(kvm);
                        goto create_irqchip_unlock;
                }
                /* Write kvm->irq_routing before enabling irqchip_in_kernel. */
                smp_wmb();
                // irq属于内核实现
                kvm->arch.irqchip_mode = KVM_IRQCHIP_KERNEL;
        create_irqchip_unlock:
                mutex_unlock(&kvm->lock);
                break;
        }
```

## 6.4. kvm_pic_init(): 虚拟pic(8259A)的初始化

`arch/x86/kvm/i8259.c`

```cpp
// arch/x86/kvm/i8259.c
int kvm_pic_init(struct kvm *kvm)
{
        struct kvm_pic *s;
        int ret;
        // 分配 kvm_pic 结构体
        s = kzalloc(sizeof(struct kvm_pic), GFP_KERNEL_ACCOUNT);
        if (!s)
                return -ENOMEM;
        spin_lock_init(&s->lock);
        // 该pic所属的kvm虚拟机
        s->kvm = kvm;
        s->pics[0].elcr_mask = 0xf8;
        s->pics[1].elcr_mask = 0xde;
        s->pics[0].pics_state = s;
        s->pics[1].pics_state = s;

        /*
         * Initialize PIO device
         */
        // 注册master的IO端口读写函数
        kvm_iodevice_init(&s->dev_master, &picdev_master_ops);
        kvm_iodevice_init(&s->dev_slave, &picdev_slave_ops);
        kvm_iodevice_init(&s->dev_eclr, &picdev_eclr_ops);
        mutex_lock(&kvm->slots_lock);
        // 注册了PIO型的bus访问形式；另一种IO形式为MMIO；
        ret = kvm_io_bus_register_dev(kvm, KVM_PIO_BUS, 0x20, 2,
                                      &s->dev_master);
        if (ret < 0)
                goto fail_unlock;
        // 注册PIO类型bus的访问
        ret = kvm_io_bus_register_dev(kvm, KVM_PIO_BUS, 0xa0, 2, &s->dev_slave);
        if (ret < 0)
                goto fail_unreg_2;
        // 注册PIO类型bus的访问
        ret = kvm_io_bus_register_dev(kvm, KVM_PIO_BUS, 0x4d0, 2, &s->dev_eclr);
        if (ret < 0)
                goto fail_unreg_1;

        mutex_unlock(&kvm->slots_lock);

        kvm->arch.vpic = s;

        return 0;

fail_unreg_1:
        kvm_io_bus_unregister_dev(kvm, KVM_PIO_BUS, &s->dev_slave);

fail_unreg_2:
        kvm_io_bus_unregister_dev(kvm, KVM_PIO_BUS, &s->dev_master);

fail_unlock:
        mutex_unlock(&kvm->slots_lock);

        kfree(s);

        return ret;
}
```

### 6.4.1. kvm_io_bus_register_dev(): 在相应的io_bus总线上注册设备

8259A PIC属于PIO访问类型.

```cpp
int kvm_io_bus_register_dev(struct kvm *kvm, enum kvm_bus bus_idx, gpa_t addr,
                            int len, struct kvm_io_device *dev)
{
        int i;
        struct kvm_io_bus *new_bus, *bus;
        struct kvm_io_range range;
        // 获取io_bus总线
        bus = kvm_get_bus(kvm, bus_idx);
        if (!bus)
                return -ENOMEM;

        /* exclude ioeventfd which is limited by maximum fd */
        if (bus->dev_count - bus->ioeventfd_count > NR_IOBUS_DEVS - 1)
                return -ENOSPC;
        // 分配新的io_bus
        new_bus = kmalloc(struct_size(bus, range, bus->dev_count + 1),
                          GFP_KERNEL_ACCOUNT);
        if (!new_bus)
                return -ENOMEM;

        range = (struct kvm_io_range) {
                .addr = addr,
                .len = len,
                .dev = dev,
        };

        for (i = 0; i < bus->dev_count; i++)
                if (kvm_io_bus_cmp(&bus->range[i], &range) > 0)
                        break;

        memcpy(new_bus, bus, sizeof(*bus) + i * sizeof(struct kvm_io_range));
        new_bus->dev_count++;
        new_bus->range[i] = range;
        memcpy(new_bus->range + i + 1, bus->range + i,
                (bus->dev_count - i) * sizeof(struct kvm_io_range));
        rcu_assign_pointer(kvm->buses[bus_idx], new_bus);
        synchronize_srcu_expedited(&kvm->srcu);
        kfree(bus);

        return 0;
}
```

### 6.4.2. 三种设备在虚拟bus上的结构

虚拟bus总线结构如下, 注意IO端口地址与设备读写函数的关联

![2020-05-04-17-34-05.png](./images/2020-05-04-17-34-05.png)

每个`kvm_io_device`的设备都有对应的读写函数

## 6.5. kvm_ioapic_init(): ioapic的初始化

```cpp
int kvm_ioapic_init(struct kvm *kvm)
{
        struct kvm_ioapic *ioapic;
        int ret;
        // 分配 kmv_ioapic 结构体
        ioapic = kzalloc(sizeof(struct kvm_ioapic), GFP_KERNEL_ACCOUNT);
        if (!ioapic)
                return -ENOMEM;
        spin_lock_init(&ioapic->lock);
        // 
        INIT_DELAYED_WORK(&ioapic->eoi_inject, kvm_ioapic_eoi_inject_work);
        kvm->arch.vioapic = ioapic;
        // 重置ioapic
        kvm_ioapic_reset(ioapic);
        // 
        kvm_iodevice_init(&ioapic->dev, &ioapic_mmio_ops);
        ioapic->kvm = kvm;
        mutex_lock(&kvm->slots_lock);
        ret = kvm_io_bus_register_dev(kvm, KVM_MMIO_BUS, ioapic->base_address,
                                      IOAPIC_MEM_LENGTH, &ioapic->dev);
        mutex_unlock(&kvm->slots_lock);
        if (ret < 0) {
                kvm->arch.vioapic = NULL;
                kfree(ioapic);
        }

        return ret;
}
```

在MMIO_BUS上注册了ioapic设备

![2020-05-04-17-58-37.png](./images/2020-05-04-17-58-37.png)

## 6.6. kvm_setup_default_irq_routing(): 默认中断路由表的初始化

**中断路由表的初始化**通过`kvm_setup_default_irq_routing`函数实现，

```cpp
// 默认有24个表项
static const struct kvm_irq_routing_entry default_routing[] = {
        ROUTING_ENTRY2(0), ROUTING_ENTRY2(1),
        ROUTING_ENTRY2(2), ROUTING_ENTRY2(3),
        ROUTING_ENTRY2(4), ROUTING_ENTRY2(5),
        ROUTING_ENTRY2(6), ROUTING_ENTRY2(7),
        ROUTING_ENTRY2(8), ROUTING_ENTRY2(9),
        ROUTING_ENTRY2(10), ROUTING_ENTRY2(11),
        ROUTING_ENTRY2(12), ROUTING_ENTRY2(13),
        ROUTING_ENTRY2(14), ROUTING_ENTRY2(15),
        ROUTING_ENTRY1(16), ROUTING_ENTRY1(17),
        ROUTING_ENTRY1(18), ROUTING_ENTRY1(19),
        ROUTING_ENTRY1(20), ROUTING_ENTRY1(21),
        ROUTING_ENTRY1(22), ROUTING_ENTRY1(23),
};

int kvm_setup_default_irq_routing(struct kvm *kvm)
{
        return kvm_set_irq_routing(kvm, default_routing,
                                   ARRAY_SIZE(default_routing), 0);
}
```

首个参数kvm指定特定的虚拟机，后面`default_routing`是一个**全局**的`kvm_irq_routing_entry`**数组**，一共24项，该数组没别的作用，就是初始化`kvm_irq_routing_table`**路由表**

看`kvm_set_irq_routing`,

```cpp
int kvm_set_irq_routing(struct kvm *kvm,
                        const struct kvm_irq_routing_entry *ue,
                        unsigned nr,
                        unsigned flags)
{
        // 路由表
        struct kvm_irq_routing_table *new, *old;
        // 路由表项
        struct kvm_kernel_irq_routing_entry *e;
        u32 i, j, nr_rt_entries = 0;
        int r;
        /*正常情况下，nr_rt_entries=nr*/
        for (i = 0; i < nr; ++i) {
                if (ue[i].gsi >= KVM_MAX_IRQ_ROUTES)
                        return -EINVAL;
                nr_rt_entries = max(nr_rt_entries, ue[i].gsi);
        }

        nr_rt_entries += 1;
        /* 为中断路由表申请空间 */
        new = kzalloc(struct_size(new, map, nr_rt_entries), GFP_KERNEL_ACCOUNT);
        if (!new)
                return -ENOMEM;
        /* 设置路由表的表项数目 */
        new->nr_rt_entries = nr_rt_entries;
        // 初始化路由表的每个芯片的每个引脚为GSI号, 为-1, 不再使用 
        for (i = 0; i < KVM_NR_IRQCHIPS; i++)
                for (j = 0; j < KVM_IRQCHIP_NUM_PINS; j++)
                        new->chip[i][j] = -1;
        /*初始化每一个路由项*/
        for (i = 0; i < nr; ++i) {
                r = -ENOMEM;
                // 为每个路由项申请空间
                e = kzalloc(sizeof(*e), GFP_KERNEL_ACCOUNT);
                if (!e)
                        goto out;

                r = -EINVAL;
                switch (ue->type) {
                // MSI类型的中断
                case KVM_IRQ_ROUTING_MSI:
                        if (ue->flags & ~KVM_MSI_VALID_DEVID)
                                goto free_entry;
                        break;
                default:
                        if (ue->flags)
                                goto free_entry;
                        break;
                }
                // 设置路由项
                r = setup_routing_entry(kvm, new, e, ue);
                if (r)
                        goto free_entry;
                // 到下一项
                ++ue;
        }

        mutex_lock(&kvm->irq_lock);
        old = rcu_dereference_protected(kvm->irq_routing, 1);
        rcu_assign_pointer(kvm->irq_routing, new);
        kvm_irq_routing_update(kvm);
        kvm_arch_irq_routing_update(kvm);
        mutex_unlock(&kvm->irq_lock);

        kvm_arch_post_irq_routing_update(kvm);

        synchronize_srcu_expedited(&kvm->irq_srcu);
        /*释放old*/
        new = old;
        r = 0;
        goto out;

free_entry:
        kfree(e);
out:
        free_irq_routing_table(new);

        return r;
}
```

看一下这个**表项宏**：

```cpp
#define IOAPIC_ROUTING_ENTRY(irq) \
        { .gsi = irq, .type = KVM_IRQ_ROUTING_IRQCHIP,  \
          .u.irqchip = { .irqchip = KVM_IRQCHIP_IOAPIC, .pin = (irq) } }
#define ROUTING_ENTRY1(irq) IOAPIC_ROUTING_ENTRY(irq)
```

这是**初始化**`default_routing`的一个关键宏，**每一项**都是通过该宏**传递irq号**（`0-23`）64位下是`0-47`, 可见**gsi**就是**irq号**; 

type是`KVM_IRQ_ROUTING_IRQCHIP`, irq芯片, 而非MSI.

所以实际上，回到函数中`nr_rt_entries`就是数组中**项数**，接着为`kvm_irq_routing_table`**分配空间**，注意分配的空间包含**三部分**：

- `kvm_irq_routing_table`**结构**、
- `nr_rt_entries`个`hlist_head`
- **nr个**`kvm_kernel_irq_routing_entry`

所以`kvm_irq_routing_table`的**大小**是和**全局数组的大小**一样的。

整个结构如下图所示

![2020-05-03-13-18-31.png](./images/2020-05-03-13-18-31.png)

根据上图就可以理解`new->rt_entries = (void *)&new->map[nr_rt_entries];`这行代码的含义. (注, 新代码已经不是这样, 但是这部分内容保留, 便于了解发展演进)

接下来是对table的chip数组做初始化，这里初始化为`-1`. 

接下来就是一个循环，对**每一个中断路由项**做初始化，该过程是通过`setup_routing_entry`函数实现的，这里看下该函数

```cpp
static int setup_routing_entry(struct kvm *kvm,
                               struct kvm_irq_routing_table *rt,
                               struct kvm_kernel_irq_routing_entry *e,
                               const struct kvm_irq_routing_entry *ue)
{
        struct kvm_kernel_irq_routing_entry *ei;
        int r;
        // 获取到这个路由项的gsi号
        u32 gsi = array_index_nospec(ue->gsi, KVM_MAX_IRQ_ROUTES);

        /*
         * Do not allow GSI to be mapped to the same irqchip more than once.
         * Allow only one to one mapping between GSI and non-irqchip routing.
         */
        // 遍历这个gsi对应的路由项链表
        hlist_for_each_entry(ei, &rt->map[gsi], link)
                if (ei->type != KVM_IRQ_ROUTING_IRQCHIP ||
                    ue->type != KVM_IRQ_ROUTING_IRQCHIP ||
                    ue->u.irqchip.irqchip == ei->irqchip.irqchip)
                        return -EINVAL;
        // 路由项的gsi
        e->gsi = gsi;
        // 路由项的类型
        e->type = ue->type;
        // 设置该路由项的set方法
        r = kvm_set_routing_entry(kvm, e, ue);
        if (r)
                return r;
        // irq芯片, 而非MSI时候
        if (e->type == KVM_IRQ_ROUTING_IRQCHIP)
                // 设置路由表的chip. 即引脚号
                rt->chip[e->irqchip.irqchip][e->irqchip.pin] = e->gsi;
        // 添加到路由表的哈希链表
        hlist_add_head(&e->link, &rt->map[e->gsi]);

        return 0;
}
```

之前的初始化过程我们已经看见了，`.type`为`KVM_IRQ_ROUTING_IRQCHIP`，所以这里实际上就是把`e->gsi = ue->gsi; e->type = ue->type;`, 然后调用了`kvm_set_routing_entry`，该函数中主要是设置了`kvm_kernel_irq_routing_entry`中的**set函数**，**APIC**的话设置的是`kvm_set_ioapic_irq`函数，而**pic**的话设置`kvm_set_pic_irq`函数，然后设置**irqchip的类型**和**管脚**，对于**IOAPIC**也是直接复制过来，PIC由于**管脚计算**是`irq%8`，所以这里需要**加上8的偏移**。之后**设置table的chip为gis号**。回到`setup_routing_entry`函数中，就把`kvm_kernel_irq_routing_entry`**以gsi号位索引**，加入到了**map数组**中对应的**双链表**中。再回到`kvm_set_irq_routing`函数中，接下来就是**更新kvm结构**中的`irq_routing`指针了。

# 7. 初始化虚拟PIT

## 7.1. QEMU

PIT创建:

```cpp
// i8254.c
kvm_vm_ioctl(kvm_state, KVM_CREATE_PIT2, &config);
kvm_vm_ioctl(kvm_state, KVM_CREATE_PIT)
```

# 参考

